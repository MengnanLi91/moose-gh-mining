{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMy0wMy0wN1QxMDo1Mjo0NS0wNjowMM4ASnt7"
    },
    "edges": [
      {
        "node": {
          "title": "Should v and displacements in the MatDiffusion Kernel behave similarly ?",
          "author": {
            "login": "aaelmeli"
          },
          "bodyText": "Hi\nI am trying to understand the difference between the displacements and the v in the MatDiffusion kernel here (and other Diffusion kernels as well). What I initially understood is that both of them are couplable_variables, am I right? If that is the case, why are they behaving differently? Please see below the input file that can reproduce my conclusion (replace v by displacements and the results will not be the same)\nAnother issue is w.r.t the jacobian computation when explicitly specifying v=variable (the default nonlinear variable).  As indicated in the documentation, if the v is not specified, the default nonlinear variable will be used for v (i.e. v=variable). Now, if the two lines in the kernel block were uncommented, it will result in an incorrect solution. However, if the ADMatDiffusion is used, it results in the correct solution, indicating the jacobian is not computed properly when explicitly specifying v=variable.\nI can work on a fix for these and submit a PR after confirming it and if you think it is worth fixing it.\nPlease see the expected (correct solution below):\n\n[Mesh]\n  type = GeneratedMesh\n  dim = 1\n  xmin = 0\n  xmax = 1\n  nx = 1000\n[]\n\n[Variables]\n  [ui]\n  []\n  [ur]\n  []\n[]\n\n[BCs]\n  [uxr_left_1]\n    type = CoupledVarNeumannBC\n    variable = ur\n    boundary = 'left'\n    v = ui\n    coef = 99.627 \n  []\n  [uxr_left_2]\n    type = CoupledVarNeumannBC\n    variable = ur\n    boundary = 'left'\n    v = ur\n    coef = -4.969 \n  []\n\n  [uxi_left_1]\n    type = CoupledVarNeumannBC\n    variable = ui\n    boundary = 'left'\n    v = ui\n    coef = -4.969\n  []\n  [uxi_left_2]\n    type = CoupledVarNeumannBC\n    variable = ui\n    boundary = 'left'\n    v = ur\n    coef = -99.627 \n  []\n  [right_real]\n    type = DirichletBC\n    variable = ur\n    value = 1\n    boundary = right\n  []\n  [right_imaginery]\n    type = DirichletBC\n    variable = ui\n    value = 0\n    boundary = right\n  []\n[]\n\n[Kernels]\n  [sigma_rr]\n    type = MatDiffusion\n    variable = ur\n    diffusivity = 1\n    # v = ur\n  []\n  [sigma_ii]\n    type = MatDiffusion\n    variable = ur\n    diffusivity = -0.1\n    v = ui\n  []\n  [sigma_ri]\n    type = MatDiffusion\n    variable = ui\n    diffusivity = 1\n    # v = ui\n  []\n  [sigma_ir]\n    type = MatDiffusion\n    variable = ui\n    diffusivity = 0.1\n    v = ur\n  []\n  [reaction_real]\n    type = Reaction\n    variable = ur\n    rate = -10000\n  []\n  [reaction_imag]\n    type = Reaction\n    variable = ui\n    rate = -10000\n  []\n[]\n\n[Executioner]\n  type = Steady\n  solve_type = LINEAR\n  petsc_options_iname = '-pc_type'\n  petsc_options_value = 'lu'\n[]\n\n[Outputs]\n  exodus = true\n[]",
          "url": "https://github.com/idaholab/moose/discussions/23666",
          "updatedAt": "2023-04-29T03:36:18Z",
          "publishedAt": "2023-03-08T23:48:26Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nDisplacements is used to represent the deformation of the mesh, not a field living on the mesh.\nDisplacements affect the volume of elements for example. It s more involved than just solving for a field\nPlease submit a patch if you have found a bug. We can examine it in the PR\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23666#discussioncomment-5247720",
                  "updatedAt": "2023-03-08T23:57:35Z",
                  "publishedAt": "2023-03-08T23:57:21Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Generating mesh for a unit cell in MOOSE",
          "author": {
            "login": "yfche"
          },
          "bodyText": "The attached mesh is generated in cubit, which contains six 1/3 cylinders, a central hole, and a hexagon excluding the 1/3 cylinders. I wonder if this geometry can be directly generated and meshed in the MOOSE reactor module. Thanks.",
          "url": "https://github.com/idaholab/moose/discussions/23646",
          "updatedAt": "2023-03-08T23:30:15Z",
          "publishedAt": "2023-03-07T21:09:35Z",
          "category": {
            "name": "Q&A Meshing"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nI think we can do this geometry.\nOverall it will be:\n\na hexagonconcentriccirclegenerator for the center with a big circle\nsame generator for the 6 other positions\nan assembly generator to tie them all together\nan hexagon trimmer with the peripheral option to cut on the circles of the 6 external positions\n\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23646#discussioncomment-5233544",
                  "updatedAt": "2023-03-07T21:14:35Z",
                  "publishedAt": "2023-03-07T21:14:35Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "yfche"
                          },
                          "bodyText": "I found that adding \"quad_center_elements = true\"  causes Segmentation fault: 11, as below. Setting it to false generates the mesh fine. Any ideas why setting the quad_center_elements crashes my code? Thanks.\n[hex_1]\n    type = PolygonConcentricCircleMeshGenerator\n    num_sides = 6\n    num_sectors_per_side = '10 10 10 10 10 10'\n    # background_intervals = 10\n    # background_block_ids = 20\n    # background_block_names = background\n    polygon_size = 3.0\n    polygon_size_style = radius\n    preserve_volumes = off # on\n    flat_side_up = true\n    quad_center_elements = true\n  []",
                          "url": "https://github.com/idaholab/moose/discussions/23646#discussioncomment-5234334",
                          "updatedAt": "2023-03-07T22:54:06Z",
                          "publishedAt": "2023-03-07T22:54:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@miaoyinb if you could please have a look",
                          "url": "https://github.com/idaholab/moose/discussions/23646#discussioncomment-5234372",
                          "updatedAt": "2023-03-07T22:57:50Z",
                          "publishedAt": "2023-03-07T22:57:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "yfche"
                          },
                          "bodyText": "In addition, the central hole is not of the same size as the 6 external circles. In this case, can we still use the hexagonal assembly to tie these circles together? If not, is my understanding correct that we may not use an hexagon trimmer to cut on the 6 external circles?",
                          "url": "https://github.com/idaholab/moose/discussions/23646#discussioncomment-5234428",
                          "updatedAt": "2023-03-07T23:05:56Z",
                          "publishedAt": "2023-03-07T23:05:56Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "yes. The central circle is not determining the boundary mesh\nFor the trimmer there may be some limitations on when you can use it, but I think there's a workaround. Please let us know once you reach there",
                          "url": "https://github.com/idaholab/moose/discussions/23646#discussioncomment-5234751",
                          "updatedAt": "2023-03-07T23:59:48Z",
                          "publishedAt": "2023-03-07T23:59:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "miaoyinb"
                          },
                          "bodyText": "I found that adding \"quad_center_elements = true\" causes Segmentation fault: 11, as below. Setting it to false generates the mesh fine. Any ideas why setting the quad_center_elements crashes my code? Thanks.\n[hex_1]\n    type = PolygonConcentricCircleMeshGenerator\n    num_sides = 6\n    num_sectors_per_side = '10 10 10 10 10 10'\n    # background_intervals = 10\n    # background_block_ids = 20\n    # background_block_names = background\n    polygon_size = 3.0\n    polygon_size_style = radius\n    preserve_volumes = off # on\n    flat_side_up = true\n    quad_center_elements = true\n  []\n\n\nThis should be a bug. I will fix it.\nIt should work fine if you uncomment # background_block_ids = 20 before the fix.",
                          "url": "https://github.com/idaholab/moose/discussions/23646#discussioncomment-5236275",
                          "updatedAt": "2023-03-08T03:15:42Z",
                          "publishedAt": "2023-03-08T03:15:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "miaoyinb"
                          },
                          "bodyText": "#23652 Thanks for reporting the bug.",
                          "url": "https://github.com/idaholab/moose/discussions/23646#discussioncomment-5236758",
                          "updatedAt": "2023-03-08T04:38:40Z",
                          "publishedAt": "2023-03-08T04:38:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "yfche"
                          },
                          "bodyText": "Uncommenting # background_block_ids = 20 works. Thanks for providing the workaround.",
                          "url": "https://github.com/idaholab/moose/discussions/23646#discussioncomment-5244081",
                          "updatedAt": "2023-03-08T16:49:26Z",
                          "publishedAt": "2023-03-08T16:49:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "miaoyinb"
                          },
                          "bodyText": "The fix for the bug has been merged. Your original input should also work with the most updated MOOSE next branch.",
                          "url": "https://github.com/idaholab/moose/discussions/23646#discussioncomment-5244371",
                          "updatedAt": "2023-03-08T17:13:20Z",
                          "publishedAt": "2023-03-08T17:13:19Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "use the BlockDeletionGenerator",
                          "url": "https://github.com/idaholab/moose/discussions/23646#discussioncomment-5247572",
                          "updatedAt": "2023-03-08T23:29:01Z",
                          "publishedAt": "2023-03-08T23:29:01Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Error running input file.",
          "author": {
            "login": "ahmad681"
          },
          "bodyText": "So I am using the executable to run the input file, you have the exact same one. And I keep getting this functionParser division by zero that I have no clue where it's coming from. Any idea? I am afraid this has to do with the libmesh itself.\n./cdd_app-opt -i inputFiles/mechanics_phase_material_interface_random.i\n\n nlx 18 nly 18 nlz 13\n nsx 234 nsy 234 nsz 324\n xlength 5\nXMAX = 5 Y_MAX = 5 Z_MAX =  5.210260493\n MESH CREATED\n l_mesh = 0.2631578947\nSetting Up\n  Initializing\n    Finished Initializing Equation Systems                                               [  9.43 s] [  638 MB]\n  Finished Initializing                                                                  [  9.61 s] [  643 MB]\nFinished Setting Up                                                                      [ 10.59 s] [  754 MB]\nFramework Information:\nMOOSE Version:           git commit 7ddfb7f51b on 2023-02-21\nLibMesh Version:         482ca36f0ba05dbb5d87d02688d43eaa4bf983eb\nPETSc Version:           3.16.6\nSLEPc Version:           3.16.2\nCurrent Time:            Sat Mar  4 18:59:38 2023\nExecutable Timestamp:    Sat Mar  4 18:36:19 2023\nParallelism:\n  Num Processors:          1\n  Num Threads:             1\n\nMesh:\n  Parallel Type:           replicated\n  Mesh Dimension:          3\n  Spatial Dimension:       3\n  Nodes:                   132651\n  Elems:                   125000\n  Num Subdomains:          1\n\nNonlinear System:\n  Num DOFs:                397953\n  Num Local DOFs:          397953\n  Num Constrained DOFs:    15453\n  Local Constrained DOFs:  15453\n  Variables:               { \"disp_x\" \"disp_y\" \"disp_z\" }\n  Finite Element Types:    \"LAGRANGE\"\n  Approximation Orders:    \"FIRST\"\n\nAuxiliary System:\n  Num DOFs:                4512718\n  Num Local DOFs:          4512718\n  Variables:               { \"cauchy_stress_xx\" \"cauchy_stress_xy\" \"cauchy_stress_xz\" \"cauchy_stress_yy\"\n                             \"cauchy_stress_yz\" \"cauchy_stress_zz\" } { \"phase_pillar\" \"phase_substrate\"\n                             \"phase_matrix\" \"n_pm_x\" \"n_pm_y\" ... \"n_ps_y\" \"n_ps_z\" \"n_pf_x\" \"n_pf_y\"\n                             \"n_pf_z\" } { \"curln_pm_x\" \"curln_pm_y\" \"curln_pm_z\" \"divn\" \"elastic_strain_energy\"\n                             ... \"interfacial_energy_pm\" \"interfacial_energy_ps\" \"interfacial_energy_ms\"\n                             \"interfacial_energy_pf\" \"interfacial_energy_mf\" }\n  Finite Element Types:    \"MONOMIAL\" \"LAGRANGE\" \"MONOMIAL\"\n  Approximation Orders:    \"CONSTANT\" \"FIRST\" \"CONSTANT\"\n\nExecution Information:\n  Executioner:             Transient\n  TimeStepper:             ConstantDT\n  Solver Mode:             NEWTON\n  MOOSE Preconditioner:    SMP\n\nLEGACY MODES ENABLED:\n This application uses the legacy material output option: material properties are output only on TIMESTEP_END, not INITIAL. To remove this message, set 'use_legacy_material_output' to false in this application. If there are gold output files that contain material property output for which output occurs on INITIAL, then these will generate diffs due to zero values being stored, and these tests should be re-golded.\n\n\n    Finished Projecting Initial Solutions                                                [  5.30 s] [    0 MB]\nERROR: FunctionParser is unable to evaluate component 0 for 'df/dx' with arguments:\n        0\n        0\n        -60\n        0\n\nlibMesh terminating:\nReason: Division by zero\nStack frames: 22\n0: libMesh::print_trace(std::ostream&)\n1: libMesh::MacroFunctions::report_error(char const*, int, char const*, char const*, std::ostream&)\n2: libMesh::ParsedFunction<double, libMesh::VectorValue<double> >::eval(FunctionParserADBase<double>&, std::basic_string_view<char, std::char_traits<char> >, unsigned int) const\n3: MooseParsedFunctionWrapper::evaluateGradient(double, libMesh::Point const&)\n4: MooseParsedFunctionTempl<Function>::gradient(double, libMesh::Point const&) const\n5: ProductAux::computeValue()\n6: AuxKernelTempl<double>::compute()\n7: ComputeNodalAuxVarsThread<AuxKernelTempl<double> >::onNode(__gnu_cxx::__normal_iterator<libMesh::Node const* const*, std::vector<libMesh::Node const*, std::allocator<libMesh::Node const*> > >&)\n8: ThreadedNodeLoop<libMesh::StoredRange<libMesh::MeshBase::const_node_iterator, libMesh::Node const*>, __gnu_cxx::__normal_iterator<libMesh::Node const* const*, std::vector<libMesh::Node const*, std::allocator<libMesh::Node const*> > > >::operator()(libMesh::StoredRange<libMesh::MeshBase::const_node_iterator, libMesh::Node const*> const&)\n9: void libMesh::Threads::parallel_reduce<libMesh::StoredRange<libMesh::MeshBase::const_node_iterator, libMesh::Node const*>, ComputeNodalAuxVarsThread<AuxKernelTempl<double> > >(libMesh::StoredRange<libMesh::MeshBase::const_node_iterator, libMesh::Node const*> const&, ComputeNodalAuxVarsThread<AuxKernelTempl<double> >&)\n10: void AuxiliarySystem::computeNodalVarsHelper<AuxKernelTempl<double> >(MooseObjectWarehouse<AuxKernelTempl<double> > const&, std::vector<std::vector<MooseVariableFieldBase*, std::allocator<MooseVariableFieldBase*> >, std::allocator<std::vector<MooseVariableFieldBase*, std::allocator<MooseVariableFieldBase*> > > > const&)\n11: AuxiliarySystem::computeNodalVars(MooseEnumItem)\n12: AuxiliarySystem::compute(MooseEnumItem)\n13: FEProblemBase::computeAuxiliaryKernels(MooseEnumItem const&)\n14: FEProblemBase::execute(MooseEnumItem const&)\n15: FEProblemBase::initialSetup()\n16: Transient::init()\n17: MooseApp::executeExecutioner()\n18: MooseApp::run()\n19: main\n20: __libc_start_main\n21: ./cdd_app-opt() [0x40ef30]\n[0] /home/ahmad68/projects/moose/scripts/../libmesh/installed/include/libmesh/parsed_function.h, line 719, compiled Feb 22 2023 at 13:12:24\n\n--------------------------------------------------------------------------\nMPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD\nwith errorcode 1.\n\nNOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.\nYou may or may not see output from other processes, depending on\nexactly when Open MPI kills them.\n\nHere if you are iterested at looking at my inputfile\nmechanics_phase_material_interface_random.txt",
          "url": "https://github.com/idaholab/moose/discussions/23607",
          "updatedAt": "2023-04-29T03:37:09Z",
          "publishedAt": "2023-03-05T00:13:13Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nI dont see anything shocking\nAre you getting any deprecation warnings from this input?\nWhat are these ProductAux for? just for a product / division?\nWe have a ParsedAux in the kernel that will do the same.\nThese ProductAux seem to be missing arguments too, I dont see what they are multiplying.\nI reckon you should transition the input file to using ParsedAux\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23607#discussioncomment-5208119",
                  "updatedAt": "2023-03-05T16:52:56Z",
                  "publishedAt": "2023-03-05T16:52:56Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ahmad681"
                          },
                          "bodyText": "Thanks for the reply Guillaume,\nso I kind of see your point, but I don't think ParsedAux does the same thing as ProductAux.\nAlso I am not getting any deprecation warning.\nThis used to work before just fine, maybe now Moose does things differently. I do recall that we registered ProductAux auxkernel to define the normals by taking the derivatives of a phase function. This phase function indicator was given by taking heaviside function of stepped signed function.\nSo basically, we have f is the stepped signed function you can view it as a circle function for instance, sqrt((x-x0)^2-(y-y0)^2) - radius. so that would be\nf = _var1_func.value(_t, p_t)-_R[i],\nThen the phase function indicator equals\nvar1+=1.0/(1+exp(-(f)/_L));\n_L is the width of the diffuse interface basically.\nThen we apply gradient to define the normals, I hope you can see in the code I am viewing below.\nSo there is this possible candidate problems I believe,  is that I traced back the error df/dx = undefined, because for some reason it is deviding by zero to find the gradient. we read locations of the pillars from an input file to initialize the problem, and now I am afraid that it is not evaluating the correct values of the pillar functions by parsing a string. What do you think?\nAnother candidate problem could be maybe it is unable to evaluate the derivative at the interface when the value transition from 0 to 1, not sure to be honest.\n#include \"ProductAux.h\"\n#define Y 1\n#define Z 2\nregisterMooseObject(\"cddAppApp\", ProductAux);\n\nInputParameters\nProductAux::validParams()\n{\n\tInputParameters params = AuxKernel::validParams();\n\tparams.addParam<FunctionName>(\"vol1_function\",0.5, \"The function used to define the surface surrounding the volume 1\");\n\tparams.addParam<FunctionName>(\"vol2_function\",0.5, \"The function used to define the surface surrounding the volume 2\");\n\tparams.addRequiredParam<bool>(\"invert_var1\",\"\");\n\tparams.addRequiredParam<bool>(\"invert_var2\",\"\");\n\tparams.addRequiredParam<Real>(\"L\",\"controls width of interface\");\n\tparams.addRequiredParam<unsigned int>(\"component\",\"0=scalar representing the volume, 1=nx component, 2=ny component, 3=nz component\");\n\tparams.addParam<unsigned int>(\"normal_to_set\",0,\"The product produces 2 types of normals which join at a common line. this number sets the one the user wants to return\");\n\treturn params;\n}\n\nProductAux::ProductAux(const InputParameters & parameters)\n: AuxKernel(parameters),\n  _invert1(getParam<bool>(\"invert_var1\")),\n  _invert2(getParam<bool>(\"invert_var2\")),\n  _normal_to_set(getParam<unsigned int>(\"normal_to_set\")),\n  _var1_func(getFunction(\"vol1_function\")),\n  _var2_func(getFunction(\"vol2_function\")),\n  _L(getParam<Real>(\"L\")),\n  _component(getParam<unsigned int>(\"component\"))\n{\n\n\tstd::string sys_file_name = \"input_pillars.txt\";\n\tstd::ifstream fileslipsys;\n\tMooseUtils::checkFileReadable(sys_file_name);\n\tfileslipsys.open(sys_file_name.c_str());\n\tunsigned int n_loops = 0;\n\tif (!(fileslipsys >> _num_pillars))\n\t\tmooseError(\"DensityDistributionDebugAux Error: Premature end of file reading slip system file \\n\");\n\t_centers.resize(_num_pillars);\n\t_R.resize(_num_pillars);\n\t_mag.resize(_num_pillars);\n\tfor (unsigned int i = 0; i < _num_pillars; ++i){\n\t\tfor(unsigned int j = 0; j<LIBMESH_DIM;++j){\n\t\t\tif (!(fileslipsys >> _centers[i](j)))\n\t\t\t\tmooseError(\"DensityDistributionDebugAux Error: Premature end of file reading slip system file \\n\");\n\t\t}\n\t\tif (!(fileslipsys >> _R[i]))\n\t\t\tmooseError(\"DensityDistributionDebugAux Error: Premature end of file reading slip system file \\n\");\n\t\tif (!(fileslipsys >> _mag[i]))\n\t\t\tmooseError(\"DensityDistributionDebugAux Error: Premature end of file reading slip system file \\n\");\n\n\n\t}\n\n}\n\nReal\nProductAux::computeValue()\n{\n\tReal var1,var2;\n\tPoint p;\n\tp(0)=(*_current_node)(0);\n\tp(1)=(*_current_node)(1);\n\tp(2)=(*_current_node)(2);\n\tReal f1=_var1_func.value(_t, *_current_node);\n\tReal f2=_var2_func.value(_t, *_current_node);\n\tReal surface_dirac1=1/(sqrt(M_PI)*_L)*exp( -(f1*f1)/(_L*_L) );\n\tReal surface_dirac2=1/(sqrt(M_PI)*_L)*exp( -(f2*f2)/(_L*_L) );\n\tReal tmp=0;\n\tvar1 = 0;\n\tif (_invert1){//pillar\n\t\tfor(unsigned int i=0;i<_num_pillars;i++){\n\t\t\tPoint p_t = p - _centers[i];\n\t\t\t//Real f = sqrt(p_t(0)*p_t(0)+p_t(1)*p_t(1);\n\t\t\tReal f = _var1_func.value(_t, p_t)-_R[i];\n\t\t\tvar1+=1.0/(1+exp(-(f)/_L));\n\t\t}\n\t\tvar1 = var1 - (_num_pillars-1);\n\t\tvar1 = 1-var1;\n\t}else{//matrix\n\t\tfor(unsigned int i=0;i<_num_pillars;i++){\n\t\t\tPoint p_t = p - _centers[i];\n\t\t\t//Real f = sqrt(p_t(0)*p_t(0)+p_t(1)*p_t(1));\n\t\t\tReal f = _var1_func.value(_t, p_t)-_R[i];\n\t\t\tvar1+=1.0/(1+exp(-(f)/_L));\n\t\t}\n\t\tvar1 = var1 - (_num_pillars-1);\n\t}\n\tif (_invert2){\n\t\tvar2=1.0-1.0/(1.0+exp(-f2/_L));\n\t}else{\n\t\tvar2 = 1.0/(1.0+exp(-f2/_L));\n\t}\n\tRealGradient df1 = _var1_func.gradient(_t, *_current_node);\n\tRealGradient df2 = _var2_func.gradient(_t, *_current_node);\n\tPoint gradF1,gradF2;\n\tgradF1(0)=df1(0);gradF2(0)=df2(0);\n\tgradF1(1)=df1(1);gradF2(1)=df2(1);\n\tgradF1(2)=df1(2);gradF2(2)=df2(2);\n\t// var1,var2 represents heaviside(f1),heaviside(f2)\n\t//\tPoint N1 = exp(-f1/_L)/((1.0+exp(-f1/_L))*(1.0+exp(-f1/_L)))*gradF1*var2;\n\tPoint N1;\n\tfor(unsigned int i=0;i<_num_pillars;i++){\n\t\tPoint p_t = p - _centers[i];\n\t\tRealGradient df1 = _var1_func.gradient(_t, p_t);\n\t\tgradF1(0)=df1(0);gradF1(1)=df1(1);gradF1(2)=df1(2);\n\t\t//Real f = sqrt(p_t(0)*p_t(0)+p_t(1)*p_t(1))-_R[i];\n\t\tReal f = _var1_func.value(_t, p_t)-_R[i];\n\t\tN1+=exp(-f/_L)/((1.0+exp(-f/_L))*(1.0+exp(-f/_L)))*gradF1*var2/_L;\n\t}\n\n\tPoint N2 = exp(-f2/_L)/((1.0+exp(-f2/_L))*(1.0+exp(-f2/_L)))*gradF2*var1/_L;\n\tif(_component==0){\n\t\treturn var1*var2;\n\t}else if (_normal_to_set==0){\n\t\treturn N1(_component-1);\n\t}else{\n\t\treturn N2(_component-1);\n\t}\n\n}",
                          "url": "https://github.com/idaholab/moose/discussions/23607#discussioncomment-5217010",
                          "updatedAt": "2023-03-06T15:06:48Z",
                          "publishedAt": "2023-03-06T15:06:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "which line is doing df/dx?\nhow is the gradient computed? Is this from a Moose function?",
                          "url": "https://github.com/idaholab/moose/discussions/23607#discussioncomment-5221838",
                          "updatedAt": "2023-03-07T00:22:20Z",
                          "publishedAt": "2023-03-07T00:22:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ahmad681"
                          },
                          "bodyText": "To me it seems like\nRealGradient df1 = _var1_func.gradient(_t, *_current_node);\nRealGradient df2 = _var2_func.gradient(_t, *_current_node); \n\nand\nRealGradient df1 = _var1_func.gradient(_t, p_t); \n\nIt seems like the gradient() is being called from\ntemplate <typename Output, typename OutputGradient>\ninline\nOutputGradient\nParsedFunction<Output,OutputGradient>::gradient (const Point & p, const Real time)\n{\n  OutputGradient grad;\n  set_spacetime(p, time);\n\n  grad(0) = eval(*dx_parsers[0], \"df/dx\", 0);\n#if LIBMESH_DIM > 1\n  grad(1) = eval(*dy_parsers[0], \"df/dy\", 0);\n#endif\n#if LIBMESH_DIM > 2\n  grad(2) = eval(*dz_parsers[0], \"df/dz\", 0);\n#endif\n\n  return grad;\n}\n\nThis can be found in\nmoose>libmesh>build>include>libmesh>parsed_function.h\nI believe in my case dx_parsers[i] should be the phase function.",
                          "url": "https://github.com/idaholab/moose/discussions/23607#discussioncomment-5228312",
                          "updatedAt": "2023-03-07T15:20:21Z",
                          "publishedAt": "2023-03-07T13:34:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Then you should have a look at the parsed expressions.\nPlease note that there was a rework of the parsed expression parameters, so if you are getting deprecation messages about this it might be the problem.\nWe renamed args -> coupled_variables\nfunction -> expression\nand a few others",
                          "url": "https://github.com/idaholab/moose/discussions/23607#discussioncomment-5230018",
                          "updatedAt": "2023-03-07T15:21:36Z",
                          "publishedAt": "2023-03-07T15:21:36Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ahmad681"
                  },
                  "bodyText": "Okay, the problem is very weird now. I do believe now there is nothing wrong with the code ProductAux auxillary kernel. I don't think it is even with the input file. The code works just fine but only with fewer number of elements, before it used to be with as many elements as we wanted.\nThese are the new dimensions, single pillar in a matrix setting on a substrate\nnx = 15\nny = 15\nnz = 15\nxmin = -20\nxmax = 20\nymin = -24.9518\nymax = 24.9518\nzmin = -60\nzmax = 30\nand the pillar is placed at (0,0,0) with radius 4.\nIt is also nothing wrong with the way the parsed function is defined, I believe. I am interested to hear your thoughts about this:\nIt working when I use up to 15x15x15 number of elements which is very weird. however, the shape of the pillar is not accurate because we are evaulating the function of pillar using sqrt(x^2+y^2)-radius. But when I increase the # of elements, that is when I start getting errors like\nERROR: FunctionParser is unable to evaluate component 0 for 'df/dx' with arguments:\n0\n0\n-20\n0\nlibMesh terminating:\nReason: Division by zero\n[0] /home/ahmad68/projects/moose/scripts/../libmesh/installed/include/libmesh/parsed_function.h, line 719, compiled Feb 22 2023 at 13:12:24\nERROR: FunctionParser is unable to evaluate component 0 for 'df/dx' with arguments:\n-20\n-24.9518\n20\n0\nlibMesh terminating:\nReason: Division by zero\n[1] /home/ahmad68/projects/moose/scripts/../libmesh/installed/include/libmesh/parsed_function.h, line 719, compiled Feb 22 2023 at 13:12:24\nERROR: FunctionParser is unable to evaluate component 0 for 'df/dx' with arguments:\n4.44444\n-24.9518\n20\n0\nlibMesh terminating:\nReason: Division by zero\nSo there seems some problem with evaulating the gradient at (0,0,-20) center of the pillar (-20,-24.9,20) that is interface between pillar and substrate perhaps\nand (4.44,-24.9,20) is matrix/pillar/substrate common line.\nSo let's see what is going on here:\nBasically I am trying to do this\n\nAnd before the stress equilibrium problem was computed just fine with as many elements, so we get uniform pillar and something like this\n\n\nNow with the new version, the code only works with 15x15x15 maximum number of elements!! so you see the pillar phase is oddly shaped in the xy plane, not along the z-direction though\n\n\nSo what I am concluding is the following: For some reason, some points their gradient is giving undefined answer because of this devivision by zero, why is it being evaluated incorrectly there at those points, that is something that I couldn't really figure out.\nBut I am happy at least that the code is functioning although with fewer number of elements. basically the larger # of elements I use, the more uniform \"circular\" the shape of the pillar and therefore the better results. I believe there is something with evaluating sqrt(xx+yy).\nAny thoughts on this, Guillaume? thanks for the help by the way",
                  "url": "https://github.com/idaholab/moose/discussions/23607#discussioncomment-5243395",
                  "updatedAt": "2023-03-08T15:55:06Z",
                  "publishedAt": "2023-03-08T15:53:36Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "This should be doable to debug.\nYou need to find the parsed function and see why it s dividing by 0 (the last component)\nIf you run this in a debugger, you should be able to get a backtrace\nhttps://mooseframework.inl.gov/application_development/debugging.html",
                          "url": "https://github.com/idaholab/moose/discussions/23607#discussioncomment-5243976",
                          "updatedAt": "2023-03-08T16:40:32Z",
                          "publishedAt": "2023-03-08T16:40:31Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ahmad681"
                  },
                  "bodyText": "Final update for the discussion forum,\nThe code finally works for as many elements as I want.\nhere is what had to change:\nI  passed in to the auxillary kernels parsed functions like that:\nvol1_function = vol1_function_parsed\n vol2_function = vol2_function_parsed \n\nand the parsed functions are defined in Functions block like this\n[Functions]\n  [vol1_function_parsed] \n    type = ParsedFunction \n    expression = sqrt(((x-0.001)*(x-0.001))+((y-0.001)*(y-0.001)))-5  \n  [../]\n  [vol2_function_parsed] \n    type = ParsedFunction \n    expression = sqrt((z-20)*(z-20))-20 \n  [../]\n[]\n\nIn addition to that, the gradient of the sqrt(x^2+y^2) at the center of the circle blows up which kind of makes sense because it deviding by zero at the point, So I basically changed this to expression = sqrt(((x-0.001)(x-0.001))+((y-0.001)(y-0.001))) where it basically never passes the center of the pillar.\nAnd the solver runs pretty nicely with the correct physics.  Stresses, elastic energies, interfacial energies, strains, phase functions, etc. Thanks for the help",
                  "url": "https://github.com/idaholab/moose/discussions/23607#discussioncomment-5245956",
                  "updatedAt": "2023-04-29T03:37:24Z",
                  "publishedAt": "2023-03-08T20:12:46Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "IterationAdaptiveDT multiple constraints conflict",
          "author": {
            "login": "jessecarterMOOSE"
          },
          "bodyText": "In IterationAdaptiveDT, you can use a postprocessor to constrain the time step, but it also takes time/dt pairs to force the time step at those specified times. It looks like the postprocessor takes precedence over time points, meaning if you're at a time where you specified the time step, but the postprocesser gives a smaller value, the postprocessor will win. Is there a way to force the time/dt pairs to take precedence at the given time points, or ignore the postprocessor at the given time points?",
          "url": "https://github.com/idaholab/moose/discussions/23645",
          "updatedAt": "2023-04-29T03:37:50Z",
          "publishedAt": "2023-03-07T21:04:20Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nI dont understand the concern. Could you please paste the TimeStepper block and the time steps it takes?\nRight now I feel like it s obeying both constraints naturally ?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5233494",
                  "updatedAt": "2023-03-07T21:09:43Z",
                  "publishedAt": "2023-03-07T21:09:43Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jessecarterMOOSE"
                          },
                          "bodyText": "Can't get to my input file from here but basically I've got:\n  [TimeStepper]\n    type = IterationAdaptiveDT\n    ...\n    dt = 1.0\n    timestep_limiting_postprocessor = time_pps\n    time_t = '1.0'\n    time_dt = '20.0'\n  []\n\nSo when I'm at t=1.0, I want to force dt = 20.0, but my time postprocessor is returning a smaller value, say 5.0.\nThe timestepper prints:\nSetting dt to value specified by dt function: 20.0\nLimiting dt to postprocessor value. dt = 5.0.\n\nI want the time_dt value(s) to take precedence over the postprocessor. My logic is that I want to force a time step at the given time(s). Currently the time points are being ignored.",
                          "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5233638",
                          "updatedAt": "2023-03-07T21:24:53Z",
                          "publishedAt": "2023-03-07T21:24:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Why even specify a timestep limiting pp if you dont want it to matter though?\nThe time points will be reached, it s just the time_dt that is not met.\nIf you say you want to hit t = 1, 8, 12 and 20s, it will hit them even with a timestep limited to 5s by the PP.\nIt would do: 1, 6, 8, 12, 17, 20, taking the max PP step or the step needed to meet the desired time points",
                          "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5233685",
                          "updatedAt": "2023-03-07T21:30:56Z",
                          "publishedAt": "2023-03-07T21:30:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jessecarterMOOSE"
                          },
                          "bodyText": "My PP is MaterialTimeStepPostprocessor, which lags the solution time. I'm trying to force a big jump in time at t=1, but the values from my material models are based on the previous time increment, which was much smaller.  I know when the big jump times are, so I want to overrule my time PP at the specified points.",
                          "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5233783",
                          "updatedAt": "2023-03-07T21:42:57Z",
                          "publishedAt": "2023-03-07T21:42:56Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I m not sure what the solution is here.\nWe are not going to change the default behavior of that Timestepper as it makes sense.\nWe could add a boolean to change the priority of time stepping decisions but it's pretty custom.\nYou could write a custom PP that has complex enough logic to sometimes give the MatTimeStepPP value, sometimes have a larger value",
                          "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5233841",
                          "updatedAt": "2023-03-07T21:49:36Z",
                          "publishedAt": "2023-03-07T21:49:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jessecarterMOOSE"
                          },
                          "bodyText": "Seems like most options for that Timestepper are for limiting the timestep, i.e., pick the smallest value of all these constraints, but not enough options to make it grow. Specifying the time points was the solution for this question, but that strategy does work in conjunction with a postprocessor. In the case I mention above my postprocessor is actually trying to increase the timestep, but I'd like to force it to increase more, so I want the largest of the constraints.\n\nYou could write a custom PP that has complex enough logic to sometimes give the MatTimeStepPP value, sometimes have a larger value\n\nThis is what I'm thinking at this point.",
                          "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5233957",
                          "updatedAt": "2023-03-07T22:03:19Z",
                          "publishedAt": "2023-03-07T22:03:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jessecarterMOOSE"
                          },
                          "bodyText": "Maybe if timestep_limiting_postprocessor forces a max dt value, there could be an analogous postprocessor that forces a min dt value? Just a thought.",
                          "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5233983",
                          "updatedAt": "2023-03-07T22:06:59Z",
                          "publishedAt": "2023-03-07T22:06:59Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "but you want to be limiting the pp with this material change? I dont think the pp you have would fit naturally for a \"grower\"",
                          "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5234143",
                          "updatedAt": "2023-03-07T22:25:09Z",
                          "publishedAt": "2023-03-07T22:25:08Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jessecarterMOOSE"
                          },
                          "bodyText": "I'm using an Abaqus UMAT, which returns a value called PNEWDT. If the value is <1 it is suggesting to cut the time step and if >1 it is suggesting to grow the time step. The AbaqusUMATStress class captures this value multiplied by the current dt in a timestep material, so MaterialTimeStepPostprocessor will reflect the minimum suggested time step from all the qp's. This min value may be greater than the current time step, meaning the timestep can grow.",
                          "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5234263",
                          "updatedAt": "2023-03-07T22:40:43Z",
                          "publishedAt": "2023-03-07T22:40:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I would bake all the logic you want in a ParsedPostprocessor and use a PostprocessorDT",
                          "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5234770",
                          "updatedAt": "2023-03-08T00:00:36Z",
                          "publishedAt": "2023-03-08T00:00:35Z",
                          "isAnswer": true
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jessecarterMOOSE"
                          },
                          "bodyText": "I still want to use the iteration adaptive part.",
                          "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5236760",
                          "updatedAt": "2023-03-08T04:38:52Z",
                          "publishedAt": "2023-03-08T04:38:51Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "jessecarterMOOSE"
                  },
                  "bodyText": "On a related note, why is cutback_factor used on a failed solve instead of cutback_factor_at_failure? I thought cutback_failure was for when solves were difficult but did eventually converge.\nLooking closer there's some overlap in the doc strings. Both mention failure, so it's unclear to me what the different situations are.\ncutback_factor: \"Factor to apply to timestep if difficult convergence (if 'optimal_iterations' is specified) or if solution failed\"\ncutback_factor_at_failure: \"Factor to apply to timestep if a time step fails to converge.\"",
                  "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5242307",
                  "updatedAt": "2023-03-08T14:22:58Z",
                  "publishedAt": "2023-03-08T14:22:57Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "oh they're some sort of overlap here.\nThanks the report I ll get a fix",
                          "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5243743",
                          "updatedAt": "2023-03-08T16:22:14Z",
                          "publishedAt": "2023-03-08T16:22:13Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "#23660 has the fix for this.",
                          "url": "https://github.com/idaholab/moose/discussions/23645#discussioncomment-5244438",
                          "updatedAt": "2023-03-08T17:20:20Z",
                          "publishedAt": "2023-03-08T17:20:19Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Quick custom kernel registration / speeding up makefile compile times",
          "author": {
            "login": "EdSheltonUKAEA"
          },
          "bodyText": "Is there a quick way to register a custom kernel?\nThe only way I know at the moment is to run a complete compile of MOOSE with these commands:\ncd ~/projects/YourAppName make clobberall make -j4 ./run_tests -j4\nFor me this takes about an hour each time.  So as a separate issue, I'm sure this is too slow.  How can I speed up the compile process when running the make file?\nI've attached a copy of my makefile (renamed as a .txt file to enable me to attach it).\nMakefile.txt",
          "url": "https://github.com/idaholab/moose/discussions/23637",
          "updatedAt": "2023-03-09T14:34:56Z",
          "publishedAt": "2023-03-07T15:02:55Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nYou should be able to add a file and recompile only the kernels file. Make in the MOOSE ecosystem realizes what objects have already been compiled.\nMy compiles take under 20s most of the time when I've modified or added only a single file.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23637#discussioncomment-5229891",
                  "updatedAt": "2023-03-07T15:10:10Z",
                  "publishedAt": "2023-03-07T15:10:10Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "EdSheltonUKAEA"
                          },
                          "bodyText": "Thanks - how do I do this?  Do I need to edit my make file?\nMy MOOSE ecosystem obviously isn't doing what you describe.",
                          "url": "https://github.com/idaholab/moose/discussions/23637#discussioncomment-5230059",
                          "updatedAt": "2023-03-07T15:24:35Z",
                          "publishedAt": "2023-03-07T15:24:34Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Are you doing make clobberall before making?\nYou do not need to edit the Makefile.\nIf you add a space in \"Diffusion.C\" then make again, does it compile everything?",
                          "url": "https://github.com/idaholab/moose/discussions/23637#discussioncomment-5230723",
                          "updatedAt": "2023-03-07T16:13:04Z",
                          "publishedAt": "2023-03-07T16:13:03Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "mfitzka"
                  },
                  "bodyText": "In my experience it is normally not necessary to do a \"make clobberall\" before recompiling to add new custom kernels. With this command you basically rebuild everything in your app folder from the ground up instead of simply adding your new kernels.\nIf you have more CPU kernels available you can substitute the 4 in \"make -j4\" with as many as you have, which can increase speed but will in the end be a limitation by your hardware.",
                  "url": "https://github.com/idaholab/moose/discussions/23637#discussioncomment-5233476",
                  "updatedAt": "2023-03-07T21:07:56Z",
                  "publishedAt": "2023-03-07T21:07:55Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "no you should not have to do a make clobberall.\nMake clobberall is only necessary if you straight up update MOOSE or libmesh, and even then it s not always the case that it s needed, you can sometimes \"wing it\"",
                          "url": "https://github.com/idaholab/moose/discussions/23637#discussioncomment-5233503",
                          "updatedAt": "2023-03-07T21:10:37Z",
                          "publishedAt": "2023-03-07T21:10:36Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "EdSheltonUKAEA"
                          },
                          "bodyText": "I think that's it.  I've always done \"clobberall\" before \"make\", as I've only ever previously used \"make\" after a MOOSE update.\nBut what seems odd is that when doing a full make for an update, I get lines for kernels in modules which are set to \"NO\" in my makefile.",
                          "url": "https://github.com/idaholab/moose/discussions/23637#discussioncomment-5238652",
                          "updatedAt": "2023-03-08T08:36:35Z",
                          "publishedAt": "2023-03-08T08:28:43Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "So you get other modules by inheritance.\nThe classic one that s unexpected is getting ray tracing because you included heat conduction and it relies on ray tracing for some radiative problems",
                          "url": "https://github.com/idaholab/moose/discussions/23637#discussioncomment-5241581",
                          "updatedAt": "2023-03-08T13:19:15Z",
                          "publishedAt": "2023-03-08T13:19:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "EdSheltonUKAEA"
                          },
                          "bodyText": "Ah that all makes sense now.  Thanks!",
                          "url": "https://github.com/idaholab/moose/discussions/23637#discussioncomment-5242359",
                          "updatedAt": "2023-03-08T14:27:12Z",
                          "publishedAt": "2023-03-08T14:27:12Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Coupling MOOSE with external programm",
          "author": {
            "login": "Fruitwind"
          },
          "bodyText": "Hello!\nI am a new user of Moose and appreciate its capabilities, and would like to extend its application.\nI would like to tightly couple Moose with the PhreeqcRm (an open-source, well-documented, and validated software for extensive geochemical modeling). The PhreeqcRM was developed specifically for coupling it with external transport codes and is supposed to be straightforward to connect.\nWhereas I found the \"MOOSE-wrapped Apps\" page interesting, I struggle with the lack of simple how-to instructions. I see the tight coupling as exchanging selected variables between MOOSE and Phreeqc on every time step for each node while performing necessary syntax transformation and processing via a third-party (MOOSE-based) app.\nSo, my question is: how to do it? Is there a way to export variables to the external code, or is there another (maybe more elegant) way to couple two different syntax apps? I am apologizing if this is a too simple question, I am very new to the MOOSE and to the software development, but very enthusiastic that this coupling would be beneficial for the community.\nThanks,\nElena",
          "url": "https://github.com/idaholab/moose/discussions/23636",
          "updatedAt": "2023-04-29T03:37:58Z",
          "publishedAt": "2023-03-07T13:59:08Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nSo if you want to call PhreeqcRM from MOOSE, you found the right resource. There's an example of doing this here:\nhttps://github.com/neams-th-coe/cardinal\nTo do this, you will need to:\n\ncompile both codes together (there'll be some basic Makefile work to do this)\nwrite some code that transfers a field (variable) from an application to another (examples in cardinal)\n\nNote: tight coupling is, in our jargon, exchanging fields and repeating the time step until convergence. Exchanging once per time step is \"loose coupling\" in our jargon.\nThere are alternatives to our system that are more or less resilient / long term:\n\npreCICE https://precice.org/, used by the UKAEA with MOOSE (https://github.com/aurora-multiphysics, you ll want to contact them to get the code, I dont see it rn)\nfile based coupling. Just output the fields to a format the other code can run, and read them from the other code, alternate running each code with a script. This isnt as clean but it s easier to set up especially if you are running this on a regular computer.\n\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23636#discussioncomment-5230918",
                  "updatedAt": "2023-03-07T16:46:03Z",
                  "publishedAt": "2023-03-07T16:29:09Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Fruitwind"
                          },
                          "bodyText": "Hi!\nThank you very much for your answers, I now take Cardinal as an example and try to learn from it, and will gladly use the chance to continue writing here :)\nSo essentially what I'd love to have is calling Phreeqc from MOOSE copying the parameter matrix for each node, and updating the field -sending it to MOOSE. At this stage, I assume that Phreeqc inputs at each node converge like a flash and no iterations are needed, which is probably a quite strong assumption. So this would be a \"loose\" coupling then. At the same time, I do not want to build new input files for Phreeqc on every time step, but just want to update variables values - and somehow I thought this will shorten the computational time and thus will be called \"tight\" coupling.. Sorry for the misuse of this term.",
                          "url": "https://github.com/idaholab/moose/discussions/23636#discussioncomment-5234212",
                          "updatedAt": "2023-03-07T22:33:52Z",
                          "publishedAt": "2023-03-07T22:33:51Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "No worries. That jargon is not universal anyway, just local to the MOOSE ecosystem.\nOk please let us know how this goes!",
                          "url": "https://github.com/idaholab/moose/discussions/23636#discussioncomment-5234806",
                          "updatedAt": "2023-03-08T00:01:59Z",
                          "publishedAt": "2023-03-08T00:01:59Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Defining a function",
          "author": {
            "login": "alimostafavi24"
          },
          "bodyText": "Hello everyone,\nIs there any way to define a function in MOOSE based on solution values in quadrature points?\nIn my project, defining the function based on DerivativeParsedMaterial will lead to a high error because the value of function is constant inside each element.\nThanks,\nAli",
          "url": "https://github.com/idaholab/moose/discussions/23647",
          "updatedAt": "2023-04-29T03:44:41Z",
          "publishedAt": "2023-03-07T21:11:01Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nWhy dont you want to just use a variable to represent that solution at \"Qp points\"?\nI think the SolutionFunction might be the best shot here for that otherwise\nhttps://mooseframework.inl.gov/source/functions/SolutionFunction.html\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23647#discussioncomment-5233579",
                  "updatedAt": "2023-03-07T21:19:31Z",
                  "publishedAt": "2023-03-07T21:19:30Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Error No standard variable named",
          "author": {
            "login": "TLWise"
          },
          "bodyText": "I used the following, modules/navier_stokes/test/tests/finite_element/ins/lid_driven/ad_lid_driven_stabilized_with_temp_transient.i, to develop a 3D model. When I run the original model, I get the appropriate solution. When using the same model on a 3D geometry I get the following error:\nNo standard variable named velocity found. Did you specify a vector variable when you meant to specify a standard variable?\nIs there a particular reason this is working for the 2D geometry and not the 3D geometry?",
          "url": "https://github.com/idaholab/moose/discussions/23642",
          "updatedAt": "2023-03-07T20:30:22Z",
          "publishedAt": "2023-03-07T19:39:47Z",
          "category": {
            "name": "Q&A Modules: Navier-Stokes"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "TLWise"
                  },
                  "bodyText": "Must use boundary conditions like VectorFunctionDirichletBC, or similar vector valued BCs.",
                  "url": "https://github.com/idaholab/moose/discussions/23642#discussioncomment-5233171",
                  "updatedAt": "2023-03-07T20:30:17Z",
                  "publishedAt": "2023-03-07T20:30:16Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "INS on hold with mesh converted to second order",
          "author": {
            "login": "AdrienWehrle"
          },
          "bodyText": "Hi everyone,\nI have been working on an application to study the viscous deformation of a material with INS. Beforehand, I was working with elastic deformation and only needed a first-order mesh with HEX8 elements.\nNow, with velocity and pressure at different orders, I would need the same mesh but converted to second order.  I came across the second_order argument that I can pass into my mesh object (as visible in my input file) which seemed exactly like what I need. Unfortunately, after a few seconds to compute the Jacobian, no computer resources are being used anymore and the run is on hold. I don't get any error message, and eventually stop the run manually.\nRunning my input file with a simple generated mesh of elements e.g. HEX20 (commented in the input file) works just fine.\nAny idea where that can come from? It seems like something is off with the second-order conversion...\nI could convert my mesh to second order with some lower-level libmesh code but this is what MOOSE can do, so I would like to stick to it!\nThank you a lot in advance for your help!",
          "url": "https://github.com/idaholab/moose/discussions/23570",
          "updatedAt": "2023-04-29T03:45:05Z",
          "publishedAt": "2023-03-01T16:02:29Z",
          "category": {
            "name": "Q&A Modules: Navier-Stokes"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nSo your preconditioning is failing. By commenting it out, I get some progress.\nit s quite slow, it looks like it s stalled, but it eventually moves on. Sadly it never converges.\nTime Step 1, time = 1, dt = 1\n 0 Nonlinear |R| = 9.649127e+05\n\n    Computing Jacobian........                                                           [ 49.80 s] [  267 MB]\n      0 Linear |R| = 9.649127e+05\n      1 Linear |R| = 9.084799e+05\n      2 Linear |R| = 8.897787e+05\n      3 Linear |R| = 8.685389e+05\n      4 Linear |R| = 8.602978e+05\n      5 Linear |R| = 8.491643e+05\n      6 Linear |R| = 8.365738e+05\n      7 Linear |R| = 8.141169e+05\n      8 Linear |R| = 7.998033e+05\n      9 Linear |R| = 7.964132e+05\n     10 Linear |R| = 7.802234e+05\n     11 Linear |R| = 7.608386e+05\n     12 Linear |R| = 7.397272e+05\n     13 Linear |R| = 7.204700e+05\n     14 Linear |R| = 6.812471e+05\n     15 Linear |R| = 6.567327e+05\n     16 Linear |R| = 6.484947e+05\n     17 Linear |R| = 6.435986e+05\n     18 Linear |R| = 6.219077e+05\n     19 Linear |R| = 5.799100e+05\n     20 Linear |R| = 5.315556e+05\n     21 Linear |R| = 4.915147e+05\n     22 Linear |R| = 4.540776e+05\n     23 Linear |R| = 4.099865e+05\n     24 Linear |R| = 3.669807e+05\n     25 Linear |R| = 3.001556e+05\n     26 Linear |R| = 2.420260e+05\n     27 Linear |R| = 1.959621e+05\n     28 Linear |R| = 1.567808e+05\n     29 Linear |R| = 1.322356e+05\n     30 Linear |R| = 1.079851e+05\n     31 Linear |R| = 9.923634e+04\n     32 Linear |R| = 9.540676e+04\n     33 Linear |R| = 8.412448e+04\n     34 Linear |R| = 7.024837e+04\n     35 Linear |R| = 5.412502e+04\n     36 Linear |R| = 4.771700e+04\n     37 Linear |R| = 4.304156e+04\n     38 Linear |R| = 4.022659e+04\n     39 Linear |R| = 3.851984e+04\n     40 Linear |R| = 3.614184e+04\n     41 Linear |R| = 3.458510e+04\n     42 Linear |R| = 3.268941e+04\n     43 Linear |R| = 3.070540e+04\n     44 Linear |R| = 3.042872e+04\n     45 Linear |R| = 2.963951e+04\n     46 Linear |R| = 2.873877e+04\n     47 Linear |R| = 2.785786e+04\n     48 Linear |R| = 2.639781e+04\n     49 Linear |R| = 2.553932e+04\n     50 Linear |R| = 2.414774e+04\n     51 Linear |R| = 2.310876e+04\n     52 Linear |R| = 2.222297e+04\n     53 Linear |R| = 2.118268e+04\n     54 Linear |R| = 2.082891e+04\n     55 Linear |R| = 2.027160e+04\n     56 Linear |R| = 1.953376e+04\n     57 Linear |R| = 1.841990e+04\n     58 Linear |R| = 1.762132e+04\n     59 Linear |R| = 1.742589e+04\n     60 Linear |R| = 1.662532e+04\n     61 Linear |R| = 1.653317e+04\n     62 Linear |R| = 1.643857e+04\n     63 Linear |R| = 1.603051e+04\n     64 Linear |R| = 1.578694e+04\n     65 Linear |R| = 1.534703e+04\n     66 Linear |R| = 1.533355e+04\n     67 Linear |R| = 1.530373e+04\n     68 Linear |R| = 1.473700e+04\n     69 Linear |R| = 1.429712e+04\n     70 Linear |R| = 1.382809e+04\n     71 Linear |R| = 1.331695e+04\n     72 Linear |R| = 1.282590e+04\n     73 Linear |R| = 1.239285e+04\n     74 Linear |R| = 1.217686e+04\n     75 Linear |R| = 1.174498e+04\n     76 Linear |R| = 1.135769e+04\n     77 Linear |R| = 1.095996e+04\n     78 Linear |R| = 1.049957e+04\n     79 Linear |R| = 1.024966e+04\n     80 Linear |R| = 9.959809e+03\n     81 Linear |R| = 9.460647e+03\n     82 Linear |R| = 8.578045e+03\n     83 Linear |R| = 7.869823e+03\n     84 Linear |R| = 7.367182e+03\n     85 Linear |R| = 6.913204e+03\n     86 Linear |R| = 6.088850e+03\n     87 Linear |R| = 5.250878e+03\n     88 Linear |R| = 4.369939e+03\n     89 Linear |R| = 3.769751e+03\n     90 Linear |R| = 3.393198e+03\n     91 Linear |R| = 3.308062e+03\n     92 Linear |R| = 3.167299e+03\n     93 Linear |R| = 2.892434e+03\n     94 Linear |R| = 2.553955e+03\n     95 Linear |R| = 2.282976e+03\n     96 Linear |R| = 2.133528e+03\n     97 Linear |R| = 2.025081e+03\n     98 Linear |R| = 1.938326e+03\n     99 Linear |R| = 1.855594e+03\n    100 Linear |R| = 1.728669e+03\n    101 Linear |R| = 1.591072e+03\n    102 Linear |R| = 1.534149e+03\n    103 Linear |R| = 1.498318e+03\n    104 Linear |R| = 1.465463e+03\n    105 Linear |R| = 1.416459e+03\n    106 Linear |R| = 1.371958e+03\n    107 Linear |R| = 1.321113e+03\n    108 Linear |R| = 1.249941e+03\n    109 Linear |R| = 1.194985e+03\n    110 Linear |R| = 1.152588e+03\n    111 Linear |R| = 1.107416e+03\n    112 Linear |R| = 1.062209e+03\n    113 Linear |R| = 1.005064e+03\n    114 Linear |R| = 9.581028e+02\n    115 Linear |R| = 9.232967e+02\n    116 Linear |R| = 8.964889e+02\n    117 Linear |R| = 8.768560e+02\n    118 Linear |R| = 8.654443e+02\n    119 Linear |R| = 8.471908e+02\n    120 Linear |R| = 8.035362e+02\n    121 Linear |R| = 7.835320e+02\n    122 Linear |R| = 7.702510e+02\n    123 Linear |R| = 7.613471e+02\n    124 Linear |R| = 7.561386e+02\n    125 Linear |R| = 7.377805e+02\n    126 Linear |R| = 7.195058e+02\n    127 Linear |R| = 7.052307e+02\n    128 Linear |R| = 6.984043e+02\n    129 Linear |R| = 6.905484e+02\n    130 Linear |R| = 6.753441e+02\n    131 Linear |R| = 6.418160e+02\n    132 Linear |R| = 6.056253e+02\n    133 Linear |R| = 5.769659e+02\n    134 Linear |R| = 5.542915e+02\n    135 Linear |R| = 5.407478e+02\n    136 Linear |R| = 5.270740e+02\n    137 Linear |R| = 5.105799e+02\n    138 Linear |R| = 4.942780e+02\n    139 Linear |R| = 4.666186e+02\n    140 Linear |R| = 4.407491e+02\n    141 Linear |R| = 4.237599e+02\n    142 Linear |R| = 3.988148e+02\n    143 Linear |R| = 3.805127e+02\n    144 Linear |R| = 3.609736e+02\n    145 Linear |R| = 3.362626e+02\n    146 Linear |R| = 3.110565e+02\n    147 Linear |R| = 2.932049e+02\n    148 Linear |R| = 2.842103e+02\n    149 Linear |R| = 2.713694e+02\n    150 Linear |R| = 2.458900e+02\n    151 Linear |R| = 2.288432e+02\n    152 Linear |R| = 2.201769e+02\n    153 Linear |R| = 2.128094e+02\n    154 Linear |R| = 2.054833e+02\n    155 Linear |R| = 1.957295e+02\n    156 Linear |R| = 1.866682e+02\n    157 Linear |R| = 1.804425e+02\n    158 Linear |R| = 1.765332e+02\n    159 Linear |R| = 1.729278e+02\n    160 Linear |R| = 1.654225e+02\n    161 Linear |R| = 1.593431e+02\n    162 Linear |R| = 1.519460e+02\n    163 Linear |R| = 1.454851e+02\n    164 Linear |R| = 1.419426e+02\n    165 Linear |R| = 1.387328e+02\n    166 Linear |R| = 1.346149e+02\n    167 Linear |R| = 1.279908e+02\n    168 Linear |R| = 1.192901e+02\n    169 Linear |R| = 1.145017e+02\n    170 Linear |R| = 1.113390e+02\n    171 Linear |R| = 1.086403e+02\n    172 Linear |R| = 1.064604e+02\n    173 Linear |R| = 1.031118e+02\n    174 Linear |R| = 1.003056e+02\n    175 Linear |R| = 9.838820e+01\n    176 Linear |R| = 9.589265e+01\n    177 Linear |R| = 9.433889e+01\n    178 Linear |R| = 9.300322e+01\n    179 Linear |R| = 9.124034e+01\n    180 Linear |R| = 8.686447e+01\n    181 Linear |R| = 8.444467e+01\n    182 Linear |R| = 8.368949e+01\n    183 Linear |R| = 8.216528e+01\n    184 Linear |R| = 7.984416e+01\n    185 Linear |R| = 7.751164e+01\n    186 Linear |R| = 7.603297e+01\n    187 Linear |R| = 7.408958e+01\n    188 Linear |R| = 7.301478e+01\n    189 Linear |R| = 7.102873e+01\n    190 Linear |R| = 7.001659e+01\n    191 Linear |R| = 6.865305e+01\n    192 Linear |R| = 6.593314e+01\n    193 Linear |R| = 6.213374e+01\n    194 Linear |R| = 5.943365e+01\n    195 Linear |R| = 5.785247e+01\n    196 Linear |R| = 5.600554e+01\n    197 Linear |R| = 5.453322e+01\n    198 Linear |R| = 5.308795e+01\n    199 Linear |R| = 5.117584e+01\n    200 Linear |R| = 4.814336e+01\n    201 Linear |R| = 4.591707e+01\n    202 Linear |R| = 4.467883e+01\n    203 Linear |R| = 4.209664e+01\n    204 Linear |R| = 4.029718e+01\n    205 Linear |R| = 3.901124e+01\n    206 Linear |R| = 3.782749e+01\n    207 Linear |R| = 3.560136e+01\n    208 Linear |R| = 3.309919e+01\n    209 Linear |R| = 3.116082e+01\n    210 Linear |R| = 3.019461e+01\n    211 Linear |R| = 2.978197e+01\n    212 Linear |R| = 2.906562e+01\n    213 Linear |R| = 2.679234e+01\n    214 Linear |R| = 2.486787e+01\n    215 Linear |R| = 2.383209e+01\n    216 Linear |R| = 2.323799e+01\n    217 Linear |R| = 2.279399e+01\n    218 Linear |R| = 2.227532e+01\n    219 Linear |R| = 2.117646e+01\n    220 Linear |R| = 2.004059e+01\n    221 Linear |R| = 1.910800e+01\n    222 Linear |R| = 1.861775e+01\n    223 Linear |R| = 1.816517e+01\n    224 Linear |R| = 1.764476e+01\n    225 Linear |R| = 1.712869e+01\n    226 Linear |R| = 1.627988e+01\n    227 Linear |R| = 1.540058e+01\n    228 Linear |R| = 1.477298e+01\n    229 Linear |R| = 1.434217e+01\n    230 Linear |R| = 1.392472e+01\n    231 Linear |R| = 1.353750e+01\n    232 Linear |R| = 1.295071e+01\n    233 Linear |R| = 1.259915e+01\n    234 Linear |R| = 1.230281e+01\n    235 Linear |R| = 1.211274e+01\n    236 Linear |R| = 1.195102e+01\n    237 Linear |R| = 1.169310e+01\n    238 Linear |R| = 1.131498e+01\n    239 Linear |R| = 1.071288e+01\n    240 Linear |R| = 9.734177e+00\n    241 Linear |R| = 9.389857e+00\n    242 Linear |R| = 9.211516e+00\n    243 Linear |R| = 8.951693e+00\n    244 Linear |R| = 8.673472e+00\n    245 Linear |R| = 8.156681e+00\n    246 Linear |R| = 7.902941e+00\n    247 Linear |R| = 7.767071e+00\n    248 Linear |R| = 7.617172e+00\n    249 Linear |R| = 7.525572e+00\n    250 Linear |R| = 7.418225e+00\n    251 Linear |R| = 7.262558e+00\n    252 Linear |R| = 7.002737e+00\n    253 Linear |R| = 6.670085e+00\n    254 Linear |R| = 6.477127e+00\n    255 Linear |R| = 6.243982e+00\n    256 Linear |R| = 5.960057e+00\n    257 Linear |R| = 5.772364e+00\n    258 Linear |R| = 5.524780e+00\n    259 Linear |R| = 5.319289e+00\n    260 Linear |R| = 5.185796e+00\n    261 Linear |R| = 5.033500e+00\n    262 Linear |R| = 4.848054e+00\n    263 Linear |R| = 4.582003e+00\n    264 Linear |R| = 4.309932e+00\n    265 Linear |R| = 4.157140e+00\n    266 Linear |R| = 3.968234e+00\n    267 Linear |R| = 3.849262e+00\n    268 Linear |R| = 3.744651e+00\n    269 Linear |R| = 3.631541e+00\n    270 Linear |R| = 3.485162e+00\n    271 Linear |R| = 3.357093e+00\n    272 Linear |R| = 3.254352e+00\n    273 Linear |R| = 3.159117e+00\n    274 Linear |R| = 3.065650e+00\n    275 Linear |R| = 2.964147e+00\n    276 Linear |R| = 2.845482e+00\n    277 Linear |R| = 2.731465e+00\n    278 Linear |R| = 2.648347e+00\n    279 Linear |R| = 2.556385e+00\n    280 Linear |R| = 2.474181e+00\n    281 Linear |R| = 2.386233e+00\n    282 Linear |R| = 2.291378e+00\n    283 Linear |R| = 2.229858e+00\n    284 Linear |R| = 2.155831e+00\n    285 Linear |R| = 2.075311e+00\n    286 Linear |R| = 2.013548e+00\n    287 Linear |R| = 1.907614e+00\n    288 Linear |R| = 1.799636e+00\n    289 Linear |R| = 1.749351e+00\n    290 Linear |R| = 1.695522e+00\n    291 Linear |R| = 1.669935e+00\n    292 Linear |R| = 1.626489e+00\n    293 Linear |R| = 1.577064e+00\n    294 Linear |R| = 1.552528e+00\n    295 Linear |R| = 1.514183e+00\n    296 Linear |R| = 1.484038e+00\n    297 Linear |R| = 1.448852e+00\n    298 Linear |R| = 1.387841e+00\n    299 Linear |R| = 1.332219e+00\n    300 Linear |R| = 1.258347e+00\n    301 Linear |R| = 1.209693e+00\n    302 Linear |R| = 1.162810e+00\n    303 Linear |R| = 1.127644e+00\n    304 Linear |R| = 1.109404e+00\n    305 Linear |R| = 1.065408e+00\n    306 Linear |R| = 1.032888e+00\n    307 Linear |R| = 1.013135e+00\n    308 Linear |R| = 9.956087e-01\n    309 Linear |R| = 9.738747e-01\n    310 Linear |R| = 9.649077e-01\n 1 Nonlinear |R| = 9.457580e+05\netc\n\nWith the equivalent MOOSE-made mesh in terms of elements (x50 more elements than the one you have checked in though), it s faster and converges. But then when you make it the same dimension as your simulation mesh (1k m dimension roughly), you get similar bad convergence.\nSo this is not really a MOOSE mesh vs external mesh problem or a second order mesh problem.\nIt s more a convergence issue with some PCs and a very slow preconditioning once the Jacobian has been computed with others.\nI would try to see if a smaller dimension system helps (using a TransformGenerator to scale the mesh for example). Then we ll have to figure out a working preconditioner, possibly using a field split.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23570#discussioncomment-5170320",
                  "updatedAt": "2023-03-01T19:20:56Z",
                  "publishedAt": "2023-03-01T19:20:56Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "LU dies\nTime Step 0, time = 0\n\nTime Step 1, time = 1, dt = 1\n 0 Nonlinear |R| = 9.658418e+05\n\n    Computing Jacobian........                                                           [ 49.41 s] [  264 MB]\n      0 Linear |R| = 9.658418e+05\n  Linear solve did not converge due to DIVERGED_PC_FAILED iterations 0\n                 PC failed due to FACTOR_NUMERIC_ZEROPIVOT \nNonlinear solve did not converge due to DIVERGED_FNORM_NAN iterations 0\n Solve Did NOT Converge!\n  Finished Solving              \n\nI think you should consider SUPG stabilization at this point, depending on the Reynolds number. What Re do you expect?\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/23570#discussioncomment-5170398",
                          "updatedAt": "2023-03-01T19:30:42Z",
                          "publishedAt": "2023-03-01T19:30:41Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "mumps LU makes some progress but it s not quite working yet\n  petsc_options_iname = '-pc_type -pc_factor_shift -pc_factor_mat_solver_package'\n  petsc_options_value = 'lu        NONZERO mumps'",
                          "url": "https://github.com/idaholab/moose/discussions/23570#discussioncomment-5170494",
                          "updatedAt": "2023-03-01T19:44:30Z",
                          "publishedAt": "2023-03-01T19:44:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "AdrienWehrle"
                          },
                          "bodyText": "Thank you so much for your help on this @GiudGiud, once again! My material at the moment is ice, so very low Reynolds number like e.g. 3x10-11!",
                          "url": "https://github.com/idaholab/moose/discussions/23570#discussioncomment-5176131",
                          "updatedAt": "2023-03-02T08:34:15Z",
                          "publishedAt": "2023-03-02T08:34:14Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "AdrienWehrle"
                          },
                          "bodyText": "I'm investigating and find convergence having tighter boundary conditions, investigating more!",
                          "url": "https://github.com/idaholab/moose/discussions/23570#discussioncomment-5176449",
                          "updatedAt": "2023-03-02T09:07:05Z",
                          "publishedAt": "2023-03-02T09:07:04Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@lindsayad @snschune @tanoret do we have experience with extremely low Reynolds? any tips?",
                          "url": "https://github.com/idaholab/moose/discussions/23570#discussioncomment-5180285",
                          "updatedAt": "2023-03-02T15:53:30Z",
                          "publishedAt": "2023-03-02T15:53:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Are you certain that the problem is nonsingular?",
                          "url": "https://github.com/idaholab/moose/discussions/23570#discussioncomment-5181773",
                          "updatedAt": "2023-03-02T17:47:18Z",
                          "publishedAt": "2023-03-02T17:47:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "If you have ~1000 dofs or less, please run with -pc_type svd -pc_svd_monitor and let's see what the condition number is and whether there are singular values.",
                          "url": "https://github.com/idaholab/moose/discussions/23570#discussioncomment-5181791",
                          "updatedAt": "2023-03-02T17:50:11Z",
                          "publishedAt": "2023-03-02T17:50:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "So I took a look and reduced the problem down to 10k dofs\nTime Step 0, time = 0\n\nTime Step 1, time = 1, dt = 1\n 0 Nonlinear |R| = 5.870875e+02\n      SVD: condition number 6.572444349720e+03, 0 of 10637 singular values are (nearly) zero\n      SVD: smallest singular values: 1.877321233448e-01 2.094433152505e-01 2.199564233013e-01 2.208569340486e-01 2.485050990591e-01\n      SVD: largest singular values : 1.226862986416e+03 1.227067137610e+03 1.231996555463e+03 1.233617991869e+03 1.233858933338e+03\n      0 Linear |R| = 5.870875e+02\n      1 Linear |R| = 5.846758e-10\n 1 Nonlinear |R| = 3.110592e+03\n      SVD: condition number 4.164648575293e+06, 0 of 10637 singular values are (nearly) zero\n      SVD: smallest singular values: 1.976190079212e-04 3.092570770496e-04 2.563092629971e-03 3.151124043481e-03 7.746795084596e-03\n      SVD: largest singular values : 8.022123327959e+02 8.193238137011e+02 8.199100923449e+02 8.222966084831e+02 8.230137197898e+02\n      0 Linear |R| = 3.110592e+03\n      1 Linear |R| = 2.683588e-10\n 2 Nonlinear |R| = 4.814716e+03\n      SVD: condition number 1.376643023645e+08, 0 of 10637 singular values are (nearly) zero\n      SVD: smallest singular values: 6.045237111331e-06 5.642258089507e-05 2.259690561512e-04 3.233848345037e-04 3.941845523962e-04\n      SVD: largest singular values : 7.757905443426e+02 7.758180246716e+02 8.126563325449e+02 8.320516468398e+02 8.322133495593e+02\n      0 Linear |R| = 4.814716e+03\n      1 Linear |R| = 1.095348e-09\n 3 Nonlinear |R| = 2.893406e+05\n      SVD: condition number 6.294350009499e+08, 0 of 10637 singular values are (nearly) zero\n      SVD: smallest singular values: 1.041685352391e-05 6.499810787961e-05 8.790019586545e-05 9.750322588867e-05 1.982058835740e-04\n      SVD: largest singular values : 6.471454149845e+03 6.556732115690e+03 6.556732120764e+03 6.556732202647e+03 6.556732207717e+03\n      0 Linear |R| = 2.893406e+05\n      1 Linear |R| = 7.953486e-09\n 4 Nonlinear |R| = 4.160647e+05\n      SVD: condition number 3.710111158441e+08, 0 of 10637 singular values are (nearly) zero\n      SVD: smallest singular values: 1.476591358900e-05 2.508460285394e-04 4.190902889112e-04 7.508517789246e-04 1.541649495969e-03\n      SVD: largest singular values : 5.255969324445e+03 5.478317252916e+03 5.478317456393e+03 5.478317861851e+03 5.478318077111e+03\n      0 Linear |R| = 4.160647e+05\n      1 Linear |R| = 4.978221e-08\n 5 Nonlinear |R| = 9.127344e+07\n      SVD: condition number 1.322867449015e+09, 0 of 10637 singular values are (nearly) zero\n      SVD: smallest singular values: 8.514291937852e-05 2.202291253434e-04 2.842230035648e-04 5.814224479103e-04 6.569247681633e-04\n      SVD: largest singular values : 1.090769029653e+05 1.090960862744e+05 1.090961679202e+05 1.126324160580e+05 1.126327965600e+05\n      0 Linear |R| = 9.127344e+07\n      1 Linear |R| = 1.184159e-06\n 6 Nonlinear |R| = 2.284092e+07\n      SVD: condition number 2.572719828600e+08, 0 of 10637 singular values are (nearly) zero\n      SVD: smallest singular values: 2.190243036608e-04 4.396641746804e-04 6.049884283724e-04 9.450927421153e-04 1.234660191946e-03\n      SVD: largest singular values : 5.460490359671e+04 5.462793094031e+04 5.462967772657e+04 5.634746092936e+04 5.634881689735e+04\n      0 Linear |R| = 2.284092e+07\n      1 Linear |R| = 3.004979e-07\n 7 Nonlinear |R| = 5.712706e+06\n\nthe conditioning is pretty good at first then seems to get worse.\nNo singular values",
                          "url": "https://github.com/idaholab/moose/discussions/23570#discussioncomment-5198944",
                          "updatedAt": "2023-03-04T01:42:17Z",
                          "publishedAt": "2023-03-04T01:42:16Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Oh, why is Newmark-Beta time integration being used? There are no second time derivatives in the equations. I would try the default time integrator, implicit Euler, or BDF2 if second order accuracy is desired",
                          "url": "https://github.com/idaholab/moose/discussions/23570#discussioncomment-5211231",
                          "updatedAt": "2023-03-06T03:12:39Z",
                          "publishedAt": "2023-03-06T03:12:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "One thing that is very different between the generated mesh and the file mesh is the length scale. You have dimensions of ~1e3-1e4 in your file mesh but your generated mesh is of order 1.\nWhat are you hoping to observe in this simulation? You have Dirichlet 0 values for velocity on the bottom boundary; as far as I can tell there is no driving force for flow anywhere. Are you just hoping to see a quiescent velocity field with a pressure profile balanced by gravity?",
                          "url": "https://github.com/idaholab/moose/discussions/23570#discussioncomment-5218161",
                          "updatedAt": "2023-03-06T16:47:03Z",
                          "publishedAt": "2023-03-06T16:47:02Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "nodal - FV variable coupling",
          "author": {
            "login": "federicohattab"
          },
          "bodyText": "Hello,\nI am a new user.\nI am trying to model the diffusion of a specie through a pipe and into the fliud inside the pipe.\nThe geometry is a 2D rectangle divided into 2 subodmains, representing half axial section of the pipe (wall + fluid domain). The fluid domain is modeled with the NavierStokesFV module. For the solid domain I am using the diffusion, time derivative and some nodal kernels to take into account trapping and releasing of the specie. Inside the NavierStokesFV module the specie is represented by the scalar equation.\nI am having difficulties in defining the coupling of the specie concentration at the interface between the fluid and solid domain, because on one side I have a nodal variable while on the other side a FV variable.\nAny tip or general direction on how to achieve the coupling?\nThank you",
          "url": "https://github.com/idaholab/moose/discussions/23494",
          "updatedAt": "2023-03-07T16:52:45Z",
          "publishedAt": "2023-02-21T11:00:48Z",
          "category": {
            "name": "Q&A Modules: Navier-Stokes"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nFor now we cant couple in the same mesh finite volume and finite element.\nThis is on our tasks for this year, getting both FE-FV coupling in the system and the option to have two numerical systems solved together on the same mesh. There's a lot of progress on the second task, you could already attempt to do it that way (and do fixed point iterations between the two systems).\nIf you're not keen on developing, you should consider using a multiapp approach. You can have two applications, duplicate the mesh, and transfer the fields from one app to the other app in an auxiliary field of the compatible finite element/volume type. There will be some projection error but you can use a renormalization to be globally conservative.\nSee this tutorial for more on multiapps & transfers\nhttps://mooseframework.inl.gov/getting_started/examples_and_tutorials/tutorial02_multiapps/presentation/index.html#/\nhttps://mooseframework.inl.gov/syntax/MultiApps/index.html\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/23494#discussioncomment-5063124",
                  "updatedAt": "2023-02-21T11:30:22Z",
                  "publishedAt": "2023-02-21T11:30:21Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "federicohattab"
                          },
                          "bodyText": "Thank you for the reply. Would it be better to do also the fluid domain with FE and simulate the specie with a time derivative, diffusion and advection kernel? (I am not sure this is possible since there is a FV scalar advection kernel but not a FE one)",
                          "url": "https://github.com/idaholab/moose/discussions/23494#discussioncomment-5076735",
                          "updatedAt": "2023-02-22T12:37:26Z",
                          "publishedAt": "2023-02-22T12:37:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You can do that.\nWe have not added the FE scalar advection kernel but they are very similar to the energy advection kernel if you want to try",
                          "url": "https://github.com/idaholab/moose/discussions/23494#discussioncomment-5078489",
                          "updatedAt": "2023-02-22T15:33:01Z",
                          "publishedAt": "2023-02-22T15:33:00Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "federicohattab"
                          },
                          "bodyText": "thank you, the implementation of an advection kernel is straight forward indeed. I am using the INSADEnergyAdvection as a reference. It works fine if I input manually a velocity vector in the input (like in the tutorial Example2), however I am having difficulties in retrieving the fluid velocity vector inside the Kernel. What is the method to get the INS fluid velocity vector?",
                          "url": "https://github.com/idaholab/moose/discussions/23494#discussioncomment-5081119",
                          "updatedAt": "2023-02-22T19:35:47Z",
                          "publishedAt": "2023-02-22T19:35:46Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "INSAD is using material properties for residuals. You ll want to have a look at adding a residual that way too, in order to be able to do the SUPG stabilization",
                          "url": "https://github.com/idaholab/moose/discussions/23494#discussioncomment-5081554",
                          "updatedAt": "2023-02-22T20:27:02Z",
                          "publishedAt": "2023-02-22T20:27:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "federicohattab"
                          },
                          "bodyText": "Thanks, seems to work great, however I am now struggling in obtaining a conservation balance for the scalar in the fluid field. I am sorry if the question is obvious, but how would you verify the conservation of a scalar at the boundary of a 2D rectangular domain?\nRight now, I am using a simplified case where the fluid is still (u = 0, v = 0) and there is a DirichletBC on the left, right and top boundaries equal to 10, 1 and 1 respectively (for the scalar). On the bottom boundary there is a NeumannBC for the scalar (i.e. a wall). I can't manage to obtain a net scalar flux across the boudaries equal to zero (the volume reached saturation since the overall concentration in the domain is constant).\nFor computing the diffusive fluxes at the interface I am usign the SideDiffusiveFluxIntegral. It is not clear to me what is the best option to get the advective flux (possibly the \"VolumetricFlowRate\" postprocessor, specifying as advected variable my scalar).\nThank you for the help!",
                          "url": "https://github.com/idaholab/moose/discussions/23494#discussioncomment-5189132",
                          "updatedAt": "2023-03-03T11:14:01Z",
                          "publishedAt": "2023-03-03T11:14:00Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You can use the VolumetricFlowRate postprocessors on boundaries around the domain to evaluation the conservation. It will let you specify which quantity is being advected and what the advecting velocity is.\nHowever, this is looking at surface balance and the FE method is conservative over volumes.\nTo check that, we implemented volumetric conservation postprocessors, such as this one\nhttps://mooseframework.inl.gov/source/postprocessors/INSElementIntegralEnergyAdvection.html\nYou should be able to adapt it for scalar quantities.\nThe SideDiffusiveFluxIntegral is not going to be valid for all types of diffusive fluxes. You ll need to double check the definition of the diffusive flux in your kernel and in the postprocessor.",
                          "url": "https://github.com/idaholab/moose/discussions/23494#discussioncomment-5199199",
                          "updatedAt": "2023-03-04T02:57:42Z",
                          "publishedAt": "2023-03-04T02:57:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "federicohattab"
                          },
                          "bodyText": "Thank you. I adapted the linked postprocessor. So it is normal that the outlet VolumetricFlowRate is off by a bit (e.g. 0.5 - 1%) compared to the inlet VolumetricFlowRate, even though the volumetric conservation postprocessor returns a basically zero (1e-17) value.\nTo my understanding the SideDiffusiveFluxIntegral should be valid for the \"ADHeatConduction\" kernel (correct me if wrong please), but I am not sure about the \"CoefDiffusion\" one",
                          "url": "https://github.com/idaholab/moose/discussions/23494#discussioncomment-5209125",
                          "updatedAt": "2023-03-05T20:34:49Z",
                          "publishedAt": "2023-03-05T20:34:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Yes it s normal. Does it get better with refinement?",
                          "url": "https://github.com/idaholab/moose/discussions/23494#discussioncomment-5209895",
                          "updatedAt": "2023-03-06T00:00:08Z",
                          "publishedAt": "2023-03-06T00:00:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "federicohattab"
                          },
                          "bodyText": "I verified that the quantity of scalar entering the domain due to the DirichletBC heavily depends on the resolution of the mesh (it has a variation of about 20%).\nUsing adaptive mesh doesn't change this, but causes the outlet VolumetricFlowRate to be very similar to the inlet one (given the indicator I used shown below, this is less true for longer simulations, as the mesh tends to be coarser due to the system being stationary).\n\nTo have a proper indication of the quantities entering/leaving my domain I need to develop a volumetric conservation postprocessor only for the volumes at the boundaries I guess (I didn't find a similar postprocessor in the documentation).\nFor verifying the diffusion term, is it ok to used the SideDiffusiveFluxIntegral if my diffusion kernel is a modified version of \"ADHeatConduction\" containing only the quantity being diffused and the diffusivity?\n\nThank you\n[Adaptivity]\n   max_h_level = 3\n   marker = marker\n   [Indicators]\n     [indicator]\n       type = GradientJumpIndicator\n       variable = myscalar\n     []\n   []\n   [Markers]\n     [marker]\n       type = ErrorFractionMarker\n       indicator = indicator\n       refine = 0.2\n       coarsen = 0.2\n     []\n   []\n []",
                          "url": "https://github.com/idaholab/moose/discussions/23494#discussioncomment-5215196",
                          "updatedAt": "2023-03-06T23:04:07Z",
                          "publishedAt": "2023-03-06T12:19:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You may want to make the refinement permanent instead of using adaptivity. To do that you can use a RefineBlockGenerator in targetted blocks.\nIf you care about conserving an inlet flux, you should consider a Neumann boundary condition.\n\n\nA volumetric conservation postprocessor will not show you the quantities entering or leaving a block. It will just compute the advection term contribution (with or without diffusion, depending on how you write it) to the balance, which can tell you about the importance of other terms (if you have a reaction term for example)\n\n\nWhat kind of boundary are you using the SideDiffusiveFlux on ? Dirichlet ? No BC?",
                          "url": "https://github.com/idaholab/moose/discussions/23494#discussioncomment-5221275",
                          "updatedAt": "2023-03-06T22:54:37Z",
                          "publishedAt": "2023-03-06T22:54:37Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}