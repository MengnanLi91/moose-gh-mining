{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMS0wOS0yMVQwNzo0OToxMC0wNTowMM4ANrIc"
    },
    "edges": [
      {
        "node": {
          "title": "optimization of an auxiliary kernel for a neural network",
          "author": {
            "login": "aiskhak"
          },
          "bodyText": "I developed an auxiliary kernel that predicts turbulent viscosity at each quadrature point. The prediction is performed by a neural network (torchscript model). Everything works fine, but unfortunately, this slows down the code ~50 times. The workflow is organized in the following way:\nloop 1 over elements:\n-- Momentum Kernel (solves the momentum equation for fluid dynamics);\n---- Material Property (sets all material properties, including turbulent viscosity);\nloop 2 over quadrature points:\n-------- Auxiliary Kernel (predicts and assigns turbulent viscosity through an auxiliary variable);\nI want to optimize my framework. Ideally, I want to predict turbulent viscosity for all quadrature points simultaneously, but it seems impossible since the quadrature points are only accessible within a particular element. I.e., I cannot predict them before loop 1.\nThe next way to make it faster is at least to predict simultaneously for all quadrature points within one element. I.e., before loop 2 and then just assign the values within this loop. Let's say I have QUAD9 mesh (9 quadratures for each element). This would make my code ~9 times faster by predicting 9 points simultaneously. However, I am not sure what type of object I can develop for this purpose.\nI would be glad to hear some suggestions from you.",
          "url": "https://github.com/idaholab/moose/discussions/18892",
          "updatedAt": "2023-04-24T18:34:51Z",
          "publishedAt": "2021-09-22T00:55:13Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nIsn't loop 1 over quadrature points as well?\nWhat kind of objects do you need to find into the neural network? velocity and pressure variables? some material properties as well or just variables?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/18892#discussioncomment-1366839",
                  "updatedAt": "2023-04-24T18:34:52Z",
                  "publishedAt": "2021-09-22T02:11:40Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aiskhak"
                          },
                          "bodyText": "Yes, probably I did not write this correctly.\nMaterial property kernel does the following:\ncomputeProperties() function iteratively (over each quadrature point) assigns:\nfor (_qp = 0; _qp < _qrule->n_points(); _qp++)\n    _turbulent_viscosity[_qp] = _turb_visc_auxvar[_qp];\n\nwhere _turb_visc_auxvar[_qp] comes from the developed auxiliary kernel. This point-wise prediction is very inefficient.",
                          "url": "https://github.com/idaholab/moose/discussions/18892#discussioncomment-1370404",
                          "updatedAt": "2021-09-22T15:52:37Z",
                          "publishedAt": "2021-09-22T15:52:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aiskhak"
                          },
                          "bodyText": "I might use any type of input feature in my neural network. But currently, I use velocity gradients.",
                          "url": "https://github.com/idaholab/moose/discussions/18892#discussioncomment-1370407",
                          "updatedAt": "2021-09-22T15:53:42Z",
                          "publishedAt": "2021-09-22T15:53:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "you could overwrite the computeProperties routine in your material property to handle all the qps simulatenously. This is not very hard to do",
                          "url": "https://github.com/idaholab/moose/discussions/18892#discussioncomment-1370485",
                          "updatedAt": "2023-04-24T18:34:52Z",
                          "publishedAt": "2021-09-22T16:06:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aiskhak"
                          },
                          "bodyText": "There are several other properties calculated in computeProperties (using different methods)... Not sure what you mean by overwrite.",
                          "url": "https://github.com/idaholab/moose/discussions/18892#discussioncomment-1370515",
                          "updatedAt": "2023-04-24T18:34:52Z",
                          "publishedAt": "2021-09-22T16:09:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "like this is a virtual function and you override it with your derived class s implementation",
                          "url": "https://github.com/idaholab/moose/discussions/18892#discussioncomment-1370525",
                          "updatedAt": "2023-04-24T18:34:54Z",
                          "publishedAt": "2021-09-22T16:11:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "note that you are computing this in an auxvariable then moving it to a material. You could just compute this directly in the material.",
                          "url": "https://github.com/idaholab/moose/discussions/18892#discussioncomment-1371219",
                          "updatedAt": "2023-04-24T18:34:54Z",
                          "publishedAt": "2021-09-22T18:42:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aiskhak"
                          },
                          "bodyText": "Yes, I tried to do this, but something went wrong there... The code behaves very differently comparing to the point-wise prediction. Maybe it is just a bug. Thanks!",
                          "url": "https://github.com/idaholab/moose/discussions/18892#discussioncomment-1371554",
                          "updatedAt": "2023-04-24T18:34:54Z",
                          "publishedAt": "2021-09-22T20:02:32Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "YaqiWang"
                  },
                  "bodyText": "Parallelization in MOOSE is done through domain decomposition. You can try letting the aux kernel execute_on at nonlinear to avoid its evaluating during linear solve. This will probably degrade the Newton convergence. Your understanding on how residual is evaluated in MOOSE seems not accurate. You may want to check out FEProblemBase::computeResidualTags function. Note that aux kernels and kernels are evaluated in separate element loops.",
                  "url": "https://github.com/idaholab/moose/discussions/18892#discussioncomment-1370371",
                  "updatedAt": "2023-04-24T18:34:54Z",
                  "publishedAt": "2021-09-22T15:45:38Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aiskhak"
                          },
                          "bodyText": "I assume that cannot do execute_on at nonlinear since it will probably affect the accuracy of the solution (I am interested in transient analysis, for steady-state it would be ok).\nYes, you are right, the auxiliary kernel has its own loop over quadrature points, my bad. My question is still valid - this loop is point-wise and is crazy slow since forward propagation through a deep neural network is expensive.",
                          "url": "https://github.com/idaholab/moose/discussions/18892#discussioncomment-1370430",
                          "updatedAt": "2023-04-24T18:34:55Z",
                          "publishedAt": "2021-09-22T15:57:34Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Execute_on nonlinear will not affect the accuracy, only possible the convergence",
                          "url": "https://github.com/idaholab/moose/discussions/18892#discussioncomment-1370477",
                          "updatedAt": "2023-04-24T18:34:55Z",
                          "publishedAt": "2021-09-22T16:04:53Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aiskhak"
                          },
                          "bodyText": "ok, thanks, I will check this",
                          "url": "https://github.com/idaholab/moose/discussions/18892#discussioncomment-1370484",
                          "updatedAt": "2023-04-24T18:34:55Z",
                          "publishedAt": "2021-09-22T16:05:56Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Failed Installation on HPC Cluster with VTK",
          "author": {
            "login": "DamynChipman"
          },
          "bodyText": "Bug Description\n\nI am attempting to install MOOSE on my university's cluster for local usage (i.e., not cluster wide). I am following the instructions listed at HPC Cluster.\nSteps to Reproduce\n\nThe issue seems to appear after running ./scripts/update_and_rebuild_petsc.sh --download-vtk. After appearing to successfully run the build script for PETSc, I run make PETSC_DIR=/bsuhome/dchipman/packages/moose/moose/scripts/../petsc PETSC_ARCH=arch-moose check and get the following output:\n(base) (11:59:21) [dchipman@borah-login petsc] >>> make PETSC_DIR=/bsuhome/dchipman/packages/moose/moose/scripts/../petsc PETSC_ARCH=arch-moose check\nRunning check examples to verify correct installation\nUsing PETSC_DIR=/bsuhome/dchipman/packages/moose/moose/scripts/../petsc and PETSC_ARCH=arch-moose\n*******************Error detected during compile or link!*******************\nSee http://www.mcs.anl.gov/petsc/documentation/faq.html\n/bsuhome/dchipman/packages/moose/moose/petsc/src/snes/tutorials ex19\n*********************************************************************************\nmpicc -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -g -O  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -g -O    -I/bsuhome/dchipman/packages/moose/moose/petsc/include -I/bsuhome/dchipman/packages/moose/moose/petsc/arch-moose/include     ex19.c  -Wl,-rpath,/bsuhome/dchipman/packages/moose/moose/scripts/../petsc/arch-moose/lib -L/bsuhome/dchipman/packages/moose/moose/scripts/../petsc/arch-moose/lib -Wl,-rpath,/bsuhome/dchipman/packages/moose/moose/petsc/arch-moose/lib -L/bsuhome/dchipman/packages/moose/moose/petsc/arch-moose/lib -Wl,-rpath,/cm/shared/apps/mpich/ge/gcc/64/3.3.2/lib -L/cm/shared/apps/mpich/ge/gcc/64/3.3.2/lib -Wl,-rpath,/cm/shared/apps/blas/gcc/3.8.0/lib64 -L/cm/shared/apps/blas/gcc/3.8.0/lib64 -Wl,-rpath,/cm/shared/apps/slurm/current/lib64 -L/cm/shared/apps/slurm/current/lib64 -Wl,-rpath,/cm/shared/apps/gcc/8.2.0/lib/gcc/x86_64-pc-linux-gnu/8.2.0 -L/cm/shared/apps/gcc/8.2.0/lib/gcc/x86_64-pc-linux-gnu/8.2.0 -Wl,-rpath,/cm/shared/apps/gcc/8.2.0/lib64 -L/cm/shared/apps/gcc/8.2.0/lib64 -Wl,-rpath,/cm/shared/apps/lapack/gcc/64/3.8.0 -L/cm/shared/apps/lapack/gcc/64/3.8.0 -Wl,-rpath,/cm/shared/apps/slurm/current/lib64/slurm -L/cm/shared/apps/slurm/current/lib64/slurm -Wl,-rpath,/cm/shared/apps/gcc/8.2.0/lib -L/cm/shared/apps/gcc/8.2.0/lib -lpetsc -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lstrumpack -lscalapack -lsuperlu_dist -lflapack -lfblas -lptesmumps -lptscotchparmetis -lptscotch -lptscotcherr -lesmumps -lscotch -lscotcherr -lpthread -lparmetis -lmetis -lm -lstdc++ -ldl -lmpifort -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lrt -lquadmath -lstdc++ -ldl -o ex19\n/usr/bin/ld: warning: libgfortran.so.3, needed by /cm/shared/apps/mpich/ge/gcc/64/3.3.2/lib/libmpifort.so, may conflict with libgfortran.so.5\n/usr/bin/ld: warning: libgfortran.so.3, needed by /cm/shared/apps/mpich/ge/gcc/64/3.3.2/lib/libmpifort.so, may conflict with libgfortran.so.5\nC/C++ example src/snes/tutorials/ex19 run successfully with 1 MPI process\nC/C++ example src/snes/tutorials/ex19 run successfully with 2 MPI processes\nC/C++ example src/snes/tutorials/ex19 run successfully with hypre\nC/C++ example src/snes/tutorials/ex19 run successfully with mumps\nC/C++ example src/snes/tutorials/ex19 run successfully with superlu_dist\nCompleted test examples\n\nContinuing with the installation to install libmesh also fails with the following output:\n(base) (11:59:39) [dchipman@borah-login moose] >>> ./scripts/update_and_rebuild_libmesh.sh \nSubmodule path 'libmesh': checked out '34519df7787ee1d80fe2d7c9e53a1048895a730a'\nfatal: reference is not a tree: 9a40214a48657d152ba6f1de2b6296b8553890a3\nSubmodule path 'libmesh/contrib/timpi': checked out '2397962a0b2c4d19c53b1a45f0304eaea999e024'\nSubmodule path 'libmesh/contrib/timpi/m4/autoconf-submodule': checked out 'a993d797c7c0dbf9728f39fd5fbcbac758b151fa'\nSubmodule path 'libmesh/m4/autoconf-submodule': checked out 'a993d797c7c0dbf9728f39fd5fbcbac758b151fa'\nUnable to checkout '9a40214a48657d152ba6f1de2b6296b8553890a3' in submodule path 'libmesh/contrib/metaphysicl'\nFailed to recurse into submodule path 'libmesh'\ngit submodule command failed, are your proxy settings correct?\nmkdir: cannot create directory \u2018libmesh\u2019: File exists\n\nImpact\n\nAs I cannot install, I cannot use MOOSE \ud83d\ude22.",
          "url": "https://github.com/idaholab/moose/discussions/18868",
          "updatedAt": "2022-06-13T04:27:10Z",
          "publishedAt": "2021-09-20T18:17:23Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "loganharbour"
                  },
                  "bodyText": "Transferred to a discussion.\nPing @roystgnr - how are we missing a commit for metaphysicl?",
                  "url": "https://github.com/idaholab/moose/discussions/18868#discussioncomment-1358892",
                  "updatedAt": "2022-06-13T04:27:12Z",
                  "publishedAt": "2021-09-20T18:34:38Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "roystgnr"
                          },
                          "bodyText": "That looks like the correct hash.  If this was an old libMesh install I'd wonder whether the contrib/metaphysicl submodule was still pointing to the old URL - https://github.com/roystgnr/MetaPhysicL/ instead of https://github.com/libMesh/MetaPhysicL/ - but if that's not the problem then I'm not sure what is - the requested reference is right on the releases page, https://github.com/libMesh/MetaPhysicL/tags - v1.3.0_bootstrapped",
                          "url": "https://github.com/idaholab/moose/discussions/18868#discussioncomment-1359007",
                          "updatedAt": "2022-06-13T04:27:12Z",
                          "publishedAt": "2021-09-20T19:06:14Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "loganharbour"
                          },
                          "bodyText": "Yeah. I'm not sure what's going on.\n@DamynChipman my easiest suggestion: nuke /bsuhome/dchipman/packages/moose/moose and re-clone. With a fresh clone on that commit, I have no issues locally parsing that failed commit in libmesh/m4/autoconf-submodule.",
                          "url": "https://github.com/idaholab/moose/discussions/18868#discussioncomment-1359027",
                          "updatedAt": "2022-06-13T04:27:12Z",
                          "publishedAt": "2021-09-20T19:11:53Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "roystgnr"
                          },
                          "bodyText": "This is weird.  When I check out Moose bc61efd (to get something with the same libMesh hash as reported above), doing git submodule update --init --recursive libmesh/ afterward succeeds ... but, even though libmesh/.gitmodules has the correct url for MetaPhysicL, when I actually go to contrib/metaphysicl/ and do a git remote -v it seems to be pointing to the old location.\nUgh, even if I go to a fully updated Moose origin/master tracking branch I get the same inconsistency.  I'm not sure what's going on here.",
                          "url": "https://github.com/idaholab/moose/discussions/18868#discussioncomment-1359066",
                          "updatedAt": "2022-06-13T04:27:13Z",
                          "publishedAt": "2021-09-20T19:22:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "roystgnr"
                          },
                          "bodyText": "That might have been something peculiar to my pre-existing Moose checkout?  If I do a fresh clone and a submodule update from there then everything looks fine.  Looking around it seems that git submodule sync is the way to properly update an existing clone, but at this point I second the \"Just nuke it from orbit.  It's the only way to be sure.\" advice.",
                          "url": "https://github.com/idaholab/moose/discussions/18868#discussioncomment-1359265",
                          "updatedAt": "2022-09-24T12:33:22Z",
                          "publishedAt": "2021-09-20T20:15:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "DamynChipman"
                          },
                          "bodyText": "Thanks for the assistance. I got rid of my clone of moose and recloned. With a fresh clone, I reran all of the update_and_rebuild_* scripts for petsc and libmesh. It got much further along, but ultimately gave an error when running the libmesh script. It's a linking error: /usr/bin/ld: cannot find -ludev. I've had this issue before installing a different package on this cluster, so I'll take it up with the system admins (unless you guys know something off the top of your head).\nFeel free to close this discussion, I'll open another issue if I run into more problems after I figure out the ludev issue.",
                          "url": "https://github.com/idaholab/moose/discussions/18868#discussioncomment-1359478",
                          "updatedAt": "2022-09-24T12:33:21Z",
                          "publishedAt": "2021-09-20T21:19:01Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "roystgnr"
                          },
                          "bodyText": "I'm kind of new to Github discussions; I've copied the answer somewhere more visible and marked it as such but I'm not sure how to close this thread like you would an issue.\ncannot find -ludev means that something in your build stack (probably your MPI implementation or PETSc install?) thinks your system needs you to link to a libudev.foo (.so on Linux, .dylib I think on OSX) shared library, but then the linker (in the middle of the configure script, I guess/hope?) can't find one.  Solution might be as simple as your sysadmins running apt install libudev-dev, or might be much more complicated depending on how they have things set up.",
                          "url": "https://github.com/idaholab/moose/discussions/18868#discussioncomment-1359569",
                          "updatedAt": "2022-10-22T21:18:53Z",
                          "publishedAt": "2021-09-20T21:50:45Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "roystgnr"
                  },
                  "bodyText": "For posterity's sake: it looks like the workaround answer was \"Nuke and restart from a Moose clone that postdates the submodule move from roystgnr/MetaPhysicL to libMesh/MetaPhysicL on Github.  People more git-submodule-savvy than I could probably come up with a much better answer; possibly git submodule sync or something?",
                  "url": "https://github.com/idaholab/moose/discussions/18868#discussioncomment-1359560",
                  "updatedAt": "2022-06-14T02:51:09Z",
                  "publishedAt": "2021-09-20T21:46:46Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "gambka"
                          },
                          "bodyText": "I just ran into this issue on the INL HPC clusters and\ncd libmesh\ngit submodule sync\ncd ../\n./scripts/update_and_rebuild_libmesh.sh\n\nfixed the issue for me.",
                          "url": "https://github.com/idaholab/moose/discussions/18868#discussioncomment-1371001",
                          "updatedAt": "2022-06-14T02:51:10Z",
                          "publishedAt": "2021-09-22T17:55:51Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Nullifying stdout for split communicators",
          "author": {
            "login": "RonRahaman"
          },
          "bodyText": "Hi all, let me know if I should move this thread to a libmesh forum.  It's relevant to our external apps in MOOSE, so I thought I'd mention it here.\nOur MOOSE app consists of some ExternalProblems from other single-physics apps.  Currently, each single-physics app is running on the global comm.  In the near future, we'd like to run each single-physics app on a comm that was split from the global comm.\nIn the split comm situation, we'd like a better way to handle stdout.  The problem is this.  Suppose we're running MOOSE such that stdout is nullified for every rank except global rank 0, as done here:\nhttps://github.com/libMesh/libmesh/blob/a34662c8df2811388c6760bf537829ea62b181b9/src/base/libmesh.C#L622-L627\nNow suppose a single-physics app is run on a split comm that doesn't include global rank 0.  In that case, that app would not produce any stdout.\nWe're aware of the nuclear --keep-cout option, but to keep stdout from getting out of control, we'd like some more fine-grained control.  Maybe if we could specify particular ranks to keep stdout?  We'd like to do that in the code, rather than through a config file, since the code would need to discover the roots of the split comms and then keep stdout for those.  Definitely open to other options!",
          "url": "https://github.com/idaholab/moose/discussions/16240",
          "updatedAt": "2022-06-02T14:34:10Z",
          "publishedAt": "2020-11-18T18:59:53Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "aeslaughter"
                  },
                  "bodyText": "@friedmud Do you know the answer to this off the top of your head? Sorry, we missed this question. We are still getting used to this tool.",
                  "url": "https://github.com/idaholab/moose/discussions/16240#discussioncomment-146871",
                  "updatedAt": "2022-06-02T14:34:14Z",
                  "publishedAt": "2020-12-04T02:15:45Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@friedmud since you said you would respond to notifications from now on ^^\nI think we could support --keep-cout #rank_we_care_about\nIs there still interest for this?",
                  "url": "https://github.com/idaholab/moose/discussions/16240#discussioncomment-1366933",
                  "updatedAt": "2022-06-02T14:34:39Z",
                  "publishedAt": "2021-09-22T02:51:16Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "loganharbour"
                          },
                          "bodyText": "I like this. It should support a vector of ranks. I know I\u2019d use it.",
                          "url": "https://github.com/idaholab/moose/discussions/16240#discussioncomment-1366949",
                          "updatedAt": "2022-06-02T14:34:43Z",
                          "publishedAt": "2021-09-22T03:00:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "YaqiWang"
                          },
                          "bodyText": "The syntax can be 0,1,3-10,100.",
                          "url": "https://github.com/idaholab/moose/discussions/16240#discussioncomment-1366961",
                          "updatedAt": "2022-06-02T14:34:45Z",
                          "publishedAt": "2021-09-22T03:06:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "anyone want to work on this?",
                          "url": "https://github.com/idaholab/moose/discussions/16240#discussioncomment-1366965",
                          "updatedAt": "2022-06-02T14:34:50Z",
                          "publishedAt": "2021-09-22T03:09:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "loganharbour"
                          },
                          "bodyText": "I can give it a crack real quick.",
                          "url": "https://github.com/idaholab/moose/discussions/16240#discussioncomment-1367052",
                          "updatedAt": "2022-10-21T23:51:12Z",
                          "publishedAt": "2021-09-22T03:54:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "loganharbour"
                          },
                          "bodyText": "Actually - --keep-cout is managed by libMesh. Ping @roystgnr for his thoughts",
                          "url": "https://github.com/idaholab/moose/discussions/16240#discussioncomment-1367060",
                          "updatedAt": "2022-10-21T23:51:13Z",
                          "publishedAt": "2021-09-22T03:57:46Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "roystgnr"
                          },
                          "bodyText": "This sounds good, as long as we only interpret numeric arguments (including commas and dashes) and we're careful to parse and ignore anything alphabetical?  We don't want file_argument.x --keep-cout input=myfile.e to suddenly get confused and die because we thought input=myfile.e was a vector of ranks but it failed to parse as one, we want to just maintain the old \"all ranks\" behavior in that case.\nI do worry a little about numeric_argument.x --keep_cout 64 ... but I don't think I've ever seen any applications behave that way, with a numeric argument that wasn't either identified via a fixed argument-vector position (in which case nobody would put -- arguments in front of it rather than behind it) or attached to a --identifier or identifier= argument, so we can probably ignore that worry.",
                          "url": "https://github.com/idaholab/moose/discussions/16240#discussioncomment-1369259",
                          "updatedAt": "2022-10-21T23:51:12Z",
                          "publishedAt": "2021-09-22T13:18:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "friedmud"
                          },
                          "bodyText": "I like this option... but we also need an API to set this programmatically.",
                          "url": "https://github.com/idaholab/moose/discussions/16240#discussioncomment-1369830",
                          "updatedAt": "2022-10-21T23:51:13Z",
                          "publishedAt": "2021-09-22T14:45:44Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Proper way to do thermal radiation with raytracing",
          "author": {
            "login": "makeclean"
          },
          "bodyText": "Hi All\nI think im doing this right, I have an unstructured mesh, with three sidesets listed with the elucidating names thermal-rad-1 through thermal-rad-3. I have a GrayLambertNeumannBC specification\n  [radiation]\n    type = GrayLambertNeumannBC\n    variable = temp\n    reconstruct_emission = false\n    surface_radiation_object_name = gray_lambert\n    boundary = 'thermal-rad-1 thermal-rad-2 thermal-rad-3'\n  []\n\nI got an error from Using the GrayDiffuseRadiation - https://mooseframework.inl.gov/syntax/GrayDiffuseRadiation/ example radiative_transfer_action.i when using an unstructured mesh, telling me that it only works with GeneratedMeshes rather than FileMeshes. So instead, I created the following\n[UserObjects]\n  [gray_lambert]\n    type = ViewFactorObjectSurfaceRadiation\n    boundary = 'thermal-rad-1 thermal-rad-2 thermal-rad-3'\n    adiabatic_boundary = 'thermal-rad-1 thermal-rad-2 thermal-rad-3'\n    emissivity = '0.3 0.9 0.1'\n    temperature = temp\n    view_factor_object_name = view_factor\n  []\n  [view_factor_study]\n    type = ViewFactorRayStudy\n    execute_on = initial\n    boundary = 'thermal-rad-1 thermal-rad-2 thermal-rad-3'\n    face_order = FOURTH\n    polar_quad_order = 12\n    azimuthal_quad_order = 4\n    ray_tracing_face_type = GAUSS\n    warn_subdomain_hmax = false\n    view_factor_calculator = ray_tracing\n  []\n  [view_factor]\n    type = RayTracingViewFactor\n    boundary = 'thermal-rad-1 thermal-rad-2 thermal-rad-3'\n    execute_on = INITIAL\n    ray_study_name = view_factor_study\n  []\n[]\n\n[RayBCs/viewfactor]\n  type = ViewFactorRayBC\n  boundary = 'thermal-rad-1 thermal-rad-2 thermal-rad-3'\n[]\n\nHowever, I get an error\n\n*** ERROR ***\nThe following error occurred in the object \"view_factor_study\", of type \"ViewFactorRayStudy\".\n\nCannot use GRID quadrature type with tetrahedral elements in ViewFactorRayStudy 'view_factor_study'\n\nYou can see above that ray_tracing_face_type is set to Gauss, so I'm at a loss, is this a genuine bug?",
          "url": "https://github.com/idaholab/moose/discussions/18874",
          "updatedAt": "2022-06-06T19:59:05Z",
          "publishedAt": "2021-09-20T22:51:58Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@loganharbour @snschune",
                  "url": "https://github.com/idaholab/moose/discussions/18874#discussioncomment-1359802",
                  "updatedAt": "2022-06-06T19:59:30Z",
                  "publishedAt": "2021-09-20T23:29:05Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "snschune"
                  },
                  "bodyText": "A few general things, I would use the action to set up this problem. Look for [GrayDiffuseRadiation] in the heat conduction module's input. Unstructured meshes are supported but triangles do not work for the grid quadrature. There should be a quadrature type that works with triangles though (I am saying triangles because that's what the sidesets around tets are made of).\nI am not sure if it makes sense to have all surfaces be adiabatic:\nboundary = 'thermal-rad-1 thermal-rad-2 thermal-rad-3'\nadiabatic_boundary = 'thermal-rad-1 thermal-rad-2 thermal-rad-3'\n\nDo you have a picture of the geometry by any chance?\nThe general way net radiation transport works in MOOSE is on a cavity basis. A cavity is a meshed region of your domain that is fully enclosed by sidesets that are listed under the boundary parameter in the [GrayDiffuseRadiation] block. There are three types of sidesets:\n\nfixed_temperature_boundary keep the temperature constant, no heat conduction variable is defined \"behind\" that sideset.\nadiabatic_boundary radiation in equals radiation out, no heat conduction variable is defined \"behind\" that sideset.\nAnything in boundary that isn't 1 or 2 has a block \"behind\" it that defines the MooseVariable that you provide in the temperature keyword.\nYou can define more than one cavity.",
                  "url": "https://github.com/idaholab/moose/discussions/18874#discussioncomment-1360154",
                  "updatedAt": "2022-06-06T19:59:34Z",
                  "publishedAt": "2021-09-21T02:10:14Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "makeclean"
                  },
                  "bodyText": "Ok, I've got some progress\n[GrayDiffuseRadiation]\n  [./cavity]\n    boundary = 'thermal-rad-1 thermal-rad-2 thermal-rad-3'\n    emissivity = '0.7 0.1 0.3'\n    n_patches = '40 20 30'\n    partitioners = 'metis metis metis'\n    temperature = temp\n    view_factor_calculator = ray_tracing\n    ray_tracing_face_type = GAUSS\n  [../]\n[]\n\nI get the same error as I did on the last message on this in may. I now get the error\n*** ERROR ***\nRay on processor 0 and thread 0 failed to trace at line 2145\n\nDon't know what to do with a Ray after it hit an external\nboundary at point (x,y,z)=(  0.0178, 0.00248967, -0.0147817)!\n\nWhen hitting an external RayBC, a Ray must either:\n  Be killed by a RayBC\n  Have its trajectory changed by the RayBC\nby at least one of the executed RayBCs.\n\nYou need to either:\n  Kill/change the Ray sooner with RayKernels, internal RayBCs, or a max distance\n  Kill/change the Ray on the boundary with a RayBC\n\nThe geometry looks like this;\n\nThe yellow region in the middle is my cavity (the mesh is sliced so you can see it (in reality its whole), there are no gaps in the sidesets, all the triangles in the 3 sets define a closed boundary. So I'm at a loss here.",
                  "url": "https://github.com/idaholab/moose/discussions/18874#discussioncomment-1362712",
                  "updatedAt": "2022-06-06T19:59:35Z",
                  "publishedAt": "2021-09-21T14:48:23Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "I also thought that the block which defines the mesh of the vacuum region, would automatically not need a kernel to be active?",
                          "url": "https://github.com/idaholab/moose/discussions/18874#discussioncomment-1362765",
                          "updatedAt": "2022-06-06T19:59:49Z",
                          "publishedAt": "2021-09-21T14:57:41Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "snschune"
                          },
                          "bodyText": "That error typically happens when the sidesets do not completely enclose the cavity. I would usually load the geometry into paraview (you can create exodus versions of your mesh using MOOSE using --mesh-only command line option), make all blocks invisible and only show the three sidesets. If that doesn't help, I'd use a sphere located at 0.0178, 0.00248967, -0.0147817 in paraview to see where the ray fails to trace.",
                          "url": "https://github.com/idaholab/moose/discussions/18874#discussioncomment-1362801",
                          "updatedAt": "2022-06-06T19:59:49Z",
                          "publishedAt": "2021-09-21T15:07:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Ok, I've reproduced a more simple problem, and still no-dice. I now have a cube inside of a cube, of side 10 m, and the smaller cube 2m. I have, what I consider to be a minimum (non) working example. The CAD does not overlap, the geometry meshes as it should. I have 6 side sets involved in the radiative transfer, named cav-1 through cav-6. I'm happy to attach meshes and cubit files if that helps.\n[Mesh]\n  [mesh-in]\n    type = FileMeshGenerator\n    file = 'heat-ray.e'\n  []\n[]\n\n[Variables]\n  [temp]\n    initial_condition = 313.15\n  []\n[]\n\n\n[AuxVariables]\n  [temp_in_C]\n  []\n  [radiation_flux]\n  []\n[]\n\n[Kernels]\n  [isotropic-heat]\n    type = HeatConduction\n    variable = temp\n    block = 'brik'\n  []\n  [null-kernel]\n    type = NullKernel\n    variable = temp \n    block = 'vacuum'\n  []\n[]\n\n[AuxKernels]\n  [K_to_C]\n    type = ParsedAux\n    variable = 'temp_in_C'\n    function = 'temp-273.15'\n    args = 'temp'\n  []\n[]\n\n[GrayDiffuseRadiation]\n  [./cavity]\n    boundary = 'cav-1 cav-2 cav-3 cav-4 cav-5 cav-6'\n    emissivity = '0.5 0.5 0.5 0.5 0.5 0.5'\n    n_patches = '20 20 20 20 20 20'\n    partitioners = 'metis metis metis metis metis metis'\n    temperature = temp\n    view_factor_calculator = ray_tracing\n    ray_tracing_face_type = GAUSS\n  [../]\n[]\n\n[BCs]\n  [fixed-temp-1]\n    type = DirichletBC\n    variable = temp\n    boundary = 't1'\n    value = 313.15\n  []\n  [fixed-temp-2]\n    type = DirichletBC\n    variable = temp\n    boundary = 't2'\n    value = 900.0\n  []\n[]\n        \n[Materials]\n  [heat-sink_density]\n    type = GenericConstantMaterial\n    prop_names = 'density'\n    block = 'brik'\n    prop_values = '1.1e3'\n  []\n  [heat-sink]\n    type = HeatConductionMaterial\n    block = 'brik'\n    specific_heat = 200\n    thermal_conductivity = 50\n  []\n  [vacuum_density]\n    type = GenericConstantMaterial\n    prop_names = 'density'\n    block = 'vacuum'\n    prop_values = '0'\n  []\n  [vacuum]\n    type = HeatConductionMaterial\n    block = 'vacuum'\n    specific_heat = 0\n    thermal_conductivity = 0\n  []\n[]\n\n[Preconditioning]\n  [SMP]\n    type = SMP\n    full = true\n  []\n[]\n\n[Executioner]\n  automatic_scaling = true\n  solve_type = 'NEWTON'\n  type = Steady\n  line_search = none\n  nl_abs_tol = 1e-6\n  nl_rel_tol = 1e-5\n  l_tol = 1e-4\n\n  l_max_its = 100\n  nl_max_its = 10\n  dt = 0.1\n  num_steps = 30\n\n  petsc_options_iname = '-pc_type -ksp_gmres_restart'\n  petsc_options_value = 'ilu      101'\n\n[]\n  \n[Outputs]\n  exodus = true\n[]\n\nThe error is,\n*** ERROR ***\nRay on processor 0 and thread 0 failed to trace at line 2145\n\nDon't know what to do with a Ray after it hit an external\nboundary at point (x,y,z)=(       5, -1.02841, -0.694079)!\n\nWhen hitting an external RayBC, a Ray must either:\n  Be killed by a RayBC\n  Have its trajectory changed by the RayBC\nby at least one of the executed RayBCs.\n\nYou need to either:\n  Kill/change the Ray sooner with RayKernels, internal RayBCs, or a max distance\n  Kill/change the Ray on the boundary with a RayBC\n\nNow my understanding is I shouldnt have to define more BC's, Im happy to, but the documentation indicates that this problem should work - what am I doing wrong?",
                          "url": "https://github.com/idaholab/moose/discussions/18874#discussioncomment-1364370",
                          "updatedAt": "2022-06-06T19:59:50Z",
                          "publishedAt": "2021-09-21T21:03:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Here are the files - https://www.dropbox.com/sh/2f0odxinfcxivkj/AAAM0ZYfULUCUeunoCC5WZdla?dl=0",
                          "url": "https://github.com/idaholab/moose/discussions/18874#discussioncomment-1364427",
                          "updatedAt": "2023-03-12T21:33:41Z",
                          "publishedAt": "2021-09-21T21:17:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "snschune"
                          },
                          "bodyText": "Here is a slight modification of the input file that runs. The main difference is how the sidesets are defined. It's a bit complicated so bear with me.\nSidesets are a collection of faces, where a face is what is around elements (triangle that bound a tet, or quadrilaterals that bound a hex). Faces do not exist on their own in MOOSE, they are indexed by two parameters element id, local side id. So for a hexahedron, you would have 8 local side ids from 0 to 7.\nNow, you'd observe immediately, that interior faces have two ways of addressing them, either from the left or the right element bordering them. These two ways of defining a face are actually not interchangeable in MOOSE. The difference is which direction the normal points. Let's say element 1 borders element 2 and the common face has side id 0 for element 1 and side id 3 for element 2. Then the face can be indexed by elem 1, side 0 or elem 2, side 3. The difference between these two alternatives is that for case 1, the normal points from element 1 to 2, while the reverse is true for the second definition. For the first definition, the face is grouped with elem 1, while for the second definition the side is grouped with elem 2. That carries through if you e.g. delete blocks and elem 1 is not deleted, but elem 2 is deleted etc.\nWhat I've essentially done is to make sure that the faces making up the sideset inbetween is defined on the brik side.\nThe rule is that sidesets that participate in the net radiation transfer and have temperature defined in the block \"behind\"\nthem, must be defined using the element/local side definition that belongs to the block that you solve temperature on.\nThis ensures that the normal points into the cavity.\nFor isothermal and adiabatic sidesets, the idea usually is that these are external surfaces anyway so their normals are usually pointing out of the cavity (nothing you can do because there is no neighboring element at an external boundary).\nSo what you have to do is to flip normals in CUBIT for all the internal sidesets that participate in the net radiation transport calculation.\n[Mesh]\n  [mesh-in]\n    type = FileMeshGenerator\n    file = 'heat-ray.e'\n  []\n\n  [sidesets]\n    type = SideSetsBetweenSubdomainsGenerator\n    primary_block = 2\n    paired_block = 1\n    new_boundary = 101\n    input = mesh-in\n  []\n\n  [name_sideset]\n    type = RenameBoundaryGenerator\n    old_boundary = 101\n    new_boundary = inbetween\n    input = sidesets\n  []\n[]\n\n[Variables]\n  [temp]\n    initial_condition = 313.15\n  []\n[]\n\n\n[AuxVariables]\n  [temp_in_C]\n  []\n  [radiation_flux]\n  []\n[]\n\n[Kernels]\n  [isotropic-heat]\n    type = HeatConduction\n    variable = temp\n    block = 'brik'\n  []\n  [null-kernel]\n    type = NullKernel\n    variable = temp\n    block = 'vacuum'\n  []\n[]\n\n[AuxKernels]\n  [K_to_C]\n    type = ParsedAux\n    variable = 'temp_in_C'\n    function = 'temp-273.15'\n    args = 'temp'\n  []\n[]\n\n[GrayDiffuseRadiation]\n  [./cavity]\n    #boundary = 'cav-1 cav-2 cav-3 cav-4 cav-5 cav-6'\n    #emissivity = '0.5 0.5 0.5 0.5 0.5 0.5'\n    #n_patches = '20 20 20 20 20 20'\n    #partitioners = 'metis metis metis metis metis metis'\n    boundary = 'inbetween'\n    emissivity = '0.5'\n    n_patches = '100'\n    partitioners = 'metis'\n    temperature = temp\n    view_factor_calculator = ray_tracing\n    ray_tracing_face_type = GAUSS\n  [../]\n[]\n\n[BCs]\n  [fixed-temp-1]\n    type = DirichletBC\n    variable = temp\n    boundary = 't1'\n    value = 313.15\n  []\n  [fixed-temp-2]\n    type = DirichletBC\n    variable = temp\n    boundary = 't2'\n    value = 900.0\n  []\n[]\n\n[Materials]\n  [heat-sink_density]\n    type = GenericConstantMaterial\n    prop_names = 'density'\n    block = 'brik'\n    prop_values = '1.1e3'\n  []\n  [heat-sink]\n    type = HeatConductionMaterial\n    block = 'brik'\n    specific_heat = 200\n    thermal_conductivity = 50\n  []\n  [vacuum_density]\n    type = GenericConstantMaterial\n    prop_names = 'density'\n    block = 'vacuum'\n    prop_values = '0'\n  []\n  [vacuum]\n    type = HeatConductionMaterial\n    block = 'vacuum'\n    specific_heat = 0\n    thermal_conductivity = 0\n  []\n[]\n\n[Preconditioning]\n  [SMP]\n    type = SMP\n    full = true\n  []\n[]\n\n[Executioner]\n  automatic_scaling = true\n  solve_type = 'NEWTON'\n  type = Steady\n  line_search = none\n  nl_abs_tol = 1e-6\n  nl_rel_tol = 1e-5\n  l_tol = 1e-4\n\n  l_max_its = 100\n  nl_max_its = 10\n\n  petsc_options_iname = '-pc_type -ksp_gmres_restart'\n  petsc_options_value = 'ilu      101'\n\n[]\n\n[Outputs]\n  exodus = true\n[]",
                          "url": "https://github.com/idaholab/moose/discussions/18874#discussioncomment-1364919",
                          "updatedAt": "2023-03-12T21:33:16Z",
                          "publishedAt": "2021-09-22T00:13:32Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "snschune"
                  },
                  "bodyText": "Small addition here, you see that I name boundary 101. That is necessary due to this bug (#17192) that will be fixed once we switched\nto id based identification of patches.\n  [sidesets]\n    type = SideSetsBetweenSubdomainsGenerator\n    primary_block = 2\n    paired_block = 1\n    new_boundary = 101\n    input = mesh-in\n  []\n\n  [name_sideset]\n    type = RenameBoundaryGenerator\n    old_boundary = 101\n    new_boundary = inbetween\n    input = sidesets\n  []",
                  "url": "https://github.com/idaholab/moose/discussions/18874#discussioncomment-1364932",
                  "updatedAt": "2022-06-15T02:13:00Z",
                  "publishedAt": "2021-09-22T00:17:18Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "No, that makes complete sense - I was trying to achieve the same thing Cubit, which was proving much more difficult :)",
                          "url": "https://github.com/idaholab/moose/discussions/18874#discussioncomment-1367422",
                          "updatedAt": "2022-06-15T02:13:02Z",
                          "publishedAt": "2021-09-22T06:34:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "However, the NullKernel thing still remains, should that still be happening, do I need to add a null kernel to my vacuum region?",
                          "url": "https://github.com/idaholab/moose/discussions/18874#discussioncomment-1367427",
                          "updatedAt": "2022-06-15T02:13:02Z",
                          "publishedAt": "2021-09-22T06:35:36Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "you can use kernel_coverage_check = false in [Problem] to not require a NullKernel\nA NullKernel should in general be avoided, that will create a bunch of 0s in your system matrix for the relevant dofs iirc",
                          "url": "https://github.com/idaholab/moose/discussions/18874#discussioncomment-1367430",
                          "updatedAt": "2022-06-15T02:13:02Z",
                          "publishedAt": "2021-09-22T06:37:01Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Our meshing software (MeshIt) is now available from git",
          "author": {
            "login": "mcacace"
          },
          "bodyText": "Foreword: This email would be of interest for the (small) group of users dealing with fracture/reservoir THM applications.\nDear Moose community,\nI would like to share that out in-house meshing software is now available from github (https://github.com/bloech/MeshIt). The main scope of MeshIt is to provide Boundary conforming Delaunay 3D meshes with a specific target to complex fractured reservoirs. It provide the flexibility to integrate 2D and 1D lower dimensional elements in a format that is compatible with the framework standard via a dedicated exodus output. You can find an application on the Moose website where we have coupled MeshIt to one of our Moose based application.  Some information (non exhaustive) on the theory behind the software can be found in a relative old paper at https://doi.org/10.1007/s12665-015-4537-x.\nHope this could be of any help to the community and we are glad to accept any commit/questions/... they should arise,\nMauro",
          "url": "https://github.com/idaholab/moose/discussions/16537",
          "updatedAt": "2022-07-26T15:07:30Z",
          "publishedAt": "2020-12-18T08:58:15Z",
          "category": {
            "name": "Q&A Meshing"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Just marking this as answered. It ll remain visible in the meshing Q&A section.\nThanks for sharing.",
                  "url": "https://github.com/idaholab/moose/discussions/16537#discussioncomment-1366937",
                  "updatedAt": "2022-07-26T15:07:30Z",
                  "publishedAt": "2021-09-22T02:53:46Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Nodeset 1st/2nd order bug",
          "author": {
            "login": "makeclean"
          },
          "bodyText": "Hi\nIve got a fairly simple 2d problem which was generated using Cubit. The nodes on the left face are added to a nodeset group, and the nodes on the top face are added to a second nodeset.\n\nI have the problem running in first order perfectly fine\n[Mesh]\n  type = FileMesh \n  file = '../bendy-cut_20_0.e'\n  construct_side_list_from_node_list = true\n#  second_order = true\n[]\n \n[GlobalParams]\n  displacements = 'disp_x disp_y'\n[]\n  \n[Variables]\n  [disp_x]\n#    family = LAGRANGE\n#    order = SECOND\n  []\n  [disp_y]\n#    family = LAGRANGE\n#    order = SECOND\n  []\n[]\n  \n[AuxVariables]\n  [./stress_xx_nodal]\n    order = FIRST\n    family = MONOMIAL\n  [../]\n  [./stress_yy_nodal]\n    order = FIRST\n    family = MONOMIAL\n  [../]\n  [./strain_xx_nodal]\n    order = FIRST\n    family = MONOMIAL\n  [../]\n  [./strain_yy_nodal]\n    order = FIRST\n    family = MONOMIAL\n  [../]\n  [./vonmises_nodal]\n    order = FIRST\n    family = MONOMIAL\n  [../]\n[] \n  \n[AuxKernels]\n  [./stress_xx]\n    type = ADRankTwoAux\n    rank_two_tensor = stress\n    variable = stress_xx_nodal\n    index_i = 0\n    index_j = 0\n [../]\n [./stress_yy]\n    type = ADRankTwoAux\n    rank_two_tensor = stress\n    variable = stress_xx_nodal\n    index_i = 1\n    index_j = 1\n [../]\n [./strain_xx]\n    type = ADRankTwoAux\n    rank_two_tensor = total_strain\n    variable = strain_xx_nodal\n    index_i = 0\n    index_j = 0\n [../]\n [./strain_yy]\n    type = ADRankTwoAux\n    rank_two_tensor = total_strain\n    variable = strain_xx_nodal\n    index_i = 1\n    index_j = 1\n  [../]\n  [./vonmises]\n    type = ADRankTwoScalarAux\n    rank_two_tensor = stress\n    variable = vonmises_nodal\n    scalar_type = VonMisesStress\n  [../]\n[] \n  \n[Modules/TensorMechanics/Master]\n  [./block1]\n    strain = SMALL #Small linearized strain, automatically set to XY coordinates\n    add_variables = true #Add the variables from the displacement string in GlobalParams\n    generate_output = 'stress_xx stress_yy stress_zz vonmises_stress'\n    use_automatic_differentiation = true\n  [../]\n[]\n\n[Kernels]\n  [gravity_y]\n    type = ADGravity\n    variable = disp_y\n    value = -9.81\n  []\n[]\n  \n[Materials]\n  [steel]\n    type = ADGenericConstantMaterial\n    prop_names = 'density'\n    prop_values = '7800'\n    block = 'steel'\n  []\n  [elasticity_tensor]\n    type = ADComputeIsotropicElasticityTensor\n    youngs_modulus = 200.e9\n    poissons_ratio = 0.3\n  []\n  [stress]\n    type = ADComputeLinearElasticStress\n  []\n[]\n\n[BCs]\n  [pressure_y]\n    type = ADPressure\n    variable = disp_y\n    component = 1\n    boundary = 'top-load'\n    constant = 1e8\n  []\n  [left_fixed_y]\n    type = ADDirichletBC\n    variable = 'disp_y'\n    boundary = 'pinned'\n    value = 0.0\n  []\n  [left_fixed_x]\n    type = ADDirichletBC\n    variable = 'disp_x'\n    boundary = 'pinned'\n    value = 0.0\n  []\n[]\n  \n[Preconditioning]\n  [./SMP]\n    type = SMP\n    full = true\n  [../]\n[]\n\n[Executioner]\n  type = Steady\n  solve_type = 'NEWTON'\n  petsc_options = '-snes_ksp_ew'\n  petsc_options_iname = '-pc_type -sub_pc_type -pc_asm_overlap -ksp_gmres_restart'\n  petsc_options_value = 'asm lu 1 101'\n[]\n\n[Outputs]\n  exodus = true\n[]\n\nWhen I run this in second order, by uncommenting the # from the 1st and second blocks, I get an error from MOOSE\n*** ERROR ***\n/mnt/disk2/beam-examples/run/bending_l.i:124: (BCs/pressure_y/boundary):\n    the following side set ids do not exist on the mesh: 2\n    \n    MOOSE distinguishes between \"node sets\" and \"side sets\" depending on whether \n    you are using \"Nodal\" or \"Integrated\" BCs respectively. Node sets corresponding \n    to your side sets are constructed for you by default.\n    \n    Try setting \"Mesh/construct_side_list_from_node_list=true\" if you see this error.\n    Note: If you are running with adaptivity you should prefer using side sets.\n\napplication called MPI_Abort(MPI_COMM_WORLD, 1) - process 0\n[unset]: write_line error; fd=-1 buf=:cmd=abort exitcode=1\n\nThis does not happen in 1st order.",
          "url": "https://github.com/idaholab/moose/discussions/17492",
          "updatedAt": "2022-06-16T00:10:21Z",
          "publishedAt": "2021-04-02T17:25:14Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@dschwen could you help with this please",
                  "url": "https://github.com/idaholab/moose/discussions/17492#discussioncomment-610708",
                  "updatedAt": "2022-06-16T00:10:33Z",
                  "publishedAt": "2021-04-14T15:38:35Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "If this hasnt been solved, I would re-add the sidesets manually since it's just the top\nThis may just be a problem with a different name for the sideset than the one used for the BC as well.\nSince your input runs withoout this BC apparently, you can just look at the sidesets in paraview and see if they do exist.\nAn update to MOOSE also made that error message more clear so that can help too.\nClosing this since it's old. Sorry we did not help at the time.",
                  "url": "https://github.com/idaholab/moose/discussions/17492#discussioncomment-1366923",
                  "updatedAt": "2022-06-16T00:10:33Z",
                  "publishedAt": "2021-09-22T02:47:51Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Return a parameter specified into a kernel as output",
          "author": {
            "login": "DomenicoCFD"
          },
          "bodyText": "Hi All,\nI created a bespoke kernel which returns a function of space and time. To do so, I do calculate a set of intermediate parameters from my input. Basically, I would like to get returned somehow and eventually as a post-processor parameter the intermediate parameters.\nIs there a way to get that?\nKind Regards,\nDomenico",
          "url": "https://github.com/idaholab/moose/discussions/18801",
          "updatedAt": "2023-08-10T07:46:13Z",
          "publishedAt": "2021-09-10T14:45:50Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nWhere is the calculation that leads to what you want  to return being done right now? In the input file? In the kernel?\nYou could move this calculation to a postprocessor (like the ParsedPostprocessor if it s simple) then feed the postprocessor in the kernel inputs.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/18801#discussioncomment-1307800",
                  "updatedAt": "2023-08-10T07:46:13Z",
                  "publishedAt": "2021-09-10T16:26:39Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "DomenicoCFD"
                          },
                          "bodyText": "Hi @GiudGiud,\nMany thanks for your response. There has been a bit of change of direction so that what I am trying to extract is a heat source term but now modelled as boundary condition. Having said that and following what you already suggested, I assume that the post-processor should be feed into the bc input. But how would I do that? Also, the postprocessor you suggested (i.e. ParsedPostprocessor) does not involve any object apart from other post-processors'.\nI look forward to hearing from you.\nKind Regards,",
                          "url": "https://github.com/idaholab/moose/discussions/18801#discussioncomment-1316994",
                          "updatedAt": "2023-08-10T07:46:36Z",
                          "publishedAt": "2021-09-13T15:55:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Ok so 2 questions:\nHow to get the calculation into the postprocessor? What are you doing to compute this term? Maybe you will need to write a new postprcoessor, maybe you can re-use existing ones\nAnd to couple a postprocessor into a BC then you can use either of these depending on your BC:\nhttps://mooseframework.inl.gov/source/bcs/PostprocessorDirichletBC.html\nhttps://mooseframework.inl.gov/source/bcs/PostprocessorNeumannBC.html\nsorry they are not documented. We are documenting the framework at a fast pace, this should be fixed soon",
                          "url": "https://github.com/idaholab/moose/discussions/18801#discussioncomment-1317251",
                          "updatedAt": "2023-08-10T07:46:38Z",
                          "publishedAt": "2021-09-13T16:33:30Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ngrilli"
                  },
                  "bodyText": "Dear @DomenicoCFD\nWhat I normally do is to define MaterialProperty in material objects for quantities that I would like to output.\nThere are many examples of this in moose, for instance:\nhttps://github.com/idaholab/moose/blob/next/modules/tensor_mechanics/src/kernels/PlasticHeatEnergy.C\nThe plastic energy is calculated by a material object and then passed to the kernel\nthat applies to the temperature variable.\nSee the corresponding input file:\nhttps://github.com/idaholab/moose/blob/next/modules/tensor_mechanics/test/tests/jacobian/phe01.i\nIn that case, plastic energy can be added to an auxkernel, then visualised and postprocessed in paraview.\nNicol\u00f2",
                  "url": "https://github.com/idaholab/moose/discussions/18801#discussioncomment-1312695",
                  "updatedAt": "2023-08-10T07:46:39Z",
                  "publishedAt": "2021-09-12T14:39:11Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ngrilli"
                          },
                          "bodyText": "Then you use getMaterialProperty to use your quantity inside the kernel",
                          "url": "https://github.com/idaholab/moose/discussions/18801#discussioncomment-1312700",
                          "updatedAt": "2023-10-24T21:25:41Z",
                          "publishedAt": "2021-09-12T14:40:40Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "If you want the parameter to be a single value for the boundary, follow the first answer\nIf you want a time/space dependent value, follow the second answer.",
                  "url": "https://github.com/idaholab/moose/discussions/18801#discussioncomment-1366858",
                  "updatedAt": "2023-10-24T21:27:55Z",
                  "publishedAt": "2021-09-22T02:21:40Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "the material property import from .CSV file is not match [.C file problem]",
          "author": {
            "login": "Traiwit"
          },
          "bodyText": "Hi all,\nI want to introduce a new material property (Damage) base on the element ID\nI use ElementPropertyReadFile to read data from csv file,\n  [./damage_read]\n    type = ElementPropertyReadFile\n    prop_file_name = 'damage.csv'\n    nprop = 1\n    read_type = element\n  [../]\n\nbut they don't match, I'm pretty sure my .C file isn't correct. could you please help me check what did I do wrong?\nThis is my .C file, I didn't know where to start, so I modified GenericConstantArray.C\nInputParameters\nGenericConstantArrayTC::validParams()\n{\n\n  InputParameters params = Material::validParams();\n  params.addRequiredParam<std::string>(\"prop_name\",\n                                       \"The name of the property this material will have\");\n  // params.addParam<RealEigenVector>(\"prop_value\",\n  //                                          \"The values associated with the named property\");\n  // params.declareControllable(\"prop_value\");\n  params.addClassDescription(\n      \"A material evaluating one material property in type of RealEigenVector\");\n  params.set<MooseEnum>(\"constant_on\") = \"SUBDOMAIN\";\n  params.addParam<UserObjectName>(\"read_prop_user_object\",\n                                      \"The ElementReadPropertyFile \"\n                                      \"GeneralUserObject to read element \"\n                                      \"specific property values from file\");\n  return params;\n}\nGenericConstantArrayTC::GenericConstantArrayTC(const InputParameters & parameters)\n  : Material(parameters),\n    _prop_name(getParam<std::string>(\"prop_name\")),\n    // _prop_value(getParam<RealEigenVector>(\"prop_value\")),\n    _property(declareProperty<Real>(_prop_name)),\n    _mat_prop(declareProperty<Real>(\"prop_value\")),\n    _read_prop_user_object(isParamValid(\"read_prop_user_object\")\n                               ? &getUserObject<ElementPropertyReadFile>(\"read_prop_user_object\")\n                               : nullptr)\n{\n}\n\nvoid\nGenericConstantArrayTC::initQpStatefulProperties()\n{\n  computeQpProperties();\n}\n\nvoid\nGenericConstantArrayTC::computeQpProperties()\n{\n   _mat_prop[_qp] = _read_prop_user_object->getData(_current_elem, 0);\n  _property[_qp] = _mat_prop[_qp];\n}\n\n** I think the problem is from the last 2 line **\nBasically the data read from csv file is store at _read_prop_user_object then > _mat_prop then > property\nValidation: I tested by let damage = elementID\n\nHowever, the result isn't that I wanted, the elementID should be equal to the damage\n\nThank you very much!\nKind regards,\nTrai",
          "url": "https://github.com/idaholab/moose/discussions/18880",
          "updatedAt": "2022-06-15T03:01:57Z",
          "publishedAt": "2021-09-21T10:35:18Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nThere's a few issues with that code.\n-If you forget the read_user_object parameter, then you ll be trying to access a nullptr and that will segfault.\n-Why do you have both mat_prop and property ? You only need one.\n\nparams.set(\"constant_on\") = \"SUBDOMAIN\";\nThis is going to mess with the evaluation, as it ll tell the code to evaluate it once per subdomain and not once per element / quadrature point.\n\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/18880#discussioncomment-1364328",
                  "updatedAt": "2022-06-15T03:01:59Z",
                  "publishedAt": "2021-09-21T20:53:46Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Traiwit"
                          },
                          "bodyText": "Hi @GiudGiud,\nAs you know my C++ isnt good, so i only follow the example and put things together.\n\n-If you forget the read_user_object parameter, then you ll be trying to access a nullptr and that will segfault.\n\nshould I just remove ': nullptr' from\n _read_prop_user_object(isParamValid(\"read_prop_user_object\")\n                               ? &getUserObject<ElementPropertyReadFile>(\"read_prop_user_object\")\n                               : nullptr)\n\n\n\n-Why do you have both mat_prop and property\n\nso at the last section, should I just remove this line  _property[_qp] = _mat_prop[_qp]; ?\n\nparams.set(\"constant_on\") = \"SUBDOMAIN\";\n\nnot sure what to do with this, do I just change subdomain to element?\nThank you for helping me again @GiudGiud :)\nKind regards,\nTraiwit",
                          "url": "https://github.com/idaholab/moose/discussions/18880#discussioncomment-1364850",
                          "updatedAt": "2022-06-15T03:01:59Z",
                          "publishedAt": "2021-09-21T23:48:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "that works\nRemove _property and the declareProperty and remove it from the header\njust delete that line params.set(\"constant_on\") = \"SUBDOMAIN\";",
                          "url": "https://github.com/idaholab/moose/discussions/18880#discussioncomment-1364857",
                          "updatedAt": "2022-06-15T03:01:59Z",
                          "publishedAt": "2021-09-21T23:50:04Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "Traiwit"
                  },
                  "bodyText": "all good now, thanks @GiudGiud !",
                  "url": "https://github.com/idaholab/moose/discussions/18880#discussioncomment-1364952",
                  "updatedAt": "2022-06-15T03:02:00Z",
                  "publishedAt": "2021-09-22T00:26:45Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Installation error on Expanse cluster at SDSC",
          "author": {
            "login": "tengzhang48"
          },
          "bodyText": "Hello,\nI followed the online instruction to install Moose on Expanse cluster at SDSC. When compiling libmesh, I got the following error\n\"  CXX      apps/version.o\nCXX      utilities/src/metaphysicl_version.lo\nCXXLD    libmetaphysicl.la\n/usr/bin/ld: cannot find -lnuma\ncollect2: error: ld returned 1 exit status\nmake[4]: *** [Makefile:710: libmetaphysicl.la] Error \"\nThis is related to the function of \"metaphysical\", which is very interesting to me.\nDid I miss some modules to load on the cluster? So far, I have just followed the online instruction. I would like to hear suggestions from the Moose community and then ask for more specific help from the Expanse support if needed.\nThanks.\nBest,\nTeng",
          "url": "https://github.com/idaholab/moose/discussions/18864",
          "updatedAt": "2023-04-10T13:56:53Z",
          "publishedAt": "2021-09-20T03:39:24Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "roystgnr"
                  },
                  "bodyText": "libMesh and MetaPhysicL have nothing directly to do with libnuma, and to the best of my knowledge neither does Moose ... but we do see these sorts of errors all the time, when an MPI or a PETSc installation is for some reason tied to libraries that don't exist, then the MPI compiler wrapper tries to link them (or we parse PETSc configure output and find linker arguments that try to link them) and the link command fails.\nWe usually see those errors at configure time, though, either the first time the configure script tries to build an executable with mpicxx or the first time it tries to build a PETSc-linked test executable.  I'm not sure how you could have made it through both libMesh and MetaPhysicL configure scripts without failure only to see a failure here.  You might need to post your config logs before we can say what's going on.",
                  "url": "https://github.com/idaholab/moose/discussions/18864#discussioncomment-1359099",
                  "updatedAt": "2023-04-10T13:56:59Z",
                  "publishedAt": "2021-09-20T19:29:32Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "tengzhang48"
                          },
                          "bodyText": "Thanks for your information. The Expanse support team helped me figure the problem. After explicitly exporting the path of \"numactl\", I can compile the software.\nBest,\nTeng",
                          "url": "https://github.com/idaholab/moose/discussions/18864#discussioncomment-1363754",
                          "updatedAt": "2023-04-10T13:56:59Z",
                          "publishedAt": "2021-09-21T18:22:37Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "20k Local DOFs - does this include Auxiliary system?",
          "author": {
            "login": "ln53"
          },
          "bodyText": "Hi,\nIn the documentation here, the recommended target for DOFs-per-process is 20,000. Is this for just the Nonlinear System or should this include the Auxiliary System DOFs as well?\nThanks",
          "url": "https://github.com/idaholab/moose/discussions/18879",
          "updatedAt": "2023-03-27T07:54:15Z",
          "publishedAt": "2021-09-21T09:35:57Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "roystgnr"
                  },
                  "bodyText": "Just for the nonlinear system.\nIt's also a \"loose enough\" number that I wouldn't worry about missing it by a factor of 2 (as you would if you included the auxiliary system in an average problem).  It's just a rule of thumb, and one that varies from system to system (relatively faster interconnects mean you can scale better to higher processor counts with fewer DoFs-per-process; relatively faster CPU cores mean you want to give each more work rather than having it wait on network latency).  Nothing's likely to break if you use too many or too few DoFs per core, you just might be missing out on or being inefficient with parallel speedup, respectively.",
                  "url": "https://github.com/idaholab/moose/discussions/18879#discussioncomment-1362144",
                  "updatedAt": "2023-03-27T07:54:15Z",
                  "publishedAt": "2021-09-21T12:47:08Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ln53"
                          },
                          "bodyText": "Thanks for the answer and additional insight!",
                          "url": "https://github.com/idaholab/moose/discussions/18879#discussioncomment-1362152",
                          "updatedAt": "2023-03-27T07:54:27Z",
                          "publishedAt": "2021-09-21T12:49:10Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}