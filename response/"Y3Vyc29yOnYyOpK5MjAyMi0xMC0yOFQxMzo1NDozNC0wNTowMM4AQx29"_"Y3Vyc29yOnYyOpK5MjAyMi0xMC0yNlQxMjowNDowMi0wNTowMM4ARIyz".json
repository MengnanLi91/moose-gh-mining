{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMi0xMC0yNlQxMjowNDowMi0wNTowMM4ARIyz"
    },
    "edges": [
      {
        "node": {
          "title": "Recovery of a multiapp simulation",
          "author": {
            "login": "xueyang94"
          },
          "bodyText": "Using FullSolveMultiApp, I have a main-app input file that calls one sub-app file. I also have a checkpoint in the output block of the main-app. My simulation crashed after the sub-app and one time step of the main-app finished. Therefore, the only checkpoint folder generated is 0000_mesh.cpr. When I use the recovery functionality by phase_field-opt -i main.i --recover , I got an error below. It seems like the sub-app (named joined_phase) is run again even though it has already finished executing before crashing. How to fix this error and continue the simulation? Thanks.\n*** Info ***\nUsing /scratch/wuxuey/inputs/nogrgr/nogrgr_main_out_cp/0000 for recovery.\ufffd[39m\n\ufffd[36mjoined_phase0: \ufffd[39mDeleting Remote Elements                                                                 [\ufffd[33m  7.37 s\ufffd[39m] [\ufffd[33m    1 MB\ufffd[39m]\n  Finished Instantiating Sub-Apps                                                        [\ufffd[33m 11.05 s\ufffd[39m] [\ufffd[33m   59 MB\ufffd[39m]\nFinished Setting Up                                                                      [\ufffd[33m 19.75 s\ufffd[39m] [\ufffd[33m  223 MB\ufffd[39m]\nFramework Information:\nMOOSE Version:           git commit baece37 on 2022-09-06\nLibMesh Version:         5fb5bc70cf1b8894b363e5678171ff90c10472bc\nPETSc Version:           3.16.5\nSLEPc Version:           3.16.2\nCurrent Time:            Sun Oct  9 11:56:10 2022\nExecutable Timestamp:    Tue Sep  6 18:56:07 2022\n\nParallelism:\n  Num Processors:          211\n  Num Threads:             1\n\nMesh: \n  Parallel Type:           distributed\n  Mesh Dimension:          2\n  Spatial Dimension:       2\n  Nodes:                   \n    Total:                 121043\n    Local:                 413\n    Min/Max/Avg:           303/3085/573\n  Elems:                   \n    Total:                 115710\n    Local:                 352\n    Min/Max/Avg:           331/2792/548\n  Num Subdomains:          1\n  Num Partitions:          1\n  Partitioner:             parmetis\n\nNonlinear System:\n  Num DOFs:                4115462\n  Num Local DOFs:          14042\n  Num Constrained DOFs:    319464\n  Local Constrained DOFs:  0\n  Variables:               { \"o\" \"cr\" \"mn\" \"fe\" \"o1\" ... \"lambda\" \"muo\" \"mucr\" \"mumn\" \"mufe\" } \n  Finite Element Types:    \"LAGRANGE\" \n  Approximation Orders:    \"FIRST\" \n\nAuxiliary System:\n  Num DOFs:                1762315\n  Num Local DOFs:          5585\n  Num Constrained DOFs:    46980\n  Local Constrained DOFs:  0\n  Variables:               \"va\" { \"bnds\" \"bnds_main\" \"etaa0\" \"etaa1\" \"etaa2\" } { \"etaa0_marker\" \"etaa1_marker\" \n                             \"etaa2_marker\" \"eta1_marker\" \"eta3_marker\" \"eta4_marker\" \"eta5_marker\" \"eta6_marker\" \n                             \"combo\" } \n  Finite Element Types:    \"MONOMIAL\" \"LAGRANGE\" \"MONOMIAL\" \n  Approximation Orders:    \"CONSTANT\" \"FIRST\" \"CONSTANT\" \n\nExecution Information:\n  Executioner:             Transient\n  TimeStepper:             IterationAdaptiveDT\n  Solver Mode:             NEWTON\n  MOOSE Preconditioner:    SMP\n\n\n    Restoring Restart Data\n      Finished Reading RestartableData                                                   [\ufffd[33m  1.19 s\ufffd[39m] [\ufffd[33m  197 MB\ufffd[39m]\n    Finished Restoring Restart Data                                                      [\ufffd[33m  1.19 s\ufffd[39m] [\ufffd[33m  197 MB\ufffd[39m]\n\ufffd[36mjoined_phase0: \ufffd[39mParallelism:\n\ufffd[36mjoined_phase0: \ufffd[39m  Num Processors:          211\n\ufffd[36mjoined_phase0: \ufffd[39m  Num Threads:             1\n\ufffd[36mjoined_phase0: \ufffd[39m\n\ufffd[36mjoined_phase0: \ufffd[39mMesh: \n\ufffd[36mjoined_phase0: \ufffd[39m  Parallel Type:           distributed\n\ufffd[36mjoined_phase0: \ufffd[39m  Mesh Dimension:          2\n\ufffd[36mjoined_phase0: \ufffd[39m  Spatial Dimension:       2\n\ufffd[36mjoined_phase0: \ufffd[39m  Nodes:                   \n\ufffd[36mjoined_phase0: \ufffd[39m    Total:                 2798980\n\ufffd[36mjoined_phase0: \ufffd[39m    Local:                 14029\n\ufffd[36mjoined_phase0: \ufffd[39m    Min/Max/Avg:           12187/14029/13265\n\ufffd[36mjoined_phase0: \ufffd[39m  Elems:                   \n\ufffd[36mjoined_phase0: \ufffd[39m    Total:                 2795580\n\ufffd[36mjoined_phase0: \ufffd[39m    Local:                 13665\n\ufffd[36mjoined_phase0: \ufffd[39m    Min/Max/Avg:           12135/13687/13249\n\ufffd[36mjoined_phase0: \ufffd[39m  Num Subdomains:          1\n\ufffd[36mjoined_phase0: \ufffd[39m  Num Partitions:          1\n\ufffd[36mjoined_phase0: \ufffd[39m  Partitioner:             parmetis\n\ufffd[36mjoined_phase0: \ufffd[39m\n\ufffd[36mjoined_phase0: \ufffd[39mNonlinear System:\n\ufffd[36mjoined_phase0: \ufffd[39m  Num DOFs:                8396940\n\ufffd[36mjoined_phase0: \ufffd[39m  Num Local DOFs:          42087\n\ufffd[36mjoined_phase0: \ufffd[39m  Variables:               { \"etaa0\" \"etaa1\" \"etaa2\" } \n\ufffd[36mjoined_phase0: \ufffd[39m  Finite Element Types:    \"LAGRANGE\" \n\ufffd[36mjoined_phase0: \ufffd[39m  Approximation Orders:    \"FIRST\" \n\ufffd[36mjoined_phase0: \ufffd[39m\n\ufffd[36mjoined_phase0: \ufffd[39mAuxiliary System:\n\ufffd[36mjoined_phase0: \ufffd[39m  Num DOFs:                2798980\n\ufffd[36mjoined_phase0: \ufffd[39m  Num Local DOFs:          14029\n\ufffd[36mjoined_phase0: \ufffd[39m  Variables:               \"bnds\" \n\ufffd[36mjoined_phase0: \ufffd[39m  Finite Element Types:    \"LAGRANGE\" \n\ufffd[36mjoined_phase0: \ufffd[39m  Approximation Orders:    \"FIRST\" \n\ufffd[36mjoined_phase0: \ufffd[39m\n\ufffd[36mjoined_phase0: \ufffd[39mExecution Information:\n\ufffd[36mjoined_phase0: \ufffd[39m  Executioner:             Transient\n\ufffd[36mjoined_phase0: \ufffd[39m  TimeStepper:             IterationAdaptiveDT\n\ufffd[36mjoined_phase0: \ufffd[39m  Solver Mode:             NEWTON\n\ufffd[36mjoined_phase0: \ufffd[39m  MOOSE Preconditioner:    SMP\n\ufffd[36mjoined_phase0: \ufffd[39m\n\n\ufffd[31m\n*** ERROR ***\nThe following error occurred in the object \"Executioner\", of type \"Transient\".\n\nInternal error in Transient executioner: _t_step is equal to 0 while recovering in init().\ufffd[39m\n\n[r3i5n25:mpi_rank_11][MPIDI_CH3_Abort] application called MPI_Abort(MPI_COMM_WORLD, 1) - process 11: Success (0)",
          "url": "https://github.com/idaholab/moose/discussions/22342",
          "updatedAt": "2022-11-15T19:17:20Z",
          "publishedAt": "2022-10-09T20:37:20Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nDoes it recover properly if there are a few more timesteps to run in the multiapp?\nWhat does your executioner block look like in the MultiApp?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22342#discussioncomment-3836267",
                  "updatedAt": "2022-10-10T05:27:08Z",
                  "publishedAt": "2022-10-10T05:27:07Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "xueyang94"
                          },
                          "bodyText": "The sub-app and first step of main-app took 6 days to run. I don't have more time steps yet, but I have started another simulation. This is the executioner block in the main-app:\n[Executioner]\n  type = Transient\n  solve_type = NEWTON\n  petsc_options_iname = '-pc_type -pc_factor_mat_solver_package'\n  petsc_options_value = 'lu       superlu_dist'\n  scheme = bdf2\n  l_max_its = 15\n  l_tol = 1e-4\n  nl_max_its = 800\n  nl_rel_tol = 1e-9\n  nl_abs_tol = 1e-7\n  end_time = 321670 #1925 hours\n  [./TimeStepper]\n    type = IterationAdaptiveDT\n    dt = 1e-3\n    iteration_window = 2\n    optimal_iterations = 10\n    growth_factor = 1.1\n    cutback_factor = 0.75\n  [../]\n[\n```]",
                          "url": "https://github.com/idaholab/moose/discussions/22342#discussioncomment-3839132",
                          "updatedAt": "2022-10-10T13:01:43Z",
                          "publishedAt": "2022-10-10T13:01:43Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "ok and your MultiApps block in the main app?\nThe next step is to build a very reduced example",
                          "url": "https://github.com/idaholab/moose/discussions/22342#discussioncomment-3839584",
                          "updatedAt": "2022-10-10T13:46:31Z",
                          "publishedAt": "2022-10-10T13:46:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "xueyang94"
                          },
                          "bodyText": "This are the multiapp and transfer blocks in the main-app:\n[MultiApps]\n  [joined_phase]\n    type = FullSolveMultiApp\n    execute_on = 'INITIAL'\n    input_files = 'voronoi_sub.i'\n  []\n[]\n\n[Transfers]\n  [from_joined]\n    type = MultiAppMeshFunctionTransfer\n    source_variable = 'bnds etaa0 etaa1 etaa2'\n    variable = 'bnds etaa0 etaa1 etaa2'\n    from_multi_app = joined_phase\n  [../]\n[]",
                          "url": "https://github.com/idaholab/moose/discussions/22342#discussioncomment-3840087",
                          "updatedAt": "2022-10-10T14:41:25Z",
                          "publishedAt": "2022-10-10T14:41:24Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "ok this all looks normal.\nWe should make a minimal working example then we can create an issue and find a resource to fix this",
                          "url": "https://github.com/idaholab/moose/discussions/22342#discussioncomment-3840113",
                          "updatedAt": "2022-10-10T14:43:53Z",
                          "publishedAt": "2022-10-10T14:43:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "xueyang94"
                          },
                          "bodyText": "I have a question. If only one timestep was finished, there should be only one checkpoint folder named 0000_mesh.cpr, correct? And if the first timestep did not finish, there's no checkpoint folder and we should just start over.",
                          "url": "https://github.com/idaholab/moose/discussions/22342#discussioncomment-3840353",
                          "updatedAt": "2022-10-10T15:08:16Z",
                          "publishedAt": "2022-10-10T15:08:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "not sure, checkpoint isnt meant to be used before a single time step for sure",
                          "url": "https://github.com/idaholab/moose/discussions/22342#discussioncomment-3840452",
                          "updatedAt": "2022-10-10T15:16:53Z",
                          "publishedAt": "2022-10-10T15:16:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I d like to have this in an issue. We need a minimal non-working example for this.\nWould you mind producing it? If you cant i can make one too",
                          "url": "https://github.com/idaholab/moose/discussions/22342#discussioncomment-3854632",
                          "updatedAt": "2022-10-11T21:40:38Z",
                          "publishedAt": "2022-10-11T21:40:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "xueyang94"
                          },
                          "bodyText": "Yes I will produce it. I will get back to you before next week.",
                          "url": "https://github.com/idaholab/moose/discussions/22342#discussioncomment-3862514",
                          "updatedAt": "2022-10-12T16:46:38Z",
                          "publishedAt": "2022-10-12T16:46:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "xueyang94"
                          },
                          "bodyText": "@GiudGiud I have created a mainapp and a subapp as below. It is a simple 3-phase 2-component KKS model with simple free energies. For testing, I terminate the mainapp after the subapp has finished, and the mainapp has run for a few steps. For recovery, I run the mainapp again with --recover flag. The recovery would crash. Could you please check if the recovery and transfer codes are correct? Then I can create an issue. Thanks.\nmainapp:\n[Executioner]\n  type = Transient\n  solve_type = NEWTON\n  petsc_options_iname = '-pc_type -pc_factor_mat_solver_package'\n  petsc_options_value = 'lu       superlu_dist'\n  scheme = bdf2\n  l_max_its = 15\n  l_tol = 1e-4\n  nl_max_its = 800\n  nl_rel_tol = 1e-9\n  nl_abs_tol = 1e-7\n  dt = 1e-3\n  num_steps = 10\n[]\n\n[Adaptivity]\n  [./Markers]\n    [./etaa0_marker]\n      type = ValueRangeMarker\n      variable = etaa0\n      upper_bound = 0.9\n      lower_bound = 0.1\n    [../]\n    [./etaa1_marker]\n      type = ValueRangeMarker\n      variable = etaa1\n      upper_bound = 0.9\n      lower_bound = 0.1\n    [../]\n    [./eta1_marker]\n      type = ValueRangeMarker\n      variable = eta1\n      upper_bound = 0.9\n      lower_bound = 0.1\n    [../]\n    [./eta2_marker]\n      type = ValueRangeMarker\n      variable = eta2\n      upper_bound = 0.9\n      lower_bound = 0.1\n    [../]\n    [./eta3_marker]\n      type = ValueRangeMarker\n      variable = eta3\n      upper_bound = 0.9\n      lower_bound = 0.1\n    [../]\n    [./combo]\n      type = ComboMarker\n      markers = 'etaa0_marker etaa1_marker eta1_marker eta2_marker eta3_marker'\n    [../]\n  [../]\nmarker = combo\ninitial_marker = combo\nrecompute_markers_during_cycles = true\ninitial_steps = 2\nmax_h_level = 2\n[]\n\n[Mesh]\n  [gmg]\n     type = DistributedRectilinearMeshGenerator\n     dim = 2\n     nx = 38\n     xmin = 0\n     xmax = 30\n     ny = 13\n     ymin = 0\n     ymax = 10\n     elem_type = QUAD4\n   []\n  parallel_type = DISTRIBUTED\n[]\n\n[MultiApps]\n  [joined_phase]\n    type = FullSolveMultiApp\n    execute_on = INITIAL\n    input_files = 'poly_sub.i'\n  []\n[]\n\n[Transfers]\n  [from_joined]\n    type = MultiAppMeshFunctionTransfer\n    source_variable = 'bnds etaa0 etaa1'\n    variable = 'bnds etaa0 etaa1'\n    from_multi_app = joined_phase\n    execute_on = INITIAL\n  [../]\n[]\n\n[Preconditioning]\n  [./full]\n    type = SMP\n    full = true\n  [../]\n[]\n\n[Outputs]\n  exodus = true\n  csv = true\n  [./out]\n    type = Checkpoint\n    num_files = 4\n    interval = 2\n  [../]\n[]\n\n[Variables]\n  [./eta1]\n  [../]\n  [./eta2]\n  [../]\n  [./eta3]\n  [../]\n  [./lambda]\n  [../]\n  [./c]\n  [../]\n  [./c1]\n    initial_condition = 0.3\n  [../]\n  [./c2]\n    initial_condition = 0.5\n  [../]\n  [./c3]\n    initial_condition = 0.8\n  [../]\n  [./mu]\n  [../]\n[]\n\n[AuxVariables]\n  [./bnds] # transferred from subapp\n  [../]\n  [./bnds_main]\n  [../]\n  [./etaa0]\n  [../]\n  [./etaa1]\n  [../]\n[]\n\n[AuxKernels]\n  [./bnds_main_aux]\n    type = BndsCalcAux\n    variable = bnds_main\n    v = 'etaa0 etaa1 eta2 eta3'\n    execute_on = 'initial timestep_end'\n  [../]\n[]\n\n[ICs]\n  [./eta1]\n    type = NestedBoundingBoxIC\n    variable = eta1\n    smaller_coordinate_corners = '-4 -4 0 '\n    larger_coordinate_corners = '10 14 0'\n    inside = '1'\n  [../]\n  [./eta2]\n    type = NestedBoundingBoxIC\n    variable = eta2\n    smaller_coordinate_corners = '10 -4 0 '\n    larger_coordinate_corners = '20 14 0'\n    inside = '1'\n  [../]\n  [./eta3]\n    type = NestedBoundingBoxIC\n    variable = eta3\n    smaller_coordinate_corners = '20 -4 0'\n    larger_coordinate_corners = '34 14 0'\n    inside = '1'\n  [../]\n  [./c]\n    type = NestedBoundingBoxIC\n    variable = c\n    smaller_coordinate_corners = '-4 -4 0 10 -4 0'\n    larger_coordinate_corners = '10 14 0 20 14 0'\n    inside = '0.3 0.5'\n    outside = 0.8\n  [../]\n[]\n\n[GlobalParams]\n  Fj_names  = 'F1 F2 F3'\n  hj_names  = 'h1 h2 h3'\n  wi = 0.02\n  int_width = 1\n  derivative_order = 2\n  evalerror_behavior = error\n  enable_ad_cache = false\n  enable_jit = false\n  epsilon = 1e-9 # used in lambda kernel, default\n[]\n\n[Materials]\n  [./const]\n    type = GenericConstantMaterial\n    prop_names =  'sigma   L  '\n    prop_values = '0.20   1e-2'\n  [../]\n  [./kappa]\n    type = ParsedMaterial\n    f_name = kappa\n    constant_names = 'lgb'\n    constant_expressions = '1'\n    material_property_names = 'sigma'\n    function = '3*sigma*lgb/4'\n  [../]\n  [./w]\n    type = ParsedMaterial\n    f_name = w\n    constant_names = 'lgb'\n    constant_expressions = '1'\n    material_property_names = 'sigma'\n    function = '6*sigma/lgb'\n  [../]\n\n  [./F1]\n    type = DerivativeParsedMaterial\n    f_name = F1\n    args = 'c1'\n    function = '(c1 - 0.3)^2'\n  [../]\n  [./F2]\n    type = DerivativeParsedMaterial\n    f_name = F2\n    args = 'c2'\n    function = '(c2 - 0.7)^2 - 10'\n  [../]\n  [./F3]\n    type = DerivativeParsedMaterial\n    f_name = F3\n    args = 'c3'\n    function = '(c3 - 0.4)^2'\n  [../]\n\n  [./h1]\n    type = SwitchingFunctionMaterial\n    eta = eta1\n    h_order = HIGH\n    function_name = h1\n  [../]\n  [./h2]\n    type = SwitchingFunctionMaterial\n    eta = eta2\n    h_order = HIGH\n    function_name = h2\n  [../]\n  [./h3]\n    type = SwitchingFunctionMaterial\n    eta = eta3\n    h_order = HIGH\n    function_name = h3\n  [../]\n\n  [./g]\n    type = DerivativeParsedMaterial\n    constant_names = 'gamma'\n    constant_expressions = '1.5'\n    f_name = g\n    function = '(eta1^4/4 - eta1^2/2) + (eta2^4/4 - eta2^2/2) + (eta3^4/4 - eta3^2/2) +\n                gamma * ((eta1*eta2)^2 + (eta1*eta3)^2 + (eta2*eta3)^2) + 1/4'\n    args = 'eta1 eta2 eta3'\n  [../]\n\n  [./M]\n    type = DerivativeParsedMaterial\n    f_name = M\n    material_property_names = 'h1(eta1) h2(eta2) h3(eta3)'\n    args = 'eta1 eta2 eta3 bnds'\n    constant_names =       'M1_bulk M1_gb  M2 M3'\n    constant_expressions = '10      1000   50 80'\n    function = 'if(bnds>0.9, h1*M1_bulk + h2*M2 + h3*M3, h1*M1_gb + h2*M2 + h3*M3)'\n  [../]\n[]\n\n[Kernels]\n  [./lambda_lagrange]\n    type = SwitchingFunctionConstraintLagrange\n    variable = lambda\n    etas =    'eta1 eta2 eta3'\n    h_names = 'h1   h2   h3'\n  [../]\n  [./eta1_lagrange]\n    type = SwitchingFunctionConstraintEta\n    variable = eta1\n    h_name = h1\n    lambda = lambda\n  [../]\n  [./eta2_lagrange]\n    type = SwitchingFunctionConstraintEta\n    variable = eta2\n    h_name = h2\n    lambda = lambda\n  [../]\n  [./eta3_lagrange]\n    type = SwitchingFunctionConstraintEta\n    variable = eta3\n    h_name = h3\n    lambda = lambda\n  [../]\n\n  [./phase_concentration]\n    type = KKSMultiPhaseConcentration\n    variable = c3\n    cj = 'c1 c2 c3'\n    etas = 'eta1 eta2 eta3'\n    c = c\n  [../]\n\n  [./chempot12]\n    type = KKSPhaseChemicalPotential\n    variable = c1\n    cb = c2\n    fa_name = F1\n    fb_name = F2\n  [../]\n  [./chempot23]\n    type = KKSPhaseChemicalPotential\n    variable = c2\n    cb = c3\n    fa_name = F2\n    fb_name = F3\n  [../]\n\n  # kernels for diffusion equation\n  [./CHBulk]\n    type = KKSSplitCHCRes\n    variable = c\n    w = mu\n    ca = c1\n    fa_name = F1\n  [../]\n  [./dcdt]\n    type = CoupledTimeDerivative\n    variable = mu\n    v = c\n  [../]\n  [./ckernel]\n    type = SplitCHWRes\n    variable = mu\n    mob_name = M\n    args = 'eta1 eta2 eta3'\n  [../]\n\n  # Kernels for Allen-Cahn equation\n  [./ACBulkF1]\n    type = KKSMultiACBulkF\n    variable  = eta1\n    gi_name   = g\n    eta_i     = eta1\n    args = 'eta2 eta3 c1 c2 c3'\n    mob_name = L\n  [../]\n  [./ACBulkC1]\n    type = KKSMultiACBulkC\n    variable  = eta1\n    cj_names  = 'c1 c2 c3'\n    eta_i     = eta1\n    args = 'eta2 eta3 c1 c2 c3'\n    mob_name = L\n  [../]\n  [./ACInterface1]\n    type = ACInterface\n    variable = eta1\n    kappa_name = kappa\n    mob_name = L\n    args      = 'eta2 eta3'\n  [../]\n  [./deta1dt]\n    type = TimeDerivative\n    variable = eta1\n  [../]\n\n  [./ACBulkF2]\n    type = KKSMultiACBulkF\n    variable  = eta2\n    gi_name   = g\n    eta_i     = eta2\n    args = 'eta1 eta3 c1 c2 c3'\n    mob_name = L\n  [../]\n  [./ACBulkC2]\n    type = KKSMultiACBulkC\n    variable  = eta2\n    cj_names  = 'c1 c2 c3'\n    eta_i     = eta2\n    args = 'eta1 eta3 c1 c2 c3'\n    mob_name = L\n  [../]\n  [./ACInterface2]\n    type = ACInterface\n    variable = eta2\n    kappa_name = kappa\n    mob_name = L\n    args      = 'eta1 eta3'\n  [../]\n  [./deta2dt]\n    type = TimeDerivative\n    variable = eta2\n  [../]\n\n  [./ACBulkF3]\n    type = KKSMultiACBulkF\n    variable  = eta3\n    gi_name   = g\n    eta_i     = eta3\n    args = 'eta1 eta2 c1 c2 c3'\n    mob_name = L\n  [../]\n  [./ACBulkC3]\n    type = KKSMultiACBulkC\n    variable  = eta3\n    cj_names  = 'c1 c2 c3'\n    eta_i     = eta3\n    args = 'eta1 eta2 c1 c2 c3'\n    mob_name = L\n  [../]\n  [./ACInterface3]\n    type = ACInterface\n    variable = eta3\n    kappa_name = kappa\n    mob_name = L\n    args      = 'eta1 eta2'\n  [../]\n  [./deta3dt]\n    type = TimeDerivative\n    variable = eta3\n  [../]\n[]\n\n\nsubapp:\n[Executioner]\n  type = Transient\n  solve_type = NEWTON\n  petsc_options_iname = '-pc_type -pc_factor_mat_solver_package'\n  petsc_options_value = 'lu       superlu_dist'\n  scheme = bdf2\n  l_max_its = 15\n  l_tol = 1e-4\n  nl_max_its = 800\n  nl_rel_tol = 1e-9\n  nl_abs_tol = 1e-7\n  num_steps = 50\n  dt = 1e-3\n[]\n\n[Adaptivity]\n  [./Markers]\n    [./etaa0_marker]\n      type = ValueRangeMarker\n      variable = etaa0\n      upper_bound = 0.9\n      lower_bound = 0.1\n    [../]\n    [./etaa1_marker]\n      type = ValueRangeMarker\n      variable = etaa1\n      upper_bound = 0.9\n      lower_bound = 0.1\n    [../]\n    [./combo]\n      type = ComboMarker\n      markers = 'etaa0_marker etaa1_marker'\n    [../]\n  [../]\nmarker = combo\nrecompute_markers_during_cycles = true\ninitial_steps = 2\nmax_h_level = 2\n[]\n\n[Mesh]\n  [gen]\n    type = DistributedRectilinearMeshGenerator\n    dim = 2\n    xmin = 0\n    xmax = 10\n    nx = 13\n    ymin = 0\n    ymax = 10\n    ny = 13\n    elem_type = QUAD4\n  []\n  parallel_type = DISTRIBUTED\n[]\n\n[Preconditioning]\n  [./full]\n    type = SMP\n    full = true\n  [../]\n[]\n\n[Outputs]\n  exodus = true\n  csv = true\n[]\n\n[Variables]\n  [./PolycrystalVariables]\n  [../]\n[]\n\n[ICs]\n  [./etaa0]\n    type = NestedBoundingBoxIC\n    variable = etaa0\n    smaller_coordinate_corners = '-2 -2 0'\n    larger_coordinate_corners = '12 5 0'\n    inside = 1\n    int_width = 1\n  [../]\n  [./etaa1]\n    type = NestedBoundingBoxIC\n    variable = etaa1\n    smaller_coordinate_corners = '-2 5 0'\n    larger_coordinate_corners = '12 12 0'\n    inside = 1\n    int_width = 1\n  [../]\n[]\n\n[GlobalParams]\n  op_num = 2\n  var_name_base = etaa\n[]\n\n[AuxVariables]\n  [./bnds]\n  [../]\n[]\n\n[AuxKernels]\n  [./bnds_aux]\n    type = BndsCalcAux\n    variable = bnds\n    execute_on = 'initial timestep_end'\n  [../]\n[]\n\n[Materials]\n  [./const]\n    type = GenericConstantMaterial\n    prop_names =  'gamma_asymm sigma    l    L'\n    prop_values = '1.5         0.2      1   1e-2'\n  [../]\n  [./kappa_op]\n    type = ParsedMaterial\n    f_name = kappa_op\n    material_property_names = 'sigma l'\n    function = '3*sigma*l/4'\n  [../]\n  [./mu]\n    type = ParsedMaterial\n    f_name = mu\n    material_property_names = 'sigma l'\n    function = '6*sigma/l'\n  [../]\n[]\n\n[Kernels]\n  [./PolycrystalKernel]\n  [../]\n[]",
                          "url": "https://github.com/idaholab/moose/discussions/22342#discussioncomment-3892028",
                          "updatedAt": "2022-10-17T01:34:10Z",
                          "publishedAt": "2022-10-17T01:34:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "this is a little too complicated for a MWE.\nIn particular it d be good to remove adaptivity, unless it's actually part of the problem",
                          "url": "https://github.com/idaholab/moose/discussions/22342#discussioncomment-3900169",
                          "updatedAt": "2022-10-17T20:33:47Z",
                          "publishedAt": "2022-10-17T20:33:46Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Access out of bounds in MooseArray",
          "author": {
            "login": "heinono1"
          },
          "bodyText": "Hi,\nI am building a FV version of ferret. After successfully compiling and linking (and checking the input file) execution throws an error:\nAssertion `i < _size ' failed\nAccess out of bounds in MooseArray (i: 0 size: 0)\nat /home/olle/projects/moose/framework/build/header_symlinks/MooseArray.h, line 276\nI have pinned down that the problem is generated in the FV kernels I built. The FVTimeKernel works, but when I add a first extra kernel (FVMagneticExchangeCons.C), the execution error shows up. The kernel is modeled after the FVDiffusion.C kernel.\nI note that there were some postings about this error before, but not in the FV stuff.  Below is the input, and source and header files of the offending kernel. Any help will be greatly appreciated.\nInput file:\nalphadef = 0.25\n\n[Mesh]\n  [./mesh]\n    type = GeneratedMeshGenerator\n    dim = 3\n    nx = 80\n    ny = 40\n    nz = 12\n    xmin = -200\n    xmax = 200\n    ymin = -100\n    ymax = 100\n    zmin = -30\n#    block_id = 1\n#    block_name = brick\n  [../]\n[]\n\n\n#[GlobalParams]\n#  mag_x = mag_x\n#  mag_y = mag_y\n#  mag_z = mag_z\n#   Ae = Ae\n#   g0 = g0\n#   Ms = Ms\n#   alpha = alpha\n#[]\n\n[Materials]\n  ############################################################################\n  ##\n  ##       material constants used.\n  ## Materials are defined as ADGenericFunctorMaterial - have to convert to real\n  ## auxiliary variables to evaluate flux kernels\n  ##\n  ##34989.1\n  ############################################################################\n\n  [./constants] \n    type = ADGenericFunctorMaterial\n    prop_names = ' alpha           g0mu0Ms        g0       permittivity Ae      Ms' #   mu0'\n    prop_values = '${alphadef}     34989.1     34989.1       1.0        13.0   -1.0' #  1.0'\n#    block = '1'\n  [../]\n\n\n  [./a_long]\n    type = ADGenericFunctorMaterial\n    prop_names = 'alpha_long'\n    prop_values = '10.'\n#    block = '1' \n  [../]\n\n[]\n\n[Variables]\n  [./mag_x]\n    order = CONSTANT\n    family = MONOMIAL\n#    block = '1'\n    fv = true\n  [../]\n  [./mag_y]\n    order = CONSTANT\n    family = MONOMIAL\n#    block = '1'\n    fv = true\n  [../]\n  [./mag_z]\n    order = CONSTANT\n    family = MONOMIAL\n#    block= '1'\n    fv = true\n  [../]\n[]\n\n[AuxVariables]\n\n  [./mag_s]\n    type = MooseVariableFVReal\n#    block = '1'\n  [../]\n  [./Ae_elem]\n    type = MooseVariableFVReal\n#    block = '1'\n  [../]\n  [./Ms_elem]\n    type = MooseVariableFVReal\n#    block = '1'\n  [../]\n  [./alpha_elem]\n    type = MooseVariableFVReal\n#    block = '1'\n  [../]\n  [./alpha_long_elem]\n    type = MooseVariableFVReal\n#    block = '1'\n  [../]\n  [./g0_elem]\n    type = MooseVariableFVReal\n#    block = '1'\n  [../]\n[../]\n\n\n[AuxKernels]\n  [./mag_mag]\n    type = FVVectorMag\n    variable = mag_s\n    vector_x = mag_x\n    vector_y = mag_y\n    vector_z = mag_z\n    execute_on = 'initial timestep_end final'\n#    block = '1'\n  [../]\n  [./get_Ae]\n    type = ADFunctorElementalAux\n    functor = 'Ae'\n    variable = 'Ae_elem'\n#    block = '1'\n    execute_on = 'initial'\n  [../]\n  [./get_Ms]\n    type = ADFunctorElementalAux\n    functor = 'Ms'\n    variable = 'Ms_elem'\n#    block = '1'\n    execute_on = 'initial'\n  [../]\n  [./get_alpha]\n    type = ADFunctorElementalAux\n    functor = 'alpha'\n    variable = 'alpha_elem'\n#    block = '1'\n    execute_on = 'initial'\n  [../]\n    [./get_alpha_long]\n    type = ADFunctorElementalAux\n    functor = 'alpha_long'\n    variable = 'alpha_long_elem'\n#    block = '1'\n    execute_on = 'initial'\n  [../]\n  [./get_g0]\n    type = ADFunctorElementalAux\n    functor = 'g0'\n    variable = 'g0_elem'\n#    block = '1'\n    execute_on = 'initial'\n  [../]\n[]\n\n\n[FVKernels]\n  #---------------------------------------#\n  #                                       #\n  #          Time dependence              #\n  #                                       #\n  #---------------------------------------#\n\n  [./mag_x_time]\n    type = FVTimeKernel\n    variable = mag_x\n#    block = '1'\n  [../]\n  [./mag_y_time]\n    type = FVTimeKernel\n    variable = mag_y\n#    block = '1'\n  [../]\n  [./mag_z_time]\n    type = FVTimeKernel\n    variable = mag_z\n#    block = '1'\n  [../]\n\n  #---------------------------------------#\n  #                                       #\n  #    Local magnetic exchange            #\n  #                                       #\n  #---------------------------------------#\n  \n  [./exch_x_cons]\n    type = FVMagneticExchangeCons\n    variable = mag_x\n    component = 0\n#    Ae = Ae\n#    Ms = Ms\n#    g0 = g0\n#    alpha = alpha\n    mag_x = mag_x\n    mag_y = mag_y\n    mag_z = mag_z\n#    block = '1'\n  [../]\n#  [./exch_y_cons]\n#    type = FVMagneticExchangeCons\n#    variable = mag_y\n#    component = 1\n#    mag_x = mag_x\n#    mag_y = mag_y\n#    mag_z = mag_z\n#    block = '1'\n#  [../]\n#  [./exch_z_cons]\n#    type = FVMagneticExchangeCons\n#    variable = mag_z\n#    component = 2\n#    mag_x = mag_x\n#    mag_y = mag_y\n#    mag_z = mag_z\n#    block = '1'\n#  [../]\n  \n\n  #---------------------------------------#\n  #                                       #\n  #    demagnetization field              #\n  #                                       #\n  #---------------------------------------#\n\n\n[]\n\n\n[Postprocessors]\n   [./dt]\n     type = TimestepSize\n   [../]\n[]\n\n[Preconditioning]\n\n  #---------------------------------------#\n  #                                       #\n  #            Solver options             #\n  #                                       #\n  #---------------------------------------#\n\n  [./smp]\n    type = SMP\n    full = true\n    petsc_options_iname = ' -ksp_gmres_restart -snes_atol -snes_rtol -ksp_rtol -pc_type -sub_ksp_type -sub_pc_type -pc_asm_overlap'\n    petsc_options_value = '    31               1e-9      1e-9      1e-8        bjacobi      preonly       ilu           2'\n  [../]\n[]\n\n[Executioner]\n  type = Transient            \n  solve_type = 'NEWTON'\n\n  [./TimeIntegrator]\n    type = NewmarkBeta #LStableDirk4 #NewmarkBeta\n  [../]\n\n  dtmin = 1.e-7\n  dtmax = 2.e-5\n\n  [./TimeStepper]\n    type = IterationAdaptiveDT\n    optimal_iterations = 25  #usually 10\n    linear_iteration_ratio = 100\n    dt = 1e-8\n    growth_factor = 1.1\n    cutback_factor = 0.75\n  [../]\n  num_steps = 1500\n[../]\n\n[Outputs]\n  print_linear_residuals = false\n\n  [./out]\n    type = Exodus\n    file_base = brick\n    elemental_as_nodal = true\n    interval = 1\n  [../]\n  [./outCSV]\n    type = CSV\n    file_base = brick\n    interval = 1\n  [../]\n[]\n-----------------------------------------------------------------------------------------------------------------------\nSource file:\n#include \"FVMagneticExchangeCons.h\"\n#include \"RelationshipManager.h\"\n\nregisterMooseObject(\"FerretApp\", FVMagneticExchangeCons);\n\nInputParameters\nFVMagneticExchangeCons::validParams()\n{\n  InputParameters params = FVFluxKernel::validParams();\n  params.addClassDescription(\"Computes residual of conservative exchange torque\");\n  params.addRequiredParam<unsigned int>(\"component\", \"An integer corresponding to the direction in order parameter space\");\n  /*  params.addRequiredParam<MooseFunctorName>(\"alpha\", \"damping coefficient\");\n  params.addRequiredParam<MooseFunctorName>(\"g0\", \"g0 coefficient\");\n  params.addRequiredParam<MooseFunctorName>(\"Ms\", \"magnetization density\");\n  params.addRequiredParam<MooseFunctorName>(\"Ae\", \"exchange coupling\");*/\n  params.addRequiredCoupledVar(\"mag_x\", \"The x component of the constrained magnetic vector\");\n  params.addRequiredCoupledVar(\"mag_y\", \"The y component of the constrained magnetic vector\");\n  params.addRequiredCoupledVar(\"mag_z\", \"The z component of the constrained magnetic vector\");\n  //  MooseEnum coeff_interp_method(\"average\", \"harmonic\");\n  MooseEnum coeff_interp_method(\"average\");  \n  params.addParam<MooseEnum>(\n\t\t\t     \"coeff_interp_method\",\n\t\t\t     coeff_interp_method,\n\t\t\t     \"Switch that can select interpolation method for magnetization density.\"); \n  params.set<unsigned short>(\"ghost_layers\") = 2;\n  return params;\n}\n\nFVMagneticExchangeCons::FVMagneticExchangeCons(const InputParameters & params)\n  : FVFluxKernel(params), /*_coeff(getFunctor<ADReal>(\"coeff\")),*/\n   _component(getParam<unsigned int>(\"component\")),\n   _mag_x_var(coupled(\"mag_x\")),\n   _mag_y_var(coupled(\"mag_y\")),\n   _mag_z_var(coupled(\"mag_z\")),\n   _mag_x(coupledValue(\"mag_x\")),\n   _mag_y(coupledValue(\"mag_y\")),\n   _mag_z(coupledValue(\"mag_z\")),\n   _mag_x_grad(coupledGradient(\"mag_x\")),\n   _mag_y_grad(coupledGradient(\"mag_y\")),\n   _mag_z_grad(coupledGradient(\"mag_z\"))\n    /*   _alpha(getFunctor<ADReal>(\"alpha\")),   \n   _g0(getFunctor<ADReal>(\"g0\")),\n   _Ms(getFunctor<ADReal>(\"Ms\")),\n   _Ae(getFunctor<ADReal>(\"Ae\"))*/\n    /*   _alpha_elem(coupledValue(\"alpha_elem\")),   \n   _g0_elem(coupledValue(\"g0_elem\")),\n   _Ms_elem(coupledValue(\"Ms_elem\")),\n   _Ae_elem(coupledValue(\"Ae_elem\"))*/\n{\n#ifndef MOOSE_GLOBAL_AD_INDEXING\n  mooseError(\n      \"FVMagneticExchangeCons is not supported by local AD indexing. In order to use this object, please run \"\n      \"the configure script in the root MOOSE directory with the configure option \"\n      \"'--with-ad-indexing-type=global'. Note that global indexing is now the default \"\n      \"configuration for AD indexing type.\");\n#endif\n\n  const auto & interp_method = getParam<MooseEnum>(\"coeff_interp_method\");\n  //const auto _coeff_interp_method;\n  if (interp_method == \"average\")\n    const auto _coeff_interp_method = Moose::FV::InterpMethod::Average;\n  /*else if (interp_method == \"harmonic\")\n    _coeff_interp_method = Moose::FV::InterpMethod::HarmonicAverage;*/\n\n  if ((_var.faceInterpolationMethod() == Moose::FV::InterpMethod::SkewCorrectedAverage) &&\n      (_tid == 0))\n     adjustRMGhostLayers(std::max((unsigned short)(3), _pars.get<unsigned short>(\"ghost_layers\")));\n}\n\nADReal\nFVMagneticExchangeCons::computeQpResidual()\n{\n  //  auto mgradm = 0.;\n  if (_component == 0)\n    {\n      //      auto mgradm =\n      return\t_normal(0)*(_mag_y[_qp]*_mag_z_grad[_qp](0)-_mag_z[_qp]*_mag_y_grad[_qp](0)) +\n\t_normal(1)*(_mag_y[_qp]*_mag_z_grad[_qp](1)-_mag_z[_qp]*_mag_y_grad[_qp](1)) +\n\t_normal(2)*(_mag_y[_qp]*_mag_z_grad[_qp](2)-_mag_z[_qp]*_mag_y_grad[_qp](2));\n     }\n  else if (_component == 1)\n    {\n      //      auto mgradm =\n      return\t_normal(0)*(_mag_z[_qp]*_mag_x_grad[_qp](0)-_mag_x[_qp]*_mag_z_grad[_qp](0)) +\n\t_normal(1)*(_mag_z[_qp]*_mag_x_grad[_qp](1)-_mag_x[_qp]*_mag_z_grad[_qp](1)) +\n\t_normal(2)*(_mag_z[_qp]*_mag_x_grad[_qp](2)-_mag_x[_qp]*_mag_z_grad[_qp](2));\n     }\n    else if (_component == 2)\n    {\n      //      auto mgradm =\n      return\t_normal(0)*(_mag_x[_qp]*_mag_y_grad[_qp](0)-_mag_y[_qp]*_mag_x_grad[_qp](0)) +\n\t_normal(1)*(_mag_x[_qp]*_mag_y_grad[_qp](1)-_mag_y[_qp]*_mag_x_grad[_qp](1)) +\n\t_normal(2)*(_mag_x[_qp]*_mag_y_grad[_qp](2)-_mag_y[_qp]*_mag_x_grad[_qp](2));\n     }\n  //    else\n  return 0.;     \n  //      auto mgradm = 0.;\n  // Perform weighted-average or central differencing (CD) interpolation of coefficients\n   // Perform weighted-average or central differencing (CD) interpolation of constants\n  /*  ADReal M0k;\n  interpolate(_coeff_interp_method,M0k,_Ms(elemFromFace()),_Ms(neighborFromFace()),*_face_info, true);\n  ADReal Aek;\n  interpolate(_coeff_interp_method,Aek,_Ae(elemFromFace()),_Ae(neighborFromFace()),*_face_info, true);\n  ADReal g0k;\n  interpolate(_coeff_interp_method,g0k,_g0(elemFromFace()),_g0(neighborFromFace()),*_face_info, true);\n  ADReal alphak;\n  interpolate(_coeff_interp_method,alphak,_alpha(elemFromFace()),_alpha(neighborFromFace()),*_face_info, true);*/\n  \n\n  //  return 2.* Aek *g0k * mgradm/((1.+ Utility::pow<2>(alphak))*M0k);\n}\n\n\nHeader file:\n#pragma once\n\n#include \"FVFluxKernel.h\"\n\n/// FVDiffusion implements a standard diffusion term:\n///\n///     - strong form: \\nabla \\cdot k \\nabla u\n///\n///     - weak form: \\int_{A} k \\nabla u \\cdot \\vec{n} dA\n///\n/// It uses/requests a material property named \"coeff\" for k. An average of\n/// the elem and neighbor k-values (which should be face-values) is used to\n/// compute k on the face. Cross-diffusion correction factors are currently not\n/// implemented for the \"grad_u*n\" term.\nclass FVMagneticExchangeCons : public FVFluxKernel\n{\npublic:\n  static InputParameters validParams();\n  FVMagneticExchangeCons(const InputParameters & params);\n\nprotected:\n  virtual ADReal computeQpResidual() override;\n\n  private:\n  \n  const unsigned int _component;\n  const unsigned int _mag_x_var;\n  const unsigned int _mag_y_var;\n  const unsigned int _mag_z_var;\n  const VariableValue & _mag_x;\n  const VariableValue & _mag_y;\n  const VariableValue & _mag_z;\n  const VariableGradient & _mag_x_grad;\n  const VariableGradient & _mag_y_grad;\n  const VariableGradient & _mag_z_grad;\n  /*  const VariableValue & _alpha_elem;\n  const VariableValue & _g0_elem;\n  const VariableValue & _Ms_elem;\n  const VariableValue & _Ae_elem;*/\n  /*  const Moose::Functor<ADReal> & _alpha;\n  const Moose::Functor<ADReal> & _g0;\n  const Moose::Functor<ADReal> & _Ms;\n  const Moose::Functor<ADReal> & _Ae;*/\n    /// Decides if a geometric arithmetic or harmonic average is used for the\n  /// face interpolation of the diffusion coefficient.\n  Moose::FV::InterpMethod _coeff_interp_method;\n\n  //const Moose::Functor<ADReal> & _coeff;\n};",
          "url": "https://github.com/idaholab/moose/discussions/22464",
          "updatedAt": "2022-11-15T19:00:41Z",
          "publishedAt": "2022-10-21T20:10:02Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "unrelated but this needs to change from\n  if (interp_method == \"average\")\n    const auto _coeff_interp_method = Moose::FV::InterpMethod::Average;\n\nto this\n  if (interp_method == \"average\")\n    _coeff_interp_method = Moose::FV::InterpMethod::Average;\n\nalso if you are passing harmonic, you are not triggering this if at all, so _coeff_interp_method will not be initialized.\nNow what I think is the problem:\nNewmarkBeta is specialized to tensor mechanics. It's not useable in the general case, you need to be calculating special quantities and this is not set up in finite volume yet (it might not be necessary to set anything up for FV, but definitely for kernels).\nPlease use implicit Euler to form your model and then switch to higher order once you have something working",
                  "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3936947",
                  "updatedAt": "2022-10-21T20:22:45Z",
                  "publishedAt": "2022-10-21T20:19:20Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "heinono1"
                  },
                  "bodyText": "Hi Guillermo,\n\nOddly enough, with just FVTimeKernel and using NewmarkBeta that error did\nnot show up. Anyhow, I changed time integrator to ImplicitEuler - still\nsame error. So it does not seem like NewmarkBeta was causing the error - it\nseems to be caused by FVMagneticExchangeCons\n\u2026\nOn Fri, Oct 21, 2022 at 3:19 PM Guillaume Giudicelli < ***@***.***> wrote:\n unrelated but this needs to change from\n\n   if (interp_method == \"average\")\n     const auto _coeff_interp_method = Moose::FV::InterpMethod::Average;\n\n to this\n\n   if (interp_method == \"average\")\n     _coeff_interp_method = Moose::FV::InterpMethod::Average;\n\n also if you are passing harmonic, you are not triggering this if at all,\n so _coeff_interp_method will not be initialized.\n\n Now the problem:\n NewmarkBeta is specialized to tensor mechanics. It's not useable in the\n general case, you need to be calculating special quantities and this is not\n set up in finite volume yet.\n\n Please use implicit Euler to form your model and then switch to higher\n order once you have something working\n\n \u2014\n Reply to this email directly, view it on GitHub\n <#22464 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AEKZEFZFZLPDHECWKXC266LWEL3FFANCNFSM6AAAAAARLPGKXY>\n .\n You are receiving this because you authored the thread.Message ID:\n ***@***.***>\n\n\n-- \nOlle Heinonen\n***@***.***",
                  "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3937237",
                  "updatedAt": "2022-10-21T21:23:50Z",
                  "publishedAt": "2022-10-21T21:23:49Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I guess I was mistaken about the source. My advice still stands.\nSo you should be able to get a full backtrace on this error if you use a debugger\nhttps://mooseframework.inl.gov/application_development/debugging.html\nthen we ll know which line is problematic",
                          "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3937253",
                          "updatedAt": "2022-10-21T21:29:36Z",
                          "publishedAt": "2022-10-21T21:29:35Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "heinono1"
                  },
                  "bodyText": "Thanks. Yeah I changed the lines related to interp_method (I have not\npulled a newer dist that should have the harmonic average fixed). I'll get\non with the debugger\n\u2026\nOn Fri, Oct 21, 2022 at 4:29 PM Guillaume Giudicelli < ***@***.***> wrote:\n I guess I was mistaken about the source. My advice still stands.\n\n So you should be able to get a full backtrace on this error if you use a\n debugger\n https://mooseframework.inl.gov/application_development/debugging.html\n then we ll know which line is problematic\n\n \u2014\n Reply to this email directly, view it on GitHub\n <#22464 (reply in thread)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AEKZEF7AFKLMKVRXU3XN5M3WEMDMVANCNFSM6AAAAAARLPGKXY>\n .\n You are receiving this because you authored the thread.Message ID:\n ***@***.***>\n\n\n-- \nOlle Heinonen\n***@***.***",
                  "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3937272",
                  "updatedAt": "2022-10-21T21:34:31Z",
                  "publishedAt": "2022-10-21T21:34:30Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "heinono1"
                  },
                  "bodyText": "Hi Guillaume,\nThe error occurs in the FV kernel when I try to access the gradients of the\nnonlinear variables. Specifically, in the kernel (computeQpResidual), if I\nhave\nreturn _normal(0)*mag_z[_qp];\nthe codes run fine. If I change to\n\nreturn _normal(0)*mag_z[_qp]*_mag_z_grad[_qp](0);\n\nthen I get the error.\n\nOn Fri, Oct 21, 2022 at 4:34 PM Olle Heinonen ***@***.***>\nwrote:\n\u2026\n Thanks. Yeah I changed the lines related to interp_method (I have not\n pulled a newer dist that should have the harmonic average fixed). I'll get\n on with the debugger\n\n On Fri, Oct 21, 2022 at 4:29 PM Guillaume Giudicelli <\n ***@***.***> wrote:\n\n> I guess I was mistaken about the source. My advice still stands.\n>\n> So you should be able to get a full backtrace on this error if you use a\n> debugger\n> https://mooseframework.inl.gov/application_development/debugging.html\n> then we ll know which line is problematic\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <#22464 (reply in thread)>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AEKZEF7AFKLMKVRXU3XN5M3WEMDMVANCNFSM6AAAAAARLPGKXY>\n> .\n> You are receiving this because you authored the thread.Message ID:\n> ***@***.***>\n>\n\n\n --\n Olle Heinonen\n ***@***.***\n\n\n-- \nOlle Heinonen\n***@***.***",
                  "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3937416",
                  "updatedAt": "2022-10-21T22:04:15Z",
                  "publishedAt": "2022-10-21T22:04:15Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "ok I think you ll need to use the gradient routine on the variable rather than the coupleable interface (coupledGradient routine)\nThis is because we compute gradients in FV using Green-Gauss, not using a local quadrature point derivative.\nSee FVDiffusion for accessing the gradient using a functor.",
                          "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3937485",
                          "updatedAt": "2022-10-21T22:15:12Z",
                          "publishedAt": "2022-10-21T22:15:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I ll raise an issue, this should have been caught in an error message",
                          "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3937488",
                          "updatedAt": "2022-10-21T22:16:00Z",
                          "publishedAt": "2022-10-21T22:15:44Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You will want to use an element argument here, in FVDiffusion it s a face argument.",
                          "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3937568",
                          "updatedAt": "2022-10-21T22:33:03Z",
                          "publishedAt": "2022-10-21T22:33:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "I believe this was essentially resolved in another discussion correct? The key change being moving from coupledGradient to adCoupledGradient or using the gradient functor API? Can we regard this discussion as \"answered\" by the other discussion?",
                          "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3987362",
                          "updatedAt": "2022-10-28T00:54:33Z",
                          "publishedAt": "2022-10-28T00:54:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "I suppose we should error when a user attempts coupledGradient with an FV var \ud83e\udd14",
                          "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3987372",
                          "updatedAt": "2022-10-28T00:56:38Z",
                          "publishedAt": "2022-10-28T00:56:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "yeah I created an issue, though it needs to be updated to say coupledGradient because I did not know that was the issue",
                          "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3987749",
                          "updatedAt": "2022-10-28T02:04:51Z",
                          "publishedAt": "2022-10-28T02:04:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Ah ok. Captured in #22465",
                          "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3988620",
                          "updatedAt": "2022-10-28T05:19:47Z",
                          "publishedAt": "2022-10-28T05:19:46Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "heinono1"
                  },
                  "bodyText": "Thanks, Guillaume.\n\u2026\nOn Fri, Oct 21, 2022, 5:33 PM Guillaume Giudicelli ***@***.***> wrote:\n You will want to use an element argument here, in FVDiffusion it s a face\n argument.\n\n \u2014\n Reply to this email directly, view it on GitHub\n <#22464 (reply in thread)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AEKZEF7UPDLWB62TP62XPVTWEMK2TANCNFSM6AAAAAARLPGKXY>\n .\n You are receiving this because you authored the thread.Message ID:\n ***@***.***>",
                  "url": "https://github.com/idaholab/moose/discussions/22464#discussioncomment-3940161",
                  "updatedAt": "2022-10-22T14:32:45Z",
                  "publishedAt": "2022-10-22T14:32:45Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Which linux version of the system does the MOOSE support?",
          "author": {
            "login": "KangChenRui"
          },
          "bodyText": "hello!\nWhich linux version of the system does the MOOSE support?\nI am currently reinstalling the system.",
          "url": "https://github.com/idaholab/moose/discussions/22527",
          "updatedAt": "2022-11-15T19:00:14Z",
          "publishedAt": "2022-10-28T00:52:54Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "this page lists the requirements\nhttps://mooseframework.inl.gov/getting_started/installation/manual_installation_gcc.html\nwe dont keep track of that as closely as we generally always support linux",
                  "url": "https://github.com/idaholab/moose/discussions/22527#discussioncomment-3987748",
                  "updatedAt": "2022-10-28T02:14:24Z",
                  "publishedAt": "2022-10-28T02:04:09Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Out of memory",
          "author": {
            "login": "RECHOA"
          },
          "bodyText": "When i run a case, i met a error shows 'EXIT CODE: 9'. Learning from other discussions, it means running out of memory. But acturally, the computational memory of our HPC has been added to 2TB, which is the maximum memory it could provide. Here is a part of the terminal log:\n  Initializing\n    Updating Because Mesh Changed\n      Updating Mesh.                                                                     [\ufffd[33m 11.78 s\ufffd[39m] [\ufffd[33m    8 MB\ufffd[39m]\n    Finished Updating Because Mesh Changed                                               [\ufffd[33m 12.00 s\ufffd[39m] [\ufffd[33m   36 MB\ufffd[39m]\n.                                                                     [\ufffd[33m 15.24 s\ufffd[39m] [\ufffd[33m    0 MB\ufffd[39m]\n    Finished Updating Because Mesh Changed                                               [\ufffd[33m 15.55 s\ufffd[39m] [\ufffd[33m    0 MB\ufffd[39m]\n....\n      Updating Geometric Search\n        Updating Displaced GeometricSearch\n          Finding Nearest Nodes\n            Building Node To Elem Map                                                    [\ufffd[33m  9.36 s\ufffd[39m] [\ufffd[33m  358 MB\ufffd[39m]\n          Finished Finding Nearest Nodes                                                 [\ufffd[33m  9.37 s\ufffd[39m] [\ufffd[33m  358 MB\ufffd[39m]\n        Finished Updating Displaced GeometricSearch                                      [\ufffd[33m  9.60 s\ufffd[39m] [\ufffd[33m  363 MB\ufffd[39m]\n      Finished Updating Geometric Search                                                 [\ufffd[33m  9.60 s\ufffd[39m] [\ufffd[33m  363 MB\ufffd[39m]\n      Finished Building Node To Elem Map                                                 [\ufffd[33m  9.33 s\ufffd[39m] [\ufffd[33m  426 MB\ufffd[39m]\n    Still Initializing Equation Systems.........                                         [\ufffd[33m 96.82 s\ufffd[39m] [\ufffd[33m 1386 MB\ufffd[39m]\n    Initializing Displaced Equation System..........                                     [\ufffd[33m 62.36 s\ufffd[39m] [\ufffd[33m  717 MB\ufffd[39m]\n      Finished Updating Mesh                                                             [\ufffd[33m 11.17 s\ufffd[39m] [\ufffd[33m    3 MB\ufffd[39m]\n    Finished Updating Because Mesh Changed                                               [\ufffd[33m 11.47 s\ufffd[39m] [\ufffd[33m    3 MB\ufffd[39m]\n  Finished Initializing                                                                  [\ufffd[33m198.22 s\ufffd[39m] [\ufffd[33m 2143 MB\ufffd[39m]\n[DBG][ACT] TASK (\ufffd[33m            check_output\ufffd[39m) TYPE (\ufffd[33m               CheckOutputAction\ufffd[39m) NAME (\ufffd[33m                \ufffd[39m) Memory usage 7089MB\n[DBG][ACT] TASK (\ufffd[33m         check_integrity\ufffd[39m) TYPE (\ufffd[33m            CheckIntegrityAction\ufffd[39m) NAME (\ufffd[33m                \ufffd[39m) Memory usage 7089MB\n[DBG][ACT] TASK (\ufffd[33m               no_action\ufffd[39m) TYPE (\ufffd[33m                     EmptyAction\ufffd[39m) NAME (\ufffd[33m    BEEsPressure\ufffd[39m) Memory usage 7089MB\n[DBG][ACT] TASK (\ufffd[33mfinish_input_file_output\ufffd[39m) TYPE (\ufffd[33m                     EmptyAction\ufffd[39m) NAME (\ufffd[33m    BEEsPressure\ufffd[39m) Memory usage 7089MB\n[DBG][ACT] Finished executing all actions with memory usage 7089MB\n\nFinished Setting Up                                                                      [\ufffd[33m1289.15 s\ufffd[39m] [\ufffd[33m 7037 MB\ufffd[39m]\nFramework Information:\nMOOSE Version:           git commit ccf25ce on 2022-07-13\nLibMesh Version:         \nPETSc Version:           3.16.5\nSLEPc Version:           3.16.2\nCurrent Time:            Thu Oct 20 17:57:41 2022\nExecutable Timestamp:    Sat Oct  8 02:20:19 2022\n\nParallelism:\n  Num Processors:          60\n  Num Threads:             1\n\nMesh: \n  Parallel Type:           replicated\n  Mesh Dimension:          3\n  Spatial Dimension:       3\n  Nodes:                   \n    Total:                 1713784\n    Local:                 30461\n    Min/Max/Avg:           24821/30461/28563\n  Elems:                   \n    Total:                 4937408\n    Local:                 82442\n    Min/Max/Avg:           80273/88294/82290\n  Num Subdomains:          3143\n  Num Partitions:          60\n  Partitioner:             metis\n\nNonlinear System:\n  Num DOFs:                6855136\n  Num Local DOFs:          121844\n  Variables:               { \"temp\" \"disp_x\" \"disp_y\" \"disp_z\" } \n  Finite Element Types:    \"LAGRANGE\" \n  Approximation Orders:    \"FIRST\" \n\nAuxiliary System:\n  Num DOFs:                63691744\n  Num Local DOFs:          1068823\n  Variables:               { \"fast_neutron_fluence\" \"baf\" \"hoop_stress_bees\" \"hoop_strain_bees\" } \"rad_disp\" \n                             \"maxPrincipal_stress\" { \"creep_strain\" \"thermal_strain\" \"swell_strain\" \"Weibull_failure_probability\" \n                             \"Pdpenetration_depth\" \"qpoint_penetration\" \"paired_temp\" } { \"penetration\" \n                             \"contact_pressure\" \"nodal_area_pellet_clad_mechanical\" } \n  Finite Element Types:    \"MONOMIAL\" \"LAGRANGE\" \"MONOMIAL\" \"MONOMIAL\" \"LAGRANGE\" \n  Approximation Orders:    \"CONSTANT\" \"FIRST\" \"CONSTANT\" \"CONSTANT\" \"FIRST\" \n\nExecution Information:\n  Executioner:             Transient\n  TimeStepper:             FunctionDT\n  Solver Mode:             Preconditioned JFNK\n  MOOSE Preconditioner:    SMP\n\n\ufffd[31mLEGACY MODES ENABLED:\ufffd[39m\n This application uses the legacy material output option: material properties are output only on TIMESTEP_END, not INITIAL. To remove this message, set 'use_legacy_material_output' to false in this application. If there are gold output files that contain material property output for which output occurs on INITIAL, then these will generate diffs due to zero values being stored, and these tests should be re-golded.\n\ufffd[39m\n\n    Setting Up Materials\n      Computing Initial Material Values.....\n===================================================================================\n=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES\n=   PID 87204 RUNNING AT ga0304\n=   EXIT CODE: 9\n=   CLEANING UP REMAINING PROCESSES\n=   YOU CAN IGNORE THE BELOW CLEANUP MESSAGES\n===================================================================================\nYOUR APPLICATION TERMINATED WITH THE EXIT STRING: Killed (signal 9)\nThis typically refers to a problem with your application.\nPlease see the FAQ page for debugging suggestions\n\nAlso, I add the\n[Debug]\n  show_actions = true\n[]\n\nto to see more information about the memory cost .\nThe complete record of terminal log shows in the following file (result_log.txt):\nresult_log.txt\nThe Executioner setting is\n[Executioner]\n  type = Transient\n  petsc_options_iname = '-ksp_gmres_restart -pc_type -pc_hypre_type -pc_hypre_boomeramg_max_iter'\n  petsc_options_value = '201                hypre    boomeramg      4'\n  line_search = 'none'\n  solve_type = PJFNK\n  l_tol =      0.0001\n  l_max_its =  20\n  nl_rel_tol = 1e-06\n  nl_abs_tol = 1e-05\n  nl_max_its = 15\n  dtmin = 0.1\n  dtmax = 1.0e6\n  start_time = 0.0\n  end_time = 9.0e7\n  [./TimeStepper]\n    type = FunctionDT\n    function = dts\n    min_dt = 1.0\n  [../]\n []\n\nI don't know which part of my case causing the memory exceed the maximum, and could anyone give better petsc options setting in the Executioner ?\nThank you in advance.",
          "url": "https://github.com/idaholab/moose/discussions/22452",
          "updatedAt": "2022-11-15T19:00:08Z",
          "publishedAt": "2022-10-20T11:20:03Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nYou're at least at 420Gb used.\nCould you try distributed meshes (--distributed-mesh on the command line) to reduce the memory consumption?\nAre you running this on a cluster scheduler that could have killed it for other reasons?\npetsc options should not be an issue yet when computing materials\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3924474",
                  "updatedAt": "2022-10-20T12:56:17Z",
                  "publishedAt": "2022-10-20T12:56:17Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "RECHOA"
                          },
                          "bodyText": "The computational memory of HPC has been added to 2TB, it is quite strange that this case failed but only 420Gb used.\nThe mesh file isn't created by using MOOSE built-in mesh block (acturally by Cubit), i'm not sure whether the --distributed-mesh could work, but i'll try it.\nI run this case in HPC for many times but it failed due to the same error. Besides, for similar cases with less number of elements, they could run successfully.",
                          "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3924606",
                          "updatedAt": "2022-10-20T13:12:48Z",
                          "publishedAt": "2022-10-20T13:12:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "RECHOA"
                          },
                          "bodyText": "I tried the --distributed-mesh command, but it got the same error. Besides, the memory usage  seems to have increased rather than decreased. Here is the new new_result_log.txt file:\nnew_result_log.txt\nDoes the memory usage show in the file reperesent the total meomry or the memory in one processor?",
                          "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3925115",
                          "updatedAt": "2022-10-20T14:08:02Z",
                          "publishedAt": "2022-10-20T14:08:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "RECHOA"
                          },
                          "bodyText": "I used the command watch \u201cfree -g\u201d to see the change of the memory usage, and I noticed that the memory usage was normal (about 400~500GB) during the case running  until it run to the step:\n  Setting Up Materials\n     Computing Initial Material Values.....\n\nat that time, the memory usage would increase dramatically (exceed 2TB), and then the case failed.\nWhat should i do to get over this problem?",
                          "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3925951",
                          "updatedAt": "2022-10-20T15:30:06Z",
                          "publishedAt": "2022-10-20T15:30:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "The previous log was showing 7Gb used, this one shows 6167MB so it's a little better with distributed meshes.\nWhy do you have so many materials? Seems like thousands of materials and auxkernels.\nWhy cant you use the same auxkernel or materials on all the blocks? What is different?\n3000 subdomains is a little much as well.",
                          "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3934061",
                          "updatedAt": "2022-10-21T14:08:06Z",
                          "publishedAt": "2022-10-21T14:08:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "RECHOA"
                          },
                          "bodyText": "There are a lot of subdomains (spheres) in my case. In each subdomain (sphere), its eigen strain is related to its location, since spherical coordinate system was created in every sphere. So there're many materials.",
                          "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3934164",
                          "updatedAt": "2022-10-21T14:21:11Z",
                          "publishedAt": "2022-10-21T14:21:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "cant it be the same material defined across multiple blocks?\nThe location is a parameter of the material?",
                          "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3934181",
                          "updatedAt": "2022-10-21T14:22:30Z",
                          "publishedAt": "2022-10-21T14:22:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "RECHOA"
                          },
                          "bodyText": "yes, when calcuting the eigen strain for each sphere, the location is a parameter.",
                          "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3934205",
                          "updatedAt": "2022-10-21T14:24:19Z",
                          "publishedAt": "2022-10-21T14:24:19Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I'd change that to use the same material everywhere, and have the location parameter be either:\n\na really long vector (temporarily)\nread from a text file\nKeeping the number of objects down will help tremendously with simulation time and memory cost.",
                          "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3934258",
                          "updatedAt": "2022-10-21T14:28:46Z",
                          "publishedAt": "2022-10-21T14:28:45Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "same for the auxkernels",
                          "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3934262",
                          "updatedAt": "2022-10-21T14:28:56Z",
                          "publishedAt": "2022-10-21T14:28:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "RECHOA"
                          },
                          "bodyText": "Sorry maybe i have misinformed you. Although the auxkernels are related to the location paramete, but i declared the same auxvariable.\nFor example, when calculting the radial displacement, i declared the same \"variable = rad_disp\":\n  [./raddispaux_73]\n    type = RadialDisplacementSphereAux\n    variable = rad_disp\n    block = '363 '\n    origin = '0.000270492 -0.00235077 -0.00270761'\n  [../]\n  [./raddispaux_74]\n    type = RadialDisplacementSphereAux\n    variable = rad_disp\n    block = '368'\n    origin = '-0.00152647 0.000133102 -0.00589633'\n  [../]\n  ...\n\nAs for the eigen strian, they are in the form like this:\n  [./EigenStrain_232]\n    type = ComputeMyMaterialEigenstrain\n    temperature = temp\n    eigenstrain_name = 'pyc_eigen_232'\n    block = '1160'\n    origin = '-0.000275106 -0.00174505 7.86264e-05'\n  [../]\n  [./_EigenStrain_233]\n    type = ComputeMyMaterialEigenstrain\n    temperature = temp\n    eigenstrain_name = 'pyc_eigen_233'\n    block = '1163 '\n    origin = '0.00161647 -0.0019067799999999998 0.00480855'\n  [../]\n  ...",
                          "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3934487",
                          "updatedAt": "2022-10-21T14:49:57Z",
                          "publishedAt": "2022-10-21T14:49:56Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "dschwen"
                  },
                  "bodyText": "Can you show your PBS script?",
                  "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3924962",
                  "updatedAt": "2022-10-20T13:56:09Z",
                  "publishedAt": "2022-10-20T13:51:50Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "RECHOA"
                          },
                          "bodyText": "The script is like this:\n#!/bin/bash\n#SBATCH -p amd_2T\n#SBATCH -N 1\n#SBATCH -n 64\nsource  activate /public1/home/scb3820/anaconda3/envs/moose/\nexport PATH=/public1/home/scb3820/new-projects/bees_new:$PATH\nmpiexec -n 60  ./*opt -i input_master.i",
                          "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3925048",
                          "updatedAt": "2022-10-20T14:00:36Z",
                          "publishedAt": "2022-10-20T14:00:35Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "do you need to request memory?\nfor example\n#SBATCH --mem=2G           # total memory per node",
                          "url": "https://github.com/idaholab/moose/discussions/22452#discussioncomment-3944506",
                          "updatedAt": "2022-10-23T16:05:00Z",
                          "publishedAt": "2022-10-23T16:04:59Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Hypre Boomerang Simulation freezes",
          "author": {
            "login": "Edward-Eth"
          },
          "bodyText": "I've recently encountered an issue while using Hypre Boomerang as my petsc options, similar to Q+A #17058 but not exactly the same.\nIn that thread the user found that removing the Chebyshev relaxation they resolved their issue, however my HYPRE options were just:\nline_search = 'none'\npetsc_options = '-snes_ksp_ew'\npetsc_options_iname = '-ksp_gmres_restart -pc_type -pc_hypre_type -pc_hypre_boomeramg_max_iter'\npetsc_options_value = '2001                hypre    boomeramg      20'\n\nWhich was causing hang-ups/freezes during nonlinear/linear iterations (it would print a nonlinear iteration then just stop, so maybe on the transition from NL to L?) but often not until an hour or more into the simulation. Running top on the nodes involved in the job would reveal that while their CPU usage was still maxed out, they were no longer using any memory at all. I don't believe memory was the issue, as I was only running around 2000 local NL DOFs so there was not much information being stored on each node.\nI'm not very familiar with debugging at all, and fear that given it takes about an hour to fail on opt mode it would take a very long time to reach failure in debug. However, I believe the issue was hypre boomeramg as a run on petsc ilu with the following options:\nline_search = 'default'\npetsc_options_iname = '-pc_type  -snes_linesearch_type -pc_factor_shift_type -snes_max_it -ksp_max_it'\npetsc_options_value = 'ilu        basic                 NONZERO               20           40'\n\nHas just lasted several hours without issue.\nInterestingly, I also find that disabling distributed mesh while still using HYPRE BOOMERANG also fixes the freezing issue, so I'm not sure what the correlation there is.",
          "url": "https://github.com/idaholab/moose/discussions/22367",
          "updatedAt": "2022-11-15T19:20:06Z",
          "publishedAt": "2022-10-11T13:09:20Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nDo you not get any live print?\nCan you turn on the linear residual printing? The max linear iterations is 10k so that can feel like a freeze\nIn Outputs: print_linear_residual = true\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22367#discussioncomment-3850980",
                  "updatedAt": "2022-10-11T14:05:07Z",
                  "publishedAt": "2022-10-11T14:05:06Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Edward-Eth"
                          },
                          "bodyText": "Linear residual printing is on, the simulation normally takes about 20 seconds for a timestep but will freeze indefinitely (I've tried waiting multiple hours) after printing a nonlinear iteration.",
                          "url": "https://github.com/idaholab/moose/discussions/22367#discussioncomment-3851232",
                          "updatedAt": "2022-10-11T14:31:41Z",
                          "publishedAt": "2022-10-11T14:31:41Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "can you please paste the input file here?",
                          "url": "https://github.com/idaholab/moose/discussions/22367#discussioncomment-3851265",
                          "updatedAt": "2022-10-11T14:35:58Z",
                          "publishedAt": "2022-10-11T14:35:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Edward-Eth"
                          },
                          "bodyText": "I've been attempting to make an MWE, will post if I manage to make one that's simple/doesn't contain any information.",
                          "url": "https://github.com/idaholab/moose/discussions/22367#discussioncomment-3851672",
                          "updatedAt": "2022-10-11T15:08:40Z",
                          "publishedAt": "2022-10-11T15:08:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Any update on this?",
                          "url": "https://github.com/idaholab/moose/discussions/22367#discussioncomment-3937893",
                          "updatedAt": "2022-10-22T00:01:55Z",
                          "publishedAt": "2022-10-22T00:01:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Edward-Eth"
                          },
                          "bodyText": "So I've not been able to make an MWE that I'm able to share here, but I managed to \"resolve\" the issue by totally removing the petsc_options, petsc_options_iname, petsc_options_value lines. I'm not sure what petsc options this means I'm now running? I was also observing freezes when using HMG as my -pc_type",
                          "url": "https://github.com/idaholab/moose/discussions/22367#discussioncomment-3983628",
                          "updatedAt": "2022-10-27T15:59:04Z",
                          "publishedAt": "2022-10-27T15:59:04Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "ILU in serial, block Jacobi with ILU on the sub-blocks in parallel.\nYou can always run with the PETSc option -snes_view which will show all the information about your nonlinear solution algorithm in PETSC including the linear solution algorithm, or you can pass -ksp_view to just get info about the linear solve (although you'll get a printout for every linear solve)",
                          "url": "https://github.com/idaholab/moose/discussions/22367#discussioncomment-3986929",
                          "updatedAt": "2022-10-27T23:02:31Z",
                          "publishedAt": "2022-10-27T23:02:31Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Nonlinear solve did not converge",
          "author": {
            "login": "Ethan-xj"
          },
          "bodyText": "Hi, I run a steady case. But the nonlinear solve did not converge.\nHere is my input file:\n[GlobalParams]\n  gravity = -9.8\n  transient_term = false\n  lk = 1\n  sk = 0.5\n  kg = 0.5\n[]\n\n[Mesh]\n file = 'twopipe_beam2.e'\n[]\n\n[Variables]\n  [./p]\n    order = FIRST\n    family = LAGRANGE\n    block = '1 2'\n  [../]\n  [./u]\n    order = FIRST\n    family = LAGRANGE\n    block = '1 2'\n    [./InitialCondition]\n      type = ConstantIC\n      value = 0.15\n    [../]\n  [../]\n  [./T]\n    order = FIRST\n    family = LAGRANGE\n    block = '1 2'\n    [./InitialCondition]\n      type = ConstantIC\n      value = 550\n    [../]\n  [../]\n  [./w]\n    order = FIRST\n    family = LAGRANGE\n    block = '1 2'\n  [../]\n[]\n\n[Kernels]\n  [./MASS_EQUATION1]\n    type = mass\n    variable = p\n    vel = u\n    temp = T\n    press = p\n    lvel = w\n    block = '1 2'\n  [../]\n  [./Momentum_EQUATION]\n    type = momentum\n    variable = u\n    press = p\n    temp = T\n    vel = u\n    lvel = w\n    block = '1 2'\n   [../]\n  [./Energy_EQUATION1]\n    type = energy\n    variable = T\n    vel = u\n    press = p\n    temp = T\n    lvel = w\n    value = 1.0\n    block = '1'\n    function = test\n    linearfittingTEMP = TEMPVALUE2\n  [../]\n  [./Energy_EQUATION2]\n    type = energy\n    variable = T\n    vel = u\n    press = p\n    temp = T\n    lvel = w\n    value = 1.0\n    block = '2'\n    function = test\n    linearfittingTEMP = TEMPVALUE1\n  [../]\n  [./LateralMomentum_EQUATION1]\n    type = lateralmomentum\n    variable = w\n    lvel = w\n    vel = u\n    temp = T\n    press = p\n    linearfittingTEMP = TEMPVALUE2\n    linearfittingPRESS = PRESSVALUE2\n    linearfittingVEL = VELVALUE2\n    block = '1'\n  [../]\n  [./LateralMomentum_EQUATION2]\n    type = lateralmomentum\n    variable = w\n    lvel = w\n    vel = u\n    temp = T\n    press = p\n    linearfittingTEMP = TEMPVALUE1\n    linearfittingPRESS = PRESSVALUE1\n    linearfittingVEL = VELVALUE1\n    block = '2'\n  [../]\n[]\n\n[Functions]\n  [./test]\n    type = ParsedFunction\n    value = 1.0e8*sin(pi*x)\n  [../]\n[../]\n\n[BCs]\n  [./outlet_p]\n    type =  DirichletBC\n    boundary = '16 26'\n    variable = p\n    value = 2.0e5\n  [../]\n  [./inlet_u1]\n    type =  DirichletBC\n    boundary = '11'\n    variable = u\n    value = 0.1\n  [../]\n  [./inlet_u2]\n    type =  DirichletBC\n    boundary = '21'\n    variable = u\n    value = 0.2\n  [../]\n  [./inlet_T1]\n    type = DirichletBC\n    variable = T\n    boundary = '11'\n    value = 500\n  [../]\n  [./inlet_T2]\n    type = DirichletBC\n    variable = T\n    boundary = '21'\n    value = 600\n  [../]\n  [./inlet_w1]\n    type =  DirichletBC\n    boundary = '11'\n    variable = w\n    value = 100\n  [../]\n  [./inlet_w2]\n    type =  DirichletBC\n    boundary = '21'\n    variable = w\n    value = -100\n  [../]\n[]\n\n[Materials]\n  [./EM]\n    type = submaterial\n    is_sodium = false\n    constant_property = false\n    constant_f_h_property = true\n    f_coefficient = 0.01\n    diameter = 0.02\n    temp = T\n    block = '1 2'\n  [../]\n[]\n\n[Preconditioning]\n  [./FD]\n    type = SMP\n    full = true\n  [../]\n[]\n\n[UserObjects]\n  [./TEMPVALUE1]\n    type = linearfitting\n    paramname1 = TEMPADJ_VEC1\n    paramname2 = TEMPADJ_VEC1\n    vectorname1 = T\n    vectorname2 = x\n    broadcast1 = false\n    broadcast2 = false\n  [../]\n  [./TEMPVALUE2]\n    type = linearfitting\n    paramname1 = TEMPADJ_VEC2\n    paramname2 = TEMPADJ_VEC2\n    vectorname1 = T\n    vectorname2 = x\n    broadcast1 = false\n    broadcast2 = false\n  [../]\n  [./PRESSVALUE1]\n    type = linearfitting\n    paramname1 = PRESSADJ_VEC1\n    paramname2 = PRESSADJ_VEC1\n    vectorname1 = p\n    vectorname2 = x\n    broadcast1 = false\n    broadcast2 = false\n  [../]\n  [./PRESSVALUE2]\n    type = linearfitting\n    paramname1 = PRESSADJ_VEC2\n    paramname2 = PRESSADJ_VEC2\n    vectorname1 = p\n    vectorname2 = x\n    broadcast1 = false\n    broadcast2 = false\n  [../]\n  [./VELVALUE1]\n    type = linearfitting\n    paramname1 = VELADJ_VEC1\n    paramname2 = VELADJ_VEC1\n    vectorname1 = u\n    vectorname2 = x\n    broadcast1 = false\n    broadcast2 = false\n  [../]\n  [./VELVALUE2]\n    type = linearfitting\n    paramname1 = VELADJ_VEC2\n    paramname2 = VELADJ_VEC2\n    vectorname1 = u\n    vectorname2 = x\n    broadcast1 = false\n    broadcast2 = false\n  [../]\n[]\n\n[VectorPostprocessors]\n  [./VELADJ_VEC1]\n    type = NodalValueSampler\n    variable = u\n    block = '1'\n    sort_by = x\n    execute_on = 'INITIAL LINEAR NONLINEAR'\n  [../]\n  [./VELADJ_VEC2]\n    type = NodalValueSampler\n    variable = u\n    block = '2'\n    sort_by = x\n    execute_on = 'INITIAL LINEAR NONLINEAR'\n  [../]\n  [./PRESSADJ_VEC1]\n    type = NodalValueSampler\n    variable = p\n    block = '1'\n    sort_by = x\n    execute_on = 'INITIAL LINEAR NONLINEAR'\n  [../]\n  [./PRESSADJ_VEC2]\n    type = NodalValueSampler\n    variable = p\n    block = '2'\n    sort_by = x\n    execute_on = 'INITIAL LINEAR NONLINEAR'\n  [../]\n  [./TEMPADJ_VEC1]\n    type = NodalValueSampler\n    variable = T\n    block = '1'\n    sort_by = x\n    execute_on = 'INITIAL LINEAR NONLINEAR'\n  [../]\n  [./TEMPADJ_VEC2]\n    type = NodalValueSampler\n    variable = T\n    block = '2'\n    sort_by = x\n    execute_on = 'INITIAL LINEAR NONLINEAR'\n  [../]\n[]\n\n[Executioner]\n  type =  Steady\n  solve_type = PJFNK\n\n#  petsc_options = '-snes_converged_reason -ksp_converged_reason -pc_svd_monitor'\n#  petsc_options_iname = '-pc_type -pc_factor_shift_type -pc_factor_mat_solver_package'\n#  petsc_options_value = 'lu    NONZERO      superlu_dist '\n#  petsc_options = '-snes_monitor -ksp_monitor_true_residual -snes_converged_reason -ksp_converged_reason'\n\n#  petsc_options = '-pc_svd_monitor'\n#  petsc_options_iname = '-pc_type'\n#  petsc_options_value = 'svd'\n\n  petsc_options = '-snes_converged_reason -ksp_converged_reason -pc_svd_monitor'\n#  petsc_options = '-snes_monitor -ksp_monitor_true_residual -snes_converged_reason -ksp_converged_reason'\n  petsc_options_iname = '-pc_type -pc_factor_mat_solver_package'\n  petsc_options_value = 'lu superlu_dist'\n\n\n  nl_rel_tol = 1e-8\n  nl_abs_tol = 1e-12\n  nl_max_its = 50\n  l_tol = 1e-6\n  l_max_its = 100\n  line_search = 'none'\n[]\n\n[Outputs]\n  exodus = true\n  csv = true\n[]\n\nError info is:\nFramework Information:\nMOOSE Version:           git commit 5d2aa15248 on 2022-04-01\nLibMesh Version:         \nPETSc Version:           3.16.5\nSLEPc Version:           3.16.2\nCurrent Time:            Mon Oct 17 22:48:03 2022\nExecutable Timestamp:    Mon Oct 17 07:47:49 2022\n\nParallelism:\n  Num Processors:          1\n  Num Threads:             1\n\nMesh: \n  Parallel Type:           replicated\n  Mesh Dimension:          1\n  Spatial Dimension:       2\n  Nodes:                   12\n  Elems:                   10\n  Num Subdomains:          2\n\nNonlinear System:\n  Num DOFs:                48\n  Num Local DOFs:          48\n  Variables:               { \"p\" \"u\" \"T\" \"w\" } \n  Finite Element Types:    \"LAGRANGE\" \n  Approximation Orders:    \"FIRST\" \n\nExecution Information:\n  Executioner:             Steady\n  Solver Mode:             Preconditioned JFNK\n  MOOSE Preconditioner:    SMP\n\n 0 Nonlinear |R| = 9.684908e+07\n      0 Linear |R| = 9.684908e+07\n      1 Linear |R| = 7.262913e+07\n      2 Linear |R| = 4.003316e+07\n      3 Linear |R| = 1.662636e+05\n      4 Linear |R| = 1.268994e+05\n      5 Linear |R| = 7.886449e+04\n      6 Linear |R| = 1.264851e+04\n      7 Linear |R| = 3.485096e+03\n      8 Linear |R| = 3.375993e+03\n      9 Linear |R| = 1.502126e+03\n     10 Linear |R| = 1.369914e+03\n     11 Linear |R| = 1.153357e+03\n     12 Linear |R| = 1.102386e+03\n     13 Linear |R| = 9.815075e+02\n     14 Linear |R| = 9.013048e+02\n     15 Linear |R| = 8.322066e+02\n     16 Linear |R| = 7.594054e+02\n     17 Linear |R| = 7.056265e+02\n     18 Linear |R| = 7.055377e+02\n     19 Linear |R| = 6.682807e+02\n     20 Linear |R| = 6.294849e+02\n     21 Linear |R| = 5.827533e+02\n     22 Linear |R| = 5.548326e+02\n     23 Linear |R| = 5.159567e+02\n     24 Linear |R| = 4.999194e+02\n     25 Linear |R| = 4.746365e+02\n     26 Linear |R| = 4.566083e+02\n     27 Linear |R| = 4.566082e+02\n     28 Linear |R| = 4.431755e+02\n     29 Linear |R| = 4.412566e+02\n     30 Linear |R| = 3.709834e+05\n     31 Linear |R| = 3.390672e+05\n     32 Linear |R| = 3.374639e+05\n     33 Linear |R| = 1.169134e+05\n     34 Linear |R| = 5.092162e+04\n     35 Linear |R| = 9.636646e+03\n     36 Linear |R| = 9.519738e+03\n     37 Linear |R| = 5.423694e+03\n     38 Linear |R| = 4.952410e+03\n     39 Linear |R| = 1.423640e+03\n     40 Linear |R| = 1.146720e+03\n     41 Linear |R| = 6.389495e+02\n     42 Linear |R| = 4.897847e+02\n     43 Linear |R| = 2.802632e+02\n     44 Linear |R| = 2.350840e+02\n     45 Linear |R| = 1.959855e+02\n     46 Linear |R| = 1.673932e+02\n     47 Linear |R| = 1.503125e+02\n     48 Linear |R| = 1.384166e+02\n     49 Linear |R| = 1.280600e+02\n     50 Linear |R| = 1.190889e+02\n     51 Linear |R| = 1.120673e+02\n     52 Linear |R| = 1.060448e+02\n     53 Linear |R| = 1.005545e+02\n     54 Linear |R| = 1.005402e+02\n     55 Linear |R| = 9.611802e+01\n  Linear solve converged due to CONVERGED_RTOL iterations 55\n 1 Nonlinear |R| = 1.795000e+14\n      0 Linear |R| = 1.795000e+14\n      1 Linear |R| = 6.115383e+12\n      2 Linear |R| = 5.000160e+12\n      3 Linear |R| = 4.915033e+12\n      4 Linear |R| = 3.349811e+12\n      5 Linear |R| = 2.004474e+12\n      6 Linear |R| = 1.903671e+12\n      7 Linear |R| = 1.092260e+11\n      8 Linear |R| = 1.089425e+11\n      9 Linear |R| = 2.346686e+10\n     10 Linear |R| = 3.576322e+09\n     11 Linear |R| = 1.675046e+09\n     12 Linear |R| = 1.492094e+09\n     13 Linear |R| = 1.347012e+09\n     14 Linear |R| = 1.188002e+09\n     15 Linear |R| = 1.062221e+09\n     16 Linear |R| = 6.002530e+08\n     17 Linear |R| = 3.337966e+08\n     18 Linear |R| = 1.049198e+08\n  Linear solve converged due to CONVERGED_RTOL iterations 18\n 2 Nonlinear |R| = 4.376385e+18\nNonlinear solve did not converge due to DIVERGED_DTOL iterations 2\n Solve Did NOT Converge!\nAborting as solve did not converge\n\nI know there may be many reasons which cause the non-convergence of the nonlinear solve. I have browsed \"Why is Newton's method not converging?\" But I don't know how to use the petsc option to find out the problem. Can anybody give me some advice?\nEthan",
          "url": "https://github.com/idaholab/moose/discussions/22425",
          "updatedAt": "2022-11-15T18:17:31Z",
          "publishedAt": "2022-10-18T07:38:04Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\ncan you try tightening the linear solve convergence?\nWhile it does look like it s converging, the residual is still large when it considers it converged.\nI would also turn on automatic_scaling\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22425#discussioncomment-3905577",
                  "updatedAt": "2022-10-18T12:26:19Z",
                  "publishedAt": "2022-10-18T12:26:18Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "A helpful analysis when facing linear solve convergence issues is to look at the singular value decomposition. You already have the right options in your executioner block, just I comment those\npetsc_options = '-pc_svd_monitor'\npetsc_options_iname = '-pc_type'\npetsc_options_value = 'svd'\nand comment the others.\nThen please report back the log. You can attach it no need to paste",
                          "url": "https://github.com/idaholab/moose/discussions/22425#discussioncomment-3906187",
                          "updatedAt": "2022-10-18T13:30:35Z",
                          "publishedAt": "2022-10-18T13:29:33Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Ethan-xj"
                          },
                          "bodyText": "I've tried tightening the linear solve convergence and turn on automatic_scaling but no help.\nsvd info is like:\n0 Nonlinear |R| = 4.336556e+07\n      SVD: condition number 3.869546805366e+20, 2 of 48 singular values are (nearly) zero\n      SVD: smallest singular values: 7.401164605705e-16 2.093903784493e-15 1.262262987096e-03 1.262474141078e-03 2.044260149468e-03\n      SVD: largest singular values : 2.599575383639e+05 2.729892529714e+05 2.729892652737e+05 2.863910226199e+05 2.863915285599e+05\n      0 Linear |R| = 4.336556e+07\n      1 Linear |R| = 1.550253e+05\n      2 Linear |R| = 2.305613e+00\n 1 Nonlinear |R| = 5.218725e+10\n      SVD: condition number 6.627935421585e+10, 0 of 48 singular values are (nearly) zero\n      SVD: smallest singular values: 1.006739393511e-02 1.053531141913e-02 1.135761460821e-02 1.172289713294e-02 1.465162648495e-02\n      SVD: largest singular values : 2.114990472696e+08 5.208574217496e+08 5.771913522718e+08 5.944399514397e+08 6.672603686557e+08\n      0 Linear |R| = 5.218725e+10\n      1 Linear |R| = 1.178826e+10\n      2 Linear |R| = 5.508254e+09\n      3 Linear |R| = 3.085541e+09\n      4 Linear |R| = 1.901834e+08\n      5 Linear |R| = 9.260299e+07\n      6 Linear |R| = 8.714542e+06\n      7 Linear |R| = 4.392612e+05\n      8 Linear |R| = 4.761062e+04\n 2 Nonlinear |R| = 1.349031e+10\n      SVD: condition number 1.391894828974e+11, 0 of 48 singular values are (nearly) zero\n      SVD: smallest singular values: 1.580539139711e-03 3.275932978742e-03 4.430524260619e-03 4.735235287784e-03 7.747361393796e-03\n      SVD: largest singular values : 6.272104708957e+07 7.153468086483e+07 7.729908043561e+07 2.128491818299e+08 2.199944255554e+08\n      0 Linear |R| = 1.349031e+10\n      1 Linear |R| = 7.893490e+09\n      2 Linear |R| = 2.538318e+09\n      3 Linear |R| = 2.515361e+09\n      4 Linear |R| = 5.376503e+08\n      5 Linear |R| = 1.906544e+08\n      6 Linear |R| = 3.369192e+07\n      7 Linear |R| = 2.522291e+07\n      8 Linear |R| = 7.227505e+06\n      9 Linear |R| = 3.396977e+05\n     10 Linear |R| = 2.908401e+02\n 3 Nonlinear |R| = 2.632591e+10\n      SVD: condition number 2.159080800468e+12, 0 of 48 singular values are (nearly) zero\n      SVD: smallest singular values: 4.337096716538e-04 2.198094868503e-03 2.683026624429e-03 6.807311730829e-03 7.929380549331e-03\n      SVD: largest singular values : 3.430059797055e+07 5.796045170453e+07 7.190534405850e+07 8.731796413478e+08 9.364142250447e+08\n      0 Linear |R| = 2.632591e+10\n      1 Linear |R| = 2.627780e+10\n      2 Linear |R| = 1.381449e+10\n      3 Linear |R| = 4.869077e+09\n      4 Linear |R| = 5.113363e+08\n      5 Linear |R| = 6.063945e+07\n      6 Linear |R| = 6.695045e+06\n      7 Linear |R| = 1.746305e+06\n      8 Linear |R| = 4.688312e+04\n      9 Linear |R| = 4.299942e+04\n     10 Linear |R| = 3.733407e+02\n 4 Nonlinear |R| = 1.907015e+10\n      SVD: condition number 6.242688330859e+11, 0 of 48 singular values are (nearly) zero\n      SVD: smallest singular values: 1.152106577911e-03 1.488192388598e-03 1.735964403871e-03 5.951813298882e-03 8.160289470301e-03\n      SVD: largest singular values : 1.633330295388e+07 2.799562009590e+07 3.634915085794e+07 6.941264872982e+08 7.192242289828e+08\n      0 Linear |R| = 1.907015e+10\n      1 Linear |R| = 1.447033e+10\n      2 Linear |R| = 4.490343e+09\n      3 Linear |R| = 6.621869e+08\n      4 Linear |R| = 9.239841e+07\n      5 Linear |R| = 1.277331e+07\n      6 Linear |R| = 5.959127e+05\n      7 Linear |R| = 1.043141e+05\n      8 Linear |R| = 1.430702e+04\n 5 Nonlinear |R| = 1.541479e+10\n      SVD: condition number 1.156956576089e+13, 0 of 48 singular values are (nearly) zero\n      SVD: smallest singular values: 7.191625627918e-05 8.055863105241e-04 9.806119362769e-04 2.816442203339e-03 3.494768662942e-03\n      SVD: largest singular values : 3.177573760032e+07 9.990360997803e+07 1.642756023806e+08 8.223471810242e+08 8.320398562989e+08\n      0 Linear |R| = 1.541479e+10\n      1 Linear |R| = 1.367224e+10\n      2 Linear |R| = 9.975120e+09\n      3 Linear |R| = 9.951815e+09\n      4 Linear |R| = 5.868451e+08\n      5 Linear |R| = 1.649037e+08\n      6 Linear |R| = 1.342734e+07\n      7 Linear |R| = 7.901587e+05\n      8 Linear |R| = 4.138576e+05\n      9 Linear |R| = 7.322996e+04\n     10 Linear |R| = 1.464983e+03\n 6 Nonlinear |R| = 1.919316e+11\n      SVD: condition number 7.856886224084e+12, 0 of 48 singular values are (nearly) zero\n      SVD: smallest singular values: 2.771698601288e-04 1.659931619665e-03 3.747110951854e-03 4.109935096003e-03 6.376962113402e-03\n      SVD: largest singular values : 1.001629408638e+08 1.648023962539e+08 4.106232529724e+08 4.743677907204e+08 2.177692055777e+09\n      0 Linear |R| = 1.919316e+11\n      1 Linear |R| = 1.810633e+10\n      2 Linear |R| = 1.501036e+10\n      3 Linear |R| = 2.352895e+09\n      4 Linear |R| = 2.223281e+09\n      5 Linear |R| = 1.982148e+08\n      6 Linear |R| = 2.716037e+07\n      7 Linear |R| = 1.771982e+07\n      8 Linear |R| = 1.734676e+07\n      9 Linear |R| = 9.037296e+06\n     10 Linear |R| = 3.059233e+05\n     11 Linear |R| = 2.108584e+02\n 7 Nonlinear |R| = 5.586902e+10\n      SVD: condition number 5.575732828813e+13, 0 of 48 singular values are (nearly) zero\n      SVD: smallest singular values: 1.467382572136e-05 1.564970666984e-04 1.899941423280e-03 2.585331012378e-03 3.021361309547e-03\n      SVD: largest singular values : 1.452532688690e+08 2.605609239556e+08 3.054394376255e+08 4.212224499198e+08 8.181733179885e+08\n      0 Linear |R| = 5.586902e+10\n      1 Linear |R| = 2.322391e+10\n      2 Linear |R| = 2.039387e+10\n      3 Linear |R| = 2.000107e+10\n      4 Linear |R| = 4.885113e+09\n      5 Linear |R| = 1.411450e+09\n      6 Linear |R| = 1.245704e+09\n      7 Linear |R| = 6.579378e+07\n      8 Linear |R| = 7.847188e+06\n      9 Linear |R| = 1.077280e+04\n 8 Nonlinear |R| = 5.997147e+11\n      SVD: condition number 2.075726717114e+13, 0 of 48 singular values are (nearly) zero\n      SVD: smallest singular values: 2.646541277013e-04 1.792534957714e-03 2.475725789593e-03 5.786980982566e-03 7.924556220179e-03\n      SVD: largest singular values : 3.362456422443e+08 4.556671171541e+08 8.783230486809e+08 2.338810642850e+09 5.493496436642e+09\n      0 Linear |R| = 5.997147e+11\n      1 Linear |R| = 1.225080e+11\n      2 Linear |R| = 5.894974e+10\n      3 Linear |R| = 7.944822e+09\n      4 Linear |R| = 3.488516e+09\n      5 Linear |R| = 8.974561e+08\n      6 Linear |R| = 4.915812e+08\n      7 Linear |R| = 4.460547e+08\n      8 Linear |R| = 3.971313e+07\n      9 Linear |R| = 4.535522e+06\n     10 Linear |R| = 6.726619e+04\n 9 Nonlinear |R| = 1.676970e+11\n      SVD: condition number 1.234246390871e+14, 0 of 48 singular values are (nearly) zero\n      SVD: smallest singular values: 2.235497959241e-05 2.172475717633e-04 9.510553119576e-04 2.924842471259e-03 3.564923002421e-03\n      SVD: largest singular values : 5.521310288351e+08 6.016433233184e+08 6.780278979133e+08 1.531072312753e+09 2.759155287992e+09\n      0 Linear |R| = 1.676970e+11\n      1 Linear |R| = 7.238843e+10\n      2 Linear |R| = 2.610884e+10\n      3 Linear |R| = 2.350698e+10\n      4 Linear |R| = 1.599008e+10\n      5 Linear |R| = 5.178251e+08\n      6 Linear |R| = 4.111981e+08\n      7 Linear |R| = 3.672563e+07\n      8 Linear |R| = 2.903827e+07\n      9 Linear |R| = 3.622527e+06\n     10 Linear |R| = 1.108048e+05\n10 Nonlinear |R| = 2.478522e+17\n      SVD: condition number 3.395490743077e+19, 0 of 48 singular values are (nearly) zero\n      SVD: smallest singular values: 4.830690350242e-06 6.858442416281e-06 2.935996989954e-04 3.982720677145e-04 6.644722188774e-04\n      SVD: largest singular values : 8.059227694498e+10 1.165332228769e+11 4.846322657941e+13 1.081321105022e+14 1.640256436692e+14\n      0 Linear |R| = 2.478522e+17\n      1 Linear |R| = 6.417952e+16\n      2 Linear |R| = 1.217168e+16\n      3 Linear |R| = 3.790699e+14\n      4 Linear |R| = 8.087065e+13\n      5 Linear |R| = 5.478043e+12\n      6 Linear |R| = 1.150552e+12\n      7 Linear |R| = 4.889437e+11\n      8 Linear |R| = 3.167855e+11\n      9 Linear |R| = 2.727717e+11\n     10 Linear |R| = 8.991009e+10\n11 Nonlinear |R| = 1.031504e+20\nNonlinear solve did not converge due to DIVERGED_DTOL iterations 11\n Solve Did NOT Converge!\nAborting as solve did not converge\n\nIt doesn't seem very normal.",
                          "url": "https://github.com/idaholab/moose/discussions/22425#discussioncomment-3906573",
                          "updatedAt": "2022-10-18T14:06:55Z",
                          "publishedAt": "2022-10-18T14:06:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "SVD: condition number 3.869546805366e+20, 2 of 48 singular values are (nearly) zero\nthis is not normal.\nVery likely something is wrong with your set up. Like the equation system is underdetermined because you forgot a boundary condition",
                          "url": "https://github.com/idaholab/moose/discussions/22425#discussioncomment-3909059",
                          "updatedAt": "2022-10-18T19:14:15Z",
                          "publishedAt": "2022-10-18T19:14:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Did you try checking the Jacobian?\nhttps://mooseframework.inl.gov/help/development/analyze_jacobian.html",
                          "url": "https://github.com/idaholab/moose/discussions/22425#discussioncomment-3933493",
                          "updatedAt": "2022-10-21T12:57:48Z",
                          "publishedAt": "2022-10-21T12:57:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Ethan-xj"
                          },
                          "bodyText": "I used the AD(or maybe even if I used the AD, I still need to check the Jacobian?).By the way, I want to ask where can I find the detailed linear and nonlinear counting process in MOOSE. I always feel like I don't know enough.\nAnd the situation now is:\nWhen my four equations are f1(x1,x2,x3)  f2(x1,x2,x3)  f3(x1,x2,x3)  f1(x1,x2,x3,x4) Converged.\nWhen my four equations are f1(x1,x2,x3,x4)  f2(x1,x2,x3,x4)  f3(x1,x2,x3,x4)  f1(x1,x2,x3,x4) Nonlinear did not converged.\nI'm not sure whether there is a solution when I add the fourth variable in the previous three equations or not.\nIf possible I can talk about the method I use to solve the equation which contains variables from different blocks.",
                          "url": "https://github.com/idaholab/moose/discussions/22425#discussioncomment-3943351",
                          "updatedAt": "2022-10-23T11:34:36Z",
                          "publishedAt": "2022-10-23T11:34:36Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Ethan-xj"
                          },
                          "bodyText": "Maybe there exists some problems in the method I use.",
                          "url": "https://github.com/idaholab/moose/discussions/22425#discussioncomment-3943357",
                          "updatedAt": "2022-10-23T11:35:43Z",
                          "publishedAt": "2022-10-23T11:35:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Yes you are right, you do not need to check the Jacobian if you use AD.\nThe 2 singular values is the problem here. Your equation system is undetermined and we need to find out why.\nMaybe you could try adding x4 to 3 out of the 4 equations and see if that still works? Just guessing, maybe it does not make sense\nThe best reference on the solves in MOOSE is the PETSc manual. For hypre we have specific documentation in MOOSE",
                          "url": "https://github.com/idaholab/moose/discussions/22425#discussioncomment-3944121",
                          "updatedAt": "2022-10-23T14:49:24Z",
                          "publishedAt": "2022-10-23T14:49:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Ethan-xj"
                          },
                          "bodyText": "just found that I misspelled the subscript of the equation.\nThe correct form is :\nWhen my four equations are f1(x1,x2,x3) f2(x1,x2,x3) f3(x1,x2,x3) f4(x1,x2,x3,x4) Converged.\nWhen my four equations are f1(x1,x2,x3,x4) f2(x1,x2,x3,x4) f3(x1,x2,x3,x4) f4(x1,x2,x3,x4) Nonlinear did not converged.\nI have tried adding x4 to previous 3 equqtions. But they don't converge.",
                          "url": "https://github.com/idaholab/moose/discussions/22425#discussioncomment-3947245",
                          "updatedAt": "2022-10-24T04:44:06Z",
                          "publishedAt": "2022-10-24T04:44:05Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Can you add it to only f1 or only f2 or only f3?\nCan you attach the logs for the two cases",
                          "url": "https://github.com/idaholab/moose/discussions/22425#discussioncomment-3951849",
                          "updatedAt": "2022-10-24T14:43:28Z",
                          "publishedAt": "2022-10-24T14:43:28Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Ethan-xj"
                          },
                          "bodyText": "Oh That's weird. I remembered that I've tried to add 'x4' only to one of the three equations and the result was not converged. But just now I add 'x4' to the f3, it converged. I think I should try more times. Later I will tell you the results.",
                          "url": "https://github.com/idaholab/moose/discussions/22425#discussioncomment-3958325",
                          "updatedAt": "2022-10-25T08:45:46Z",
                          "publishedAt": "2022-10-25T08:45:45Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Error reported after \"make\"",
          "author": {
            "login": "KangChenRui"
          },
          "bodyText": "Hello everyone!\nError reported after \"make\",But it worked fine yesterday. I don't konw what happened.\nPlease help me!",
          "url": "https://github.com/idaholab/moose/discussions/22510",
          "updatedAt": "2022-11-15T18:17:15Z",
          "publishedAt": "2022-10-27T02:11:39Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nSeems odd. Did you just udpate MOOSE?\nCan you make clobberall before building?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22510#discussioncomment-3976658",
                  "updatedAt": "2022-10-27T02:29:45Z",
                  "publishedAt": "2022-10-27T02:29:44Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "KangChenRui"
                          },
                          "bodyText": "I did not update MOOSE.",
                          "url": "https://github.com/idaholab/moose/discussions/22510#discussioncomment-3979151",
                          "updatedAt": "2022-10-27T08:21:56Z",
                          "publishedAt": "2022-10-27T08:21:56Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "please try cleaning the repository then building again",
                          "url": "https://github.com/idaholab/moose/discussions/22510#discussioncomment-3982540",
                          "updatedAt": "2022-10-27T14:12:08Z",
                          "publishedAt": "2022-10-27T14:12:07Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Date type setting of variables",
          "author": {
            "login": "abc-hy"
          },
          "bodyText": "Hi everyone,\nDoes anyone know how can I set the date type of any variables I define? Currently, I found the data type of the variable I define is cell data, however, I want it to be point data type, how to set the specific data type for the variables?\nThank you very much,\nBest",
          "url": "https://github.com/idaholab/moose/discussions/22488",
          "updatedAt": "2022-10-27T02:31:08Z",
          "publishedAt": "2022-10-25T00:12:45Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nYou set the finite element family with the family parameter in the variables block.\ncell_data is usually elemental variables, while point data is nodal variables.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22488#discussioncomment-3955760",
                  "updatedAt": "2022-10-25T00:26:04Z",
                  "publishedAt": "2022-10-25T00:26:03Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "This is how I set the variable, how to change it to make this variable become point data? Currently, the data type I got is cell data.",
                          "url": "https://github.com/idaholab/moose/discussions/22488#discussioncomment-3955788",
                          "updatedAt": "2022-10-25T00:32:34Z",
                          "publishedAt": "2022-10-25T00:32:33Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "You can convert point data to cell data in Paraview directly. There's an option, maybe in the advanced settings after clicking the little cogwheel.\nIf you want moose to output point data, you ll need to create an auxiliary FIRST (order) LAGRANGE variable and project your CONSTANT MONOMIAL variable",
                          "url": "https://github.com/idaholab/moose/discussions/22488#discussioncomment-3955817",
                          "updatedAt": "2022-10-25T00:39:26Z",
                          "publishedAt": "2022-10-25T00:39:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "Got it. Thank you",
                          "url": "https://github.com/idaholab/moose/discussions/22488#discussioncomment-3956250",
                          "updatedAt": "2022-10-25T01:55:55Z",
                          "publishedAt": "2022-10-25T01:55:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "After I set the laplacian to be FIRST and LAGRANGE, I keep getting this error message. When I change back to set laplacian as CONSTANT and MONOMIAL, I can get it run. Why is this? Does that mean some variable just cannot be set as point data?\nAlso, last time I used paraview to convert cell data to point data, and I found the data at the interface is very very little, is the convertion able to maintain the accuracy? Or is cell data just not as accurate as point data?",
                          "url": "https://github.com/idaholab/moose/discussions/22488#discussioncomment-3971079",
                          "updatedAt": "2022-10-26T15:01:21Z",
                          "publishedAt": "2022-10-26T15:01:21Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Is laplacian a variable?\nwhat is your current [Mesh] block?",
                          "url": "https://github.com/idaholab/moose/discussions/22488#discussioncomment-3972387",
                          "updatedAt": "2022-10-26T17:24:52Z",
                          "publishedAt": "2022-10-26T17:24:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "Laplacian is calculated from w and c, w and c are all variables.\n\nThis is my mesh",
                          "url": "https://github.com/idaholab/moose/discussions/22488#discussioncomment-3973543",
                          "updatedAt": "2022-10-26T19:53:20Z",
                          "publishedAt": "2022-10-26T19:53:19Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "nz = 0 is not needed.\nAre you running in parallel?\nDo you hit any issue with less refinement?\nAnd there are no second order variables anywhere in the simulation?",
                          "url": "https://github.com/idaholab/moose/discussions/22488#discussioncomment-3976690",
                          "updatedAt": "2022-10-27T02:31:08Z",
                          "publishedAt": "2022-10-27T02:31:08Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "FV variable gradient in FVElemental kernel",
          "author": {
            "login": "heinono1"
          },
          "bodyText": "I need to write an FV kernel that inherits from FVElementalKernel but includes gradients of FV variables. I understand that I cannot just use coupledGradient as I would for the usual FE variables. Is there a \"ready-made\" way to access or compute (element-averages of)  gradients of FV variables using the procedures outlined in \"Reconstruction\" on https://mooseframework.inl.gov/moose/finite_volumes/fv_design.html, or do I have to figure out how to compute the element-average gradient?\nThanks.",
          "url": "https://github.com/idaholab/moose/discussions/22484",
          "updatedAt": "2022-10-26T23:36:15Z",
          "publishedAt": "2022-10-24T20:31:21Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nDid you try the functor element gradient?\nhttps://mooseframework.inl.gov/docs/doxygen/moose/classMoose_1_1FunctorBase.html#a9af8d394649b42b3c4ca9c4c7ba07e42\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22484#discussioncomment-3954959",
                  "updatedAt": "2022-10-24T21:22:09Z",
                  "publishedAt": "2022-10-24T21:22:09Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "heinono1"
                  },
                  "bodyText": "Hi,\n\nThanks. Sorry for being a bit slow on the uptake, but do you know of an\nexample of usage?\n\u2026\nOn Mon, Oct 24, 2022 at 4:22 PM Guillaume Giudicelli < ***@***.***> wrote:\n Hello\n\n Did you try the functor element gradient?\n\n https://mooseframework.inl.gov/docs/doxygen/moose/classMoose_1_1FunctorBase.html#a9af8d394649b42b3c4ca9c4c7ba07e42\n\n Guillaume\n\n \u2014\n Reply to this email directly, view it on GitHub\n <#22484 (comment)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AEKZEFYT7YCH4PKVOYQ2J33WE34YXANCNFSM6AAAAAARNKQ5U4>\n .\n You are receiving this because you authored the thread.Message ID:\n ***@***.***>\n\n\n-- \nOlle Heinonen\n***@***.***",
                  "url": "https://github.com/idaholab/moose/discussions/22484#discussioncomment-3955235",
                  "updatedAt": "2022-10-24T22:24:19Z",
                  "publishedAt": "2022-10-24T22:24:18Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "I guess I dont\nI thought this one had\nhttps://github.com/idaholab/moose/blob/next/modules/navier_stokes/src/fvkernels/INSFVMixingLengthReynoldsStress.C\nbut it uses another API, adGradSln, which should work too",
                          "url": "https://github.com/idaholab/moose/discussions/22484#discussioncomment-3955284",
                          "updatedAt": "2022-10-24T22:37:21Z",
                          "publishedAt": "2022-10-24T22:37:21Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "An example of what @GiudGiud suggested (which is a great option), is here",
                          "url": "https://github.com/idaholab/moose/discussions/22484#discussioncomment-3964430",
                          "updatedAt": "2022-10-25T21:30:44Z",
                          "publishedAt": "2022-10-25T21:30:43Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "heinono1"
                  },
                  "bodyText": "Thanks. I'll give it a try.\n\u2026\nOn Mon, Oct 24, 2022 at 5:37 PM Guillaume Giudicelli < ***@***.***> wrote:\n I guess I dont\n I thought this one had\n\n https://github.com/idaholab/moose/blob/next/modules/navier_stokes/src/fvkernels/INSFVMixingLengthReynoldsStress.C\n\n but it uses another API, adGradSln, which should work too\n\n \u2014\n Reply to this email directly, view it on GitHub\n <#22484 (reply in thread)>,\n or unsubscribe\n <https://github.com/notifications/unsubscribe-auth/AEKZEFYIDDW2WPSD5WUYRSDWE4FSXANCNFSM6AAAAAARNKQ5U4>\n .\n You are receiving this because you authored the thread.Message ID:\n ***@***.***>\n\n\n-- \nOlle Heinonen\n***@***.***",
                  "url": "https://github.com/idaholab/moose/discussions/22484#discussioncomment-3960477",
                  "updatedAt": "2022-10-25T13:17:20Z",
                  "publishedAt": "2022-10-25T13:17:19Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "lindsayad"
                  },
                  "bodyText": "We're trying to encourage our posters to use threads in their responses to answers. You can't use coupleGradient, but you should be able to use adCoupledGradient as you would for an AD kernel in FE",
                  "url": "https://github.com/idaholab/moose/discussions/22484#discussioncomment-3964417",
                  "updatedAt": "2022-10-25T21:28:29Z",
                  "publishedAt": "2022-10-25T21:28:28Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "heinono1"
                          },
                          "bodyText": "Thanks, Alex. Sorry about breaking the thread.",
                          "url": "https://github.com/idaholab/moose/discussions/22484#discussioncomment-3970022",
                          "updatedAt": "2022-10-26T13:22:34Z",
                          "publishedAt": "2022-10-26T13:22:34Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "No problem at all!",
                          "url": "https://github.com/idaholab/moose/discussions/22484#discussioncomment-3971997",
                          "updatedAt": "2022-10-26T16:38:28Z",
                          "publishedAt": "2022-10-26T16:38:28Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "heinono1"
                          },
                          "bodyText": "@lindsayad so does adCoupledGradient work in the FV system so I can use it directly to calculate an element-average gradient (FVElementalKernel) without any other extra steps (eg getting element faces etc etc)?",
                          "url": "https://github.com/idaholab/moose/discussions/22484#discussioncomment-3974178",
                          "updatedAt": "2022-10-26T21:15:48Z",
                          "publishedAt": "2022-10-26T21:15:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Correct. For a finite volume variable, adCoupledGradient returns a cell-average gradient computed via Green-Gauss",
                          "url": "https://github.com/idaholab/moose/discussions/22484#discussioncomment-3974575",
                          "updatedAt": "2022-10-26T22:01:14Z",
                          "publishedAt": "2022-10-26T22:01:13Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "heinono1"
                          },
                          "bodyText": "That is awesome! Thank you, MOOSE team!",
                          "url": "https://github.com/idaholab/moose/discussions/22484#discussioncomment-3975630",
                          "updatedAt": "2022-10-26T23:36:16Z",
                          "publishedAt": "2022-10-26T23:36:15Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Strain at t_points at shell integration points",
          "author": {
            "login": "Zoophish"
          },
          "bodyText": "Hi, I'm trying to extract curvature values from shell elements by using some AuxVariables. To do this, I'm accessing the strain values at the two t_points above and below the shell mid surface at each quadrature point using the RankTwoTensor AuxKernel, like in the modules/tensor_mechanics/test/tests/shell/static/straintest.i example.\nIf I use the material property total_global_strain_t_points_, like in the example, the strain values all output zero at every element, despite my model being under load and producing non-zero displacement. Interestingly, the global_stress_t_points_ material property outputs valid stress values, so it seems to only be an issue with the strain.\nDoes anyone know the correct way to extract the strain values at the t_points, or why they may be outputting zero? I will add my input file as a comment.\nThanks,\nSam",
          "url": "https://github.com/idaholab/moose/discussions/22460",
          "updatedAt": "2022-10-26T17:04:02Z",
          "publishedAt": "2022-10-21T10:11:35Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "Zoophish"
                  },
                  "bodyText": "This is my input file:\nx_size = 100 #mm\ny_size = 25 #mm\nn_plies = 16\nply_thickness = '${fparse 5/n_plies}'\nn_elems_x = 64\n# n_elems_y should be even to allow for the creation of the centerline sideset\nn_elems_y = 16\nforce = 500 # N\npressure = '${fparse force / (y_size)}'\n\n[Mesh]\n  [Generator]\n    type = GeneratedMeshGenerator\n    dim = 2\n    xmax = ${x_size}\n    ymax = ${y_size}\n    nx = ${n_elems_x}\n    ny = ${n_elems_y}\n  []\n  [SampleXCenterline]\n    type = ParsedGenerateSideset\n    input = Generator\n    new_sideset_name = Centerline\n    combinatorial_geometry = 'x=${fparse x_size/2}'\n  []\n[]\n\n[Variables]\n  [disp_x]\n  []\n  [disp_y]\n  []\n  [disp_z]\n  []\n  [rot_x]\n  []\n  [rot_y]\n  []\n[]\n\n[AuxVariables]\n  [strain_xx_bottom]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n  [strain_xx_top]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n  [strain_yy_bottom]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n  [strain_yy_top]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n  [strain_xx_midplane]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n  [kxx]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n[]\n\n[AuxKernels]\n  [strain_xx_bottom]\n    type = RankTwoAux\n    variable = strain_xx_bottom\n    # quadrature underneath the midplane\n    rank_two_tensor = total_global_strain_t_points_0\n    index_i = 0\n    index_j = 0\n  []\n  [stress_xx_top]\n    type = RankTwoAux\n    variable = strain_xx_top\n    # quadrature above the midplane\n    rank_two_tensor = global_stress_t_points_1\n    index_i = 0\n    index_j = 0\n  []\n  [strain_yy_bottom]\n    type = RankTwoAux\n    variable = strain_yy_bottom\n    # quadrature underneath the midplane\n    rank_two_tensor = total_global_strain_t_points_0\n    index_i = 1\n    index_j = 1\n  []\n  [strain_yy_top]\n    type = RankTwoAux\n    variable = strain_yy_top\n    # quadrature above the midplane\n    rank_two_tensor = total_global_strain_t_points_1\n    index_i = 1\n    index_j = 1\n  []\n[]\n\n[GlobalParams]\n  displacements = 'disp_x disp_y disp_z'\n  rotations = 'rot_x rot_y'\n[]\n\n[Kernels]\n  [solid_disp_x]\n    type = ADStressDivergenceShell\n    block = '0'\n    component = 0\n    variable = disp_x\n    through_thickness_order = SECOND\n  []\n  [solid_disp_y]\n    type = ADStressDivergenceShell\n    block = '0'\n    component = 1\n    variable = disp_y\n    through_thickness_order = SECOND\n  []\n  [solid_disp_z]\n    type = ADStressDivergenceShell\n    block = '0'\n    component = 2\n    variable = disp_z\n    through_thickness_order = SECOND\n  []\n  [solid_rot_x]\n    type = ADStressDivergenceShell\n    block = '0'\n    component = 3\n    variable = rot_x\n    through_thickness_order = SECOND\n  []\n  [solid_rot_y]\n    type = ADStressDivergenceShell\n    block = '0'\n    component = 4\n    variable = rot_y\n    through_thickness_order = SECOND\n  []\n[]\n\n[Materials]\n  # Materials are computed using the shell functions, see the moose docs on Shells.\n  [stress]\n    type = ADComputeShellStress\n    through_thickness_order = SECOND\n  []\n  [elasticity]\n    # isotropic aluminium\n    type = ADComputeIsotropicElasticityTensorShell\n    youngs_modulus = 70e3\n    poissons_ratio = 0.31\n    through_thickness_order = SECOND\n    block = 0\n  []\n  [strain]\n    type = ADComputeFiniteShellStrain\n    thickness = '${fparse ply_thickness*n_plies}'\n    through_thickness_order = SECOND\n  []\n[]\n\n[BCs]\n  [Fixed_X]\n    type = ADDirichletBC\n    boundary = left\n    value = 0\n    variable = disp_x\n  []\n  [Fixed_Y]\n    type = ADDirichletBC\n    boundary = Centerline\n    value = 0\n    variable = disp_y\n  []\n  [Fixed_Z]\n    type = ADDirichletBC\n    boundary = 'left right'\n    value = 0\n    variable = disp_z\n  []\n  [Load]\n    type = ADNeumannBC\n    boundary = Centerline\n    value = '${fparse -pressure/2}'\n    variable = disp_z\n  []\n[]\n\n[Preconditioning]\n  [smp]\n    type = SMP\n    full = false\n  []\n[]\n\n[Executioner]\n  type = Transient\n  dt = 1\n  dtmin = 1\n  end_time = 1\n  automatic_scaling = TRUE\n  solve_type = 'NEWTON'\n  line_search = 'default'\n  petsc_options_iname = '-pc_type  -snes_linesearch_type -pc_factor_shift_type -snes_max_it  -ksp_max_it'\n  petsc_options_value = 'lu        basic                 NONZERO               20            30'\n[]\n\n[Postprocessors]\n  [Strain_XX]\n    type = ElementalVariableValue\n    elementid = 543\n    variable = strain_xx_bottom\n  []\n[]\n\n[Outputs]\n  [output_file]\n    type = Exodus\n    file_base = shell_cantilever_stress_gradient\n  []\n[]",
                  "url": "https://github.com/idaholab/moose/discussions/22460#discussioncomment-3932236",
                  "updatedAt": "2022-10-21T10:59:00Z",
                  "publishedAt": "2022-10-21T10:12:53Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@neuphris @recuero",
                  "url": "https://github.com/idaholab/moose/discussions/22460#discussioncomment-3933446",
                  "updatedAt": "2022-10-21T12:52:24Z",
                  "publishedAt": "2022-10-21T12:52:23Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "Zoophish"
                  },
                  "bodyText": "So I just discovered that changing ADComputeFiniteShellStrain to ADComputeIncrementalShellStrain solves the issue, however I am not sure why this is. Would anyone be able to explain?\nOn a slight side note, I was also having an issue using ADComputeIncrementalShellStrain where it was giving the error \"Shell element needs to have exactly four quadrature points.\" for the above input file. However, I verified that all of the elements in the model had exactly 4 quadrature points using a custom AuxKernel. I removed the error-throwing code in the ADComputeIncrementalShellStrain C++ file,  recompiled it and it worked. Could this be a bug?",
                  "url": "https://github.com/idaholab/moose/discussions/22460#discussioncomment-3933534",
                  "updatedAt": "2022-10-21T13:02:07Z",
                  "publishedAt": "2022-10-21T13:02:07Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "neuphris"
                          },
                          "bodyText": "My first guess that \" Shell Element needs to have exactly four quadrature points\"   may have been generated due to the BC that was developed to be applied at the area and is being applied at the edge (I don't know how ADNeuman BC works) because when I tried to create a test with pressure BC (that should be applied over the area) at the edge of shell element, it led to the failure of the test cases and we decided to generate that error for such mismatch. Refer to the comment at the end of #20771",
                          "url": "https://github.com/idaholab/moose/discussions/22460#discussioncomment-3935801",
                          "updatedAt": "2022-10-21T17:03:56Z",
                          "publishedAt": "2022-10-21T17:03:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Zoophish"
                          },
                          "bodyText": "Okay that's interesting, I think my workaround for now will be to comment out the error as I seem to be getting valid results with the Neumann boundary.\nWould you be able to explain why ADComputeFiniteShellStrain does not work?",
                          "url": "https://github.com/idaholab/moose/discussions/22460#discussioncomment-3948199",
                          "updatedAt": "2022-10-24T07:45:28Z",
                          "publishedAt": "2022-10-24T07:45:27Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "neuphris"
                          },
                          "bodyText": "I went through the code quickly and found that the strains in the contravariant system are not converted to the global strain values which would have been stored in _total_global_strain variable for output in the ADComputeFiniteShellStrain due to which you are getting zero values for the strain.\nThe stress are correct because the strains in contravariant system are used to calculate the stress in the covariant  system and is converted into the global system.\nI think it should be an easy fix. Just adding the few lines of code in theend of  ADFiniteShellStrain::computeProperties() (similar to ADIncrementalShellStrain::computeProperties())\n  for (unsigned int ii = 0; ii < 3; ++ii)\n    for (unsigned int jj = 0; jj < 3; ++jj)\n      _unrotated_total_strain(ii, jj) = MetaPhysicL::raw_value((*_total_strain[j])[i](ii, jj));\n  (*_total_global_strain[j])[i] = (*_contravariant_transformation_matrix[j])[i] *\n                                  _unrotated_total_strain *\n                                  (*_contravariant_transformation_matrix[j])[i].transpose();",
                          "url": "https://github.com/idaholab/moose/discussions/22460#discussioncomment-3963151",
                          "updatedAt": "2022-10-25T18:21:09Z",
                          "publishedAt": "2022-10-25T18:20:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Zoophish"
                          },
                          "bodyText": "Thanks for the help, I'll try out those changes.",
                          "url": "https://github.com/idaholab/moose/discussions/22460#discussioncomment-3967700",
                          "updatedAt": "2022-10-26T08:26:03Z",
                          "publishedAt": "2022-10-26T08:26:03Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "neuphris"
                          },
                          "bodyText": "@bwspenc We never noticed this. It needs to be fixed (i haven't tried, but it seems like the above-mentioned change is the only thing missing) and merged.",
                          "url": "https://github.com/idaholab/moose/discussions/22460#discussioncomment-3971797",
                          "updatedAt": "2022-10-26T16:18:10Z",
                          "publishedAt": "2022-10-26T16:18:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Zoophish"
                          },
                          "bodyText": "I can confirm the changes you suggested worked when I added it to my copy of MOOSE and recompiled.",
                          "url": "https://github.com/idaholab/moose/discussions/22460#discussioncomment-3972231",
                          "updatedAt": "2022-10-26T17:04:02Z",
                          "publishedAt": "2022-10-26T17:04:01Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}