{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyNC0wMi0yOFQxOTowMjozNi0wNjowMM4AX8DX"
    },
    "edges": [
      {
        "node": {
          "title": "Call a component of a normal vector in a Postprocessor",
          "author": {
            "login": "TLWise"
          },
          "bodyText": "I need to use the y-component of _normal in my Postprocessor. Can this be accomplished and if so how what is the syntax to call it for use?",
          "url": "https://github.com/idaholab/moose/discussions/26940",
          "updatedAt": "2024-03-02T21:40:46Z",
          "publishedAt": "2024-03-01T16:34:13Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "Ali1990dashti"
                  },
                  "bodyText": "Which module of MOOSE are you using to calculate normals? If you are using PorousFlow the calculation is quite straightforward via AuxKernels and AuxVariables:\n[AuxVariables]\n  [n1]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n  [n2]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n  [n3]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n[]\n\n[AuxKernels]\n  [normal_dirn_x]\n    type = PorousFlowElementNormal\n    variable = n1\n    component = x\n  []\n  [normal_dirn_y]\n    type = PorousFlowElementNormal\n    variable = n2\n    component = y\n  []\n  [normal_dirn_z]\n    type = PorousFlowElementNormal\n    variable = n3\n    component = z\n  []\n[]\n\nYou can also see more examples here.\nThen, you will have each normal as an elemental variable in your (exodus) output.",
                  "url": "https://github.com/idaholab/moose/discussions/26940#discussioncomment-8651420",
                  "updatedAt": "2024-03-02T12:00:40Z",
                  "publishedAt": "2024-03-02T12:00:40Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "TLWise"
                          },
                          "bodyText": "@Ali1990dashti, I am using the Combined App, modeling channel flow.",
                          "url": "https://github.com/idaholab/moose/discussions/26940#discussioncomment-8652466",
                          "updatedAt": "2024-03-02T15:22:27Z",
                          "publishedAt": "2024-03-02T15:22:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "TLWise"
                          },
                          "bodyText": "when I included the code into my file.i I received the following error:\n*** ERROR ***\nA 'PorousFlowElementNormal' is not a registered object.\nIf you are trying to find this object in a dynamically loaded library, make sure that\nthe library can be found either in your \"Problem/library_path\" parameter or in the\nMOOSE_LIBRARY_PATH environment variable.",
                          "url": "https://github.com/idaholab/moose/discussions/26940#discussioncomment-8653306",
                          "updatedAt": "2024-03-02T18:02:45Z",
                          "publishedAt": "2024-03-02T18:02:44Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Ali1990dashti"
                          },
                          "bodyText": "The error you faced is discussed here.",
                          "url": "https://github.com/idaholab/moose/discussions/26940#discussioncomment-8653373",
                          "updatedAt": "2024-03-02T18:16:15Z",
                          "publishedAt": "2024-03-02T18:16:14Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "TLWise"
                          },
                          "bodyText": "After adding APPs to the make file of Parent(crab) APP, I had to $ make clobberall, followed by a make of the parent APP. I no longer get an error about 'PorousFlowElementNormal' is not a registered object. I do no however have this error:\n*** ERROR ***\nThe parameter vectors constant_names and constant_values must have equal length.",
                          "url": "https://github.com/idaholab/moose/discussions/26940#discussioncomment-8653950",
                          "updatedAt": "2024-03-02T20:26:53Z",
                          "publishedAt": "2024-03-02T20:26:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Hello\nThis is coming from one of your Parsed objects. It should say which one in the error message\nAnd the message says what the problem is exactly\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/26940#discussioncomment-8654060",
                          "updatedAt": "2024-03-02T20:56:43Z",
                          "publishedAt": "2024-03-02T20:56:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "TLWise"
                          },
                          "bodyText": "Here is how I'm attempting to implement it:\n[AuxVariables]\n[vel_x]\norder = FIRST\n[]\n[vel_y]\norder = FIRST\n[]\n[nx]\norder = CONSTANT\nfamily = MONOMIAL\n[]\n[ny]\norder = CONSTANT\nfamily = MONOMIAL\n[]\n[nz]\norder = CONSTANT\nfamily = MONOMIAL\n[]\n[]\n[AuxKernels]\n[vel_x]\ntype = VectorVariableComponentAux\nvariable = vel_x\nvector_variable = velocity\ncomponent = 'x'\n[]\n[vel_y]\ntype = VectorVariableComponentAux\nvariable = vel_y\nvector_variable = velocity\ncomponent = 'y'\n[]\n[nx]\ntype = PorousFlowElementNormal\nboundary = 'CylWall'\nvariable = nx\ncomponent = x\n1D_perp = '0 1 0'\n[]\n[ny]\ntype = PorousFlowElementNormal\nboundary = 'CylWall'\nvariable = ny\ncomponent = y\n1D_perp = '0 1 0'\n[]\n[nz]\ntype = PorousFlowElementNormal\nboundary = 'CylWall'\nvariable = nz\ncomponent = z\n1D_perp = '0 1 0'\n[]\n[]\n[Postprocessors]\n[drag_force]\nconstant_names = 'nx'\n# #    constant_expressions = '${rho} ${fparse 2/3inlet_velocity} ${fparse 2circle_radius}'\ntype = ParsedPostprocessor\nfunction = 'mu_diff_vel_x - normal_x_pressure * nx'\npp_names = 'mu_diff_vel_x normal_x_pressure'\nexecute_on = 'INITIAL TIMESTEP_END'\n[]\n[]",
                          "url": "https://github.com/idaholab/moose/discussions/26940#discussioncomment-8654080",
                          "updatedAt": "2024-03-02T21:02:25Z",
                          "publishedAt": "2024-03-02T21:02:24Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "The ParsedPostprocessor syntax is the problem.\nYou need to define the symbols and the names for every constant\nSo these two parameters must match",
                          "url": "https://github.com/idaholab/moose/discussions/26940#discussioncomment-8654124",
                          "updatedAt": "2024-03-02T21:12:18Z",
                          "publishedAt": "2024-03-02T21:12:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "TLWise"
                          },
                          "bodyText": "Will the parsedpostprocessor work at all for these combination of auxvariables and postprocessors?",
                          "url": "https://github.com/idaholab/moose/discussions/26940#discussioncomment-8654161",
                          "updatedAt": "2024-03-02T21:21:28Z",
                          "publishedAt": "2024-03-02T21:21:27Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "The postprocessors yes.\nThe auxvariable no. These cannot be inputs as we do not know which value to use (they are fields, there are many values)\nUse a postprocessor to perform the desired reduction operation (average?) on the auxiliary variable first",
                          "url": "https://github.com/idaholab/moose/discussions/26940#discussioncomment-8654229",
                          "updatedAt": "2024-03-02T21:40:47Z",
                          "publishedAt": "2024-03-02T21:40:46Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Why was the sobol value 0 when I conducted sensitivity analysis",
          "author": {
            "login": "Ating24"
          },
          "bodyText": "Is there an issue with the input file I used for evaluation, or is it for some reason?Here is my input file\n[StochasticTools]\n[]\n[Distributions]\n  [k_dist]\n    type = Uniform\n    lower_bound = 0.8\n    upper_bound = 1.2\n  []\n  [density_dist]\n    type = Uniform\n    lower_bound = 0.9\n    upper_bound = 1.1\n  []\n  [cp_dist]\n    type = Uniform\n    lower_bound = 0.9\n    upper_bound = 1.1\n  []\n  [fluxcoff_dist]\n    type = Uniform\n    lower_bound = 1050\n    upper_bound = 1950\n  []\n[]\n\n[Samplers]\n  [sample]\n    type = MonteCarlo\n    num_rows = 10000\n    distributions = 'k_dist density_dist cp_dist fluxcoff_dist'\n    execute_on = initial\n  []  \n[]\n\n[Surrogates]\n  [poly_chaos_disp_x1]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_x1.rd'\n  []\n  [poly_chaos_disp_y1]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_y1.rd'\n  []\n  [poly_chaos_disp_z1]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_z1.rd'\n  []\n  [poly_chaos_disp_x2]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_x2.rd'\n  []\n  [poly_chaos_disp_y2]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_y2.rd'\n  []\n  [poly_chaos_disp_z2]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_z2.rd'\n  []\n  [poly_chaos_disp_x3]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_x3.rd'\n  []\n  [poly_chaos_disp_y3]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_y3.rd'\n  []\n  [poly_chaos_disp_z3]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_z3.rd'\n  []\n  [poly_chaos_disp_x4]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_x4.rd'\n  []\n  [poly_chaos_disp_y4]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_y4.rd'\n  []\n  [poly_chaos_disp_z4]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_z4.rd'\n  []  [poly_chaos_disp_x5]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_x5.rd'\n  []\n  [poly_chaos_disp_y5]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_y5.rd'\n  []\n  [poly_chaos_disp_z5]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_disp_z5.rd'\n  []\n  [poly_chaos_temperature1]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_temperature1.rd'\n  []\n  [poly_chaos_temperature2]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_temperature2.rd'\n  []\n  [poly_chaos_temperature3]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_temperature3.rd'\n  []\n  [poly_chaos_temperature4]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_temperature4.rd'\n  []\n  [poly_chaos_temperature5]\n    type = PolynomialChaos\n    filename = 'poly_chaos_training_poly_chaos_temperature5.rd'\n  []\n[]\n\n\n\n[Reporters]\n  [samp]\n    type = EvaluateSurrogate\n    model = 'poly_chaos_disp_x1 poly_chaos_disp_y1 poly_chaos_disp_z1 poly_chaos_disp_x2 poly_chaos_disp_y2 poly_chaos_disp_z2 poly_chaos_disp_x3 poly_chaos_disp_y3 poly_chaos_disp_z3 poly_chaos_disp_x4 poly_chaos_disp_y4 poly_chaos_disp_z4 poly_chaos_disp_x5 poly_chaos_disp_y5 poly_chaos_disp_z5 poly_chaos_temperature1 poly_chaos_temperature2 poly_chaos_temperature3 poly_chaos_temperature4 poly_chaos_temperature5'\n    sampler = sample\n    parallel_type = ROOT\n    #execute_on = final\n  []\n  [stats]\n    type = PolynomialChaosReporter\n    pc_name = 'poly_chaos_disp_x1 poly_chaos_disp_y1 poly_chaos_disp_z1 poly_chaos_disp_x2 poly_chaos_disp_y2 poly_chaos_disp_z2 poly_chaos_disp_x3 poly_chaos_disp_y3 poly_chaos_disp_z3 poly_chaos_disp_x4 poly_chaos_disp_y4 poly_chaos_disp_z4 poly_chaos_disp_x5 poly_chaos_disp_y5 poly_chaos_disp_z5 poly_chaos_temperature1 poly_chaos_temperature2 poly_chaos_temperature3 poly_chaos_temperature4 poly_chaos_temperature5'\n    #statistics = 'mean stddev'\n    #local_sensitivity_points = '1 1 1 1500; 1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500; 1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500; 1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500; 1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500'\n    include_sobol = True\n  []\n[]\n\n[Outputs]\n  csv = true\n    [out]\n    type = JSON\n    execute_on = final\n  []\n[]",
          "url": "https://github.com/idaholab/moose/discussions/26915",
          "updatedAt": "2024-03-02T01:19:09Z",
          "publishedAt": "2024-02-28T01:59:08Z",
          "category": {
            "name": "Q&A Tools"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "Ating24"
                  },
                  "bodyText": "@grmnptr",
                  "url": "https://github.com/idaholab/moose/discussions/26915#discussioncomment-8637730",
                  "updatedAt": "2024-03-01T02:52:10Z",
                  "publishedAt": "2024-03-01T02:52:09Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "grmnptr"
                          },
                          "bodyText": "Try using this (there might be issues on final output):\n[Reporters]\n  [samp]\n    type = EvaluateSurrogate\n    model = 'poly_chaos_disp_x1 poly_chaos_disp_y1 poly_chaos_disp_z1 poly_chaos_disp_x2 poly_chaos_disp_y2 poly_chaos_disp_z2 poly_chaos_disp_x3 poly_chaos_disp_y3 poly_chaos_disp_z3 poly_chaos_disp_x4 poly_chaos_disp_y4 poly_chaos_disp_z4 poly_chaos_disp_x5 poly_chaos_disp_y5 poly_chaos_disp_z5 poly_chaos_temperature1 poly_chaos_temperature2 poly_chaos_temperature3 poly_chaos_temperature4 poly_chaos_temperature5'\n    sampler = sample\n    parallel_type = ROOT\n    execute_on = final\n    outputs = json\n  []\n  [stats]\n    type = PolynomialChaosReporter\n    pc_name = 'poly_chaos_disp_x1 poly_chaos_disp_y1 poly_chaos_disp_z1 poly_chaos_disp_x2 poly_chaos_disp_y2 poly_chaos_disp_z2 poly_chaos_disp_x3 poly_chaos_disp_y3 poly_chaos_disp_z3 poly_chaos_disp_x4 poly_chaos_disp_y4 poly_chaos_disp_z4 poly_chaos_disp_x5 poly_chaos_disp_y5 poly_chaos_disp_z5 poly_chaos_temperature1 poly_chaos_temperature2 poly_chaos_temperature3 poly_chaos_temperature4 poly_chaos_temperature5'\n    #statistics = 'mean stddev'\n    #local_sensitivity_points = '1 1 1 1500; 1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500; 1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500; 1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500; 1 1 1 1500;1 1 1 1500;1 1 1 1500;1 1 1 1500'\n    include_sobol = True\n    execute_on = final\n    outputs = json\n  []\n[]\n\n[Outputs]\n  csv = true\n  [json]\n    type = JSON\n    execute_on = final\n  []\n[]",
                          "url": "https://github.com/idaholab/moose/discussions/26915#discussioncomment-8644601",
                          "updatedAt": "2024-03-01T15:37:51Z",
                          "publishedAt": "2024-03-01T15:37:51Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "Ating24"
                          },
                          "bodyText": "I have tried and the result is still 0",
                          "url": "https://github.com/idaholab/moose/discussions/26915#discussioncomment-8649140",
                          "updatedAt": "2024-03-02T01:19:10Z",
                          "publishedAt": "2024-03-02T01:19:09Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Excavation with a huge number of blocks",
          "author": {
            "login": "jmeier"
          },
          "bodyText": "Dear Moose-Community,\nI have seen that the topic of simulating excavation stages has already been discussed several times in the Discussions and that there is also a very nice demo-model for this. However, the examples found can either describe the excavation front with an x-y-z function or have a small number of blocks.\nI would like to create a 3D model in which a large number of blocks are successively excavated and backfilled over time. The blocks (more than 5000) are arranged in such a way that no \"excavation front\" can be reasonably described mathematically as an equation. Excavation and refilling must therefore be defined per block over time.\nA few pieces of the puzzle that I have found so far:\n\n\nCoupledVarThresholdElementSubdomainModifier: Using this userobject, one can \"activate\"/\"deactivate\" blocks over time.\n\nPlus: Using the \"block\" parameter i can restrict this userobject to a singe block. Thus, function to be given in \"coupled_var\" needs only depend on time.\nMinus: Moving a block to another subdomain takes place abruptly.\nQuestion 1: If I use this user object, I have to create thousands of instances of the CoupledVarThresholdElementSubdomainModifier (e.g. via script). Given this amount of UserObjects, do I have to expect performance or memory problems in Moose?\nQuestion 2: In case there are performance or memory problems for a huge number of  CoupledVarThresholdElementSubdomainModifier - instances, is there a way to reduce the number of userobjects e.g. using a CSV-file? I did not find a way to make the function to be given in \"coupled_var\" to be dependent on the blocks name and using the coordinates seems messy.\n\n\n\nPre-Factoring Material Properies: In order to avoid (or prepare) the sudden removal of blocks, the stiffness can be reduced in a time-dependent manner using \"elasticity_tensor_prefactor\", for example (density etc. likewise; e.g. #23677)\n\nPlus: Numerical stability.\nQuestion 3: Because the blocks are to be excavated one by one, I would have to create a huge number of materials (worst case: one material set per block). This I can do easily by script. But: Given this amount of materials, do I have to expect performance or memory problems in Moose?\nQuestion 4: In case there are performance or memory problems for a huge number of  materials, is there a way to reduce the number of materials e.g. using a CSV-file? I did not find a way to make the function to be given in \"elasticity_tensor_prefactor\" to be dependent on the blocks name.\n\n\n\nI hope to be able to combine both approaches above: First \"fade out\" a block by factorising the material parameters and then remove the block completely.\nKind regards, J\u00f6rg",
          "url": "https://github.com/idaholab/moose/discussions/26505",
          "updatedAt": "2024-03-01T17:25:35Z",
          "publishedAt": "2024-01-08T15:51:55Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nA few comments. Ultimately, whether the performance is acceptable for you or not depends on your machine and your patience so that's just something you should find out. Objects are replicated across parallel domains though so there will be a penalty from using thousands of them, especially in memory. How big is the mesh? How big are each node if using HPC?\nBut\n\nCoupledVarThresholdElementSubdomainModifier:\nPlus: Using the \"block\" parameter i can restrict this userobject to a singe block. Thus, function to be given in \"coupled_var\" needs only depend on time.\n\nyou could just use one of these objects and not-block restricti it. I think you should aim to capture the block-dependent behavior in the threshold instead.\n\nQuestion 3: Because the blocks are to be excavated one by one, I would have to create a huge number of materials\n\nsame idea. Just make a block restricted tensor prefactor instead if you do not want to have thousands of materials. (what you say in Q4)\nThousands of materials will scale well CPU-wise, they are not all active at the same time on every element.\n\nI did not find a way to make the function to be given in \"elasticity_tensor_prefactor\" to be dependent on the blocks name.\n\nthis has not been needed before.  But the way to do this will be to use a material property OR a variable OR use the functor interfaces (most flexible) for this parameter. The material will need a slight modification to do that.\nI would recommend starting small. One or two blocks at most.\nBest,\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8062063",
                  "updatedAt": "2024-01-09T08:38:06Z",
                  "publishedAt": "2024-01-09T08:38:05Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jmeier"
                          },
                          "bodyText": "Dear Guillaume,\nThank you for your reply and your comments.\nI don't have an HPC available. That's why I want to be careful with the resources. The model will probably consist of 300'000 to 400'000 TET10 elements.\n\nI think you should aim to capture the block-dependent behaviour in the threshold instead.\n\nThat was the aim of my Q2 and Q4: I'm not yet clear on the best way to do this. I have seen that PropertyReadFile has a parameter \"read_type\", which I can set to \"block\".\n\nUnder PropertyReadFile it is specified that the order of the blocks in the CSV must match that in the Moose (and the IDs must start with 1). Alternatively, can I enter the block name in the first column of the CSV?\nTherefore: The rows of the CSV correspond to the blocks. So I would like to define when which block is on/off in the columns.\nHow do I map the data in the columns of the CSV to my model time? In other words: How do I select a column of the CVS depending on the model time \"t\"?\n\nKind regards,\nJ\u00f6rg",
                          "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8062900",
                          "updatedAt": "2024-01-09T09:53:45Z",
                          "publishedAt": "2024-01-09T09:53:45Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Alternatively, can I enter the block name in the first column of the CSV?\n\nthat has not been implemented but you could do it if you want to.\n\nHow do I map the data in the columns of the CSV to my model time?\n\nyou currently cannot. We have not added a time column. That's also something that could be added\nYou can specify multiple CSV files and change every time step / every time the PropertyReadFile is executed (can be more or less frequent than time steps)",
                          "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8062973",
                          "updatedAt": "2024-01-09T09:59:57Z",
                          "publishedAt": "2024-01-09T09:59:56Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jmeier"
                          },
                          "bodyText": "Dear Guillaume,\n\n\nAlternatively, can I enter the block name in the first column of the CSV?\n\n\n\nthat has not been implemented but you could do it if you want to.\n\nUnfortunately, my C++ skills are are not sufficient. However, this functionality would certainly be something that would make the reading of block-related data much more robust in Moose. Perhaps something for the wish-list?\n\u00a0\n\nWe have not added a time column. That's also something that could be added\nYou can specify multiple CSV files and change every time step / every time the PropertyReadFile is executed (can be more or less frequent than time steps)\n\nI've seen the discussion going on in #26294. For my model I expect a lot of automatically generated time steps. So providing one CSV per time step is no option (due to fact I do not know the time steps chosen by Moose). So, I presume for me it would be favorable to use the approach you describe as:\n\nSo if you used an auxkernel with let's say 10 CSV files for ten time steps you need:\n\n10 PropertyReadFile to read each file\n10 functions PiecewiseConstantFromCSV, one for each UO\n10 auxkernels FunctionAux that set the SAME auxvariable damage using a different function\n10 Controls objects that turn on/off the auxkernels on each time step\n\n\n... and then use the auxvariable inside the CoupledVarThresholdElementSubdomainModifier? If this is correct, what type of AuxVariable do I have to define to maintain \"read_type='block'\" given in PropertyReadFile and PiecewiseConstantFromCSV?\nWhen pre-factoring material properies, I presume I need 20 auxkernels with this approach (10 writing one auxvariable, and another one writing another auxvariable). When pre-factoring I use these two auxvariables and interpolate?\nKind regards,\nJ\u00f6rg",
                          "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8067268",
                          "updatedAt": "2024-01-09T14:23:07Z",
                          "publishedAt": "2024-01-09T14:23:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "So, I presume for me it would be favorable to use the approach you describe as:\n\nno this is an old approach.\nYou can do this approach with many Controls object (one for every file change you want) and specifying all the CSV files in a single PropertyReadFile, with a single PiecewiseConstrantFromCSV etc.",
                          "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8078772",
                          "updatedAt": "2024-01-10T11:18:08Z",
                          "publishedAt": "2024-01-10T11:18:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "When pre-factoring I use these two auxvariables and interpolate?\n\nthis is not a bad idea actually if you want a smoothly varying pre-factor. I still would only use 2 auxvariables, so 2 functions, 2 FunctionAux and 2 PropertyReadFile (one for each side of the interpolation)",
                          "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8078781",
                          "updatedAt": "2024-01-10T11:19:30Z",
                          "publishedAt": "2024-01-10T11:19:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jmeier"
                          },
                          "bodyText": "Dear @GiudGiud,\n\nYou can do this approach with many Controls object (one for every file change you want) and specifying all the CSV files in a single PropertyReadFile, with a single PiecewiseConstrantFromCSV etc.\n\nHaving only one PropertyReadFile with a single PiecewiseConstrantFromCSV sound for sure much more efficient. Unfortunately, it is not yet clear to me how to map the sequence of CSV files to specific model times.\nMy [Executioner] block looks like:\n# Executioner defintion\n[Executioner]\n  type = Transient\n \n  #set solver\n  solve_type = 'PJFNK'\n \n  # options for petsc\n  petsc_options = '-snes_converged_reason'\n  petsc_options_iname = '-pc_type -pc_factor_mat_solver_package'\n  petsc_options_value = ' lu       mumps'\n \n  ...\n \n  # timing options\n  start_time = 0.0\n  end_time   = 1.25\n  dt         = 0.25\n  dtmin      = 0.0001\n[]\n\nIn the [Executioner]-block above I give a dt - but in most of my models the 'real' timesteps are smaller and more numerous (as allowed by dtmin). Therefore my question regarding the mapping of the CSV-files to the timesteps.\nKind regards, J\u00f6rg",
                          "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8140812",
                          "updatedAt": "2024-01-16T07:52:00Z",
                          "publishedAt": "2024-01-16T07:51:59Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Do you know the exact times you need to change CSV files?\nIf so, write a ParsedFunction that is equal to 1 at these times and 0 elsewhere.\nThen use the\nconditionalFunctionEnableControl\nTo enable the reader at those times.\nMy other idea is to write a new Control object that activates only at specified times. I m busy with a training right now but I can make that next week maybe.",
                          "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8143629",
                          "updatedAt": "2024-01-16T12:29:31Z",
                          "publishedAt": "2024-01-16T12:29:31Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jmeier"
                          },
                          "bodyText": "Dear @GiudGiud,\nAfter the distraction of #26664 I removed all ${units ... } from my test project for now and tried to follow your recommendations. Please find the current state of my test project this repository.\nThe model consists of 7 blocks. 6 of them are to be activated/deactivated at pre-known times. The times are stored in stages.csv. The corresponding activation states in stages.block_activation_t0000.csv to stages.block_activation_t0003.csv.\nI can run the model and Moose is calculating something. But...\n\nMoose creates not one .e-file, but a set of .e-s### files.\nIn Paraview, only one block is available/visible (the big one).\nMy aux variable BlockActivation_StateAuxVariable is always shown to be zero by Paraview (despite the fact it is set to 1 at distinct times in BlockActivation_AdvanceStatesFileReaderFunction\n\nObviously, I'm doing something wrong. Could you please have a look?\nKind regards,\nJ\u00f6rg",
                          "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8423173",
                          "updatedAt": "2024-02-09T20:41:20Z",
                          "publishedAt": "2024-02-09T20:41:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Moose creates not one .e-file, but a set of .e-s### files.\n\nthis is because the mesh is changing. Are you using adaptivity for example?\nIt s a limitation of the exodus format.\n\nIn Paraview, only one block is available/visible (the big one).\n\nIn the left panel you only see on block? And in the moose simulation there are more? (for example in the header of the simulation it reports the number of blocks)\n\nMy aux variable BlockActivation_StateAuxVariable is always shown to be zero by Paraview (despite the fact it is set to 1 at distinct times in BlockActivation_AdvanceStatesFileReaderFunction\n\nDo you see the auxiliary kernel running using Debug/show_execution_order = ALWAYS ?",
                          "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8424025",
                          "updatedAt": "2024-02-09T22:57:37Z",
                          "publishedAt": "2024-02-09T22:57:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jmeier"
                          },
                          "bodyText": "Dear @GiudGiud,\n\nthis is because the mesh is changing. Are you using adaptivity for example?\n\nI do not use adaptivity (at least not deliberately). But I use a CoupledVarThresholdElementSubdomainModifier to move blocks between subdomains:\n[UserObjects]\n  [BlockActivation]\n    type = CoupledVarThresholdElementSubdomainModifier\n    coupled_var = 'BlockActivation_StateAuxVariable'\n    criterion_type = BELOW\n    threshold = 0\n    subdomain_id = 1\n    complement_subdomain_id = 2\n    execute_on = 'INITIAL TIMESTEP_BEGIN'\n  []\n[]\n\n\nIn the left panel you only see on block? And in the moose simulation there are more? (for example in the header of the simulation it reports the number of blocks)\n\nYes, only one \"block\" in Paraview. Moose reports \"Num of subdomains: 7\" (Mesh/File/show_info=true also reports 7 \"subdomains\").\nBy the way: Is there a mixup between the terms \"subdomain\" and \"block\"? This makes me a bit nervous due to the fact the CoupledVarThresholdElementSubdomainModifier is moving between subdomain_id and complement_subdomain_id . Is this my mistake?\nMesh:\n  Parallel Type:           replicated\n  Mesh Dimension:          3\n  Spatial Dimension:       3\n  Nodes:                   5207\n  Elems:                   3325\n  Num Subdomains:          7\n\nIf I run the model without any of the stuff connected with the CoupledVarThresholdElementSubdomainModifier, I see the 7 blocks in Paraview just fine.\n\nDo you see the auxiliary kernel running using Debug/show_execution_order = ALWAYS ?\n\nIn the Debug I see before the first step that Moose is handling 7 blocks. This is the message for the last block:\n[DBG] Only user objects active on local element/sides are executed\n[DBG] Ordering of User Objects on block 7\n[DBG] Executing ElementUserObject on INITIAL\n[DBG] Order of execution:\n[DBG] BlockActivation\n\nFor all other timesteps Moose is only talking about \"block 2\". This is the message for time step 3:\nTime Step 3, time = 0.6, dt = 0.2\n[DBG] Computing elemental user objects on TIMESTEP_BEGIN\n[DBG] Ordering of User Objects on block 2\n[DBG] Executing ElementUserObject on TIMESTEP_BEGIN\n[DBG] Order of execution:\n[DBG] BlockActivation\n\n[DBG] Only user objects active on local element/sides are executed\n[DBG] Executing auxiliary kernels on elements on LINEAR\n[DBG] Ordering of AuxKernels on block 2\n[DBG] BlockActivation_StateAux\n      Still Computing Residual..[DBG] Beginning elemental loop to compute Residual on LINEAR\n[DBG] Ordering of Residual Objects on block Box2 (2)\n[DBG] Ordering of kernels:\n[DBG] TM_all0 TM_all1 TM_all2 Gravity\n[DBG] Ordering of Residual Objects on boundary BoundaryZMax (18)\n[DBG] Ordering of integrated boundary conditions:\n[DBG] BoundaryZMax_Pressure\n\n      Finished Computing Residual                                                        [ 22.65 s] [  204 MB]\n    Finished Computing Initial Residual                                                  [ 22.65 s] [  204 MB]\n[DBG] Executing auxiliary kernels on elements on LINEAR\n[DBG] Ordering of AuxKernels on block 2\n[DBG] BlockActivation_StateAux\n    Still Computing Residual..[DBG] Beginning elemental loop to compute Residual on LINEAR\n[DBG] Ordering of Residual Objects on block Box2 (2)\n[DBG] Ordering of kernels:\n[DBG] TM_all0 TM_all1 TM_all2 Gravity\n[DBG] Ordering of Residual Objects on boundary BoundaryZMax (18)\n[DBG] Ordering of integrated boundary conditions:\n[DBG] BoundaryZMax_Pressure\n\n    Finished Computing Residual                                                          [ 23.51 s] [  204 MB]\n 0 Nonlinear |R| = 5.134485e-06\n Solve Converged!\n  Finished Solving                                                                       [ 46.17 s] [  204 MB]\n[DBG] Initializing, executing & finalizing general UO 'BlockActivation_StatesCSV' on TIMESTEP_END\n[DBG] Executing auxiliary kernels on elements on TIMESTEP_END\n[DBG] Ordering of AuxKernels on block 2\n[DBG] stress_xx_all stress_xy_all stress_xz_all stress_yy_all stress_yz_all stress_zz_all BlockActivation_StateAux\n\nStill Executing..\nOutlier Variable Residual Norms:\n  disp_z: 4.984422e-06",
                          "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8426214",
                          "updatedAt": "2024-02-10T09:19:35Z",
                          "publishedAt": "2024-02-10T09:19:34Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "Traiwit"
                  },
                  "bodyText": "Hi, by 'excavation' do you want to actually remove the blocks from the mesh, or you are okay with changing the blocks property to be really weak (lower the youngs_modulus or something like that)\nif so, you can have the state map/flag material for each element (via PropertyReadFile), and modify the material property of each element (for example youngs_modulus) based on the state\nPropertyReadFile can read .csv file and give the value for each element (1 to n_th element == 1 to n_th row of the file)\nI did this with PorousFlow permeability, but I think it's the same in Tensormechanics\n  // calculate perm tensor\n  if (_flag[_qp] == 1){\n    // state==1: this is for excavated domains, set permeability to 1e-18 = very low\n\n      _perm[_qp](0) =  _perm_excav; \n      _perm[_qp](1) =  _perm_excav; \n      _perm[_qp](2) =  _perm_excav; \n\n  }\n  else if (_flag[_qp] == 2) {\n    // state==2: this is for caved domains, set permeability to 1e-14 (kw=1e-5)\n    _perm[_qp](0) =  _perm_cave; \n    _perm[_qp](1) =  _perm_cave; \n    _perm[_qp](2) =  _perm_cave; \n\n  }\n  else if (_flag[_qp] == 3 ) {\n  \n    _perm[_qp](0) =  _perm_backfill; \n    _perm[_qp](1) =  _perm_backfill; \n    _perm[_qp](2) =  _perm_backfill; \n  }\n  else {\n    // any other state (including state==0): this is for intact domains, set permeability to exponential function of damage\n\nmy C++ is very bad but ChatGPT helps a lot. Personally I find modifying mesh during the simulation is very difficult.\nHope this helps, I also do mining applications like excavation/backfill/cave but for hydro - with Abaqus mesh, I hope to develop a system for Tensormechanics soon (still waiting for Cohesive elements so I can properly deal with faults).",
                  "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8436565",
                  "updatedAt": "2024-02-12T00:48:37Z",
                  "publishedAt": "2024-02-12T00:48:36Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "jmeier"
                          },
                          "bodyText": "Dear @Traiwit,\nThank you for your message.\nIn the coal mining model actually the \"softening\" you are proposing is done. But thanks to the elasticity_tensor_prefactor, no C++ code is needed in tensor mechanics (in combination of reducing the weight of the blocks affected).\nIn view of experiences with other FE codes / FE models, I am very interested in really removing the blocks (and possibly reinserting them later). Depending on the model, the approach with the elasticity_tensor_prefactor is also quite tricky: For most tasks, the elasticity_tensor_prefactor alone is not sufficient. The material also often has to become purely linear-elastic. And lighter (see also the coal mining model). And more permeable. And... And yet the edges of these blocks would not be stress-free. Compressive stresses - if not too large - are often not a problem. Tensile stresses, on the other hand, are a major problem if the \"normal\" blocks next to them have no or very low tensile strength (like many soft soils like sand or clay). In addition, other FE codes quickly encountered problems with convergence if the stiffness differences and deformations of the \"soft ghost blocks\" were too great.\nTherefore, the idea was to first soften the blocks to be excavated (using elasticity_tensor_prefactor and density and ...) and then to really remove them from the model.\nKind regards,\nJ\u00f6rg",
                          "url": "https://github.com/idaholab/moose/discussions/26505#discussioncomment-8437685",
                          "updatedAt": "2024-02-12T06:16:44Z",
                          "publishedAt": "2024-02-12T06:16:43Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "postprocessor at arbitrary point values",
          "author": {
            "login": "mcacace"
          },
          "bodyText": "Dear all,\nI have a multiapp where the master is a classical Moose FEM problem and the sub app is a set of scalar ODEs that are computed based on some transferred values from the master (from postprocessor values computed at given points). All works fine, though as it is coded now, the points must match the locations of the master mesh, while I would like to enable the computing of the postprocessor to be more flexible, let's say to compute those values at arbitrary points, that is, points that do not match a node in the mesh, though are inside the boundaries of the master domain.\nThis said, I am wondering what would be the easiest and cleanest was to custom a pointvalue postprocessor that provides the value of an auxvariable (CONSTANT MONOMIAL) at an arbitrary point, possibly by interpolation from closest neighbors or from the value of the element that contains the point.\nLooking at the discussion, I realize that my post might be similar to (#26747), though I am struggling to educate myself with functors. Could anyone provide any hint/suggestion/example which I could benefit from? That would be great.\nThanks,\nmauro",
          "url": "https://github.com/idaholab/moose/discussions/26931",
          "updatedAt": "2024-03-01T10:24:57Z",
          "publishedAt": "2024-02-29T10:51:20Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nIf there are may points, and you are looking to distribute in an arbitrary way, possibly programmatically, possibly from a file, I would suggest you use the Positions system.\nThis will let you keep track of the list of points and\n\ncreate multiapps at those locations\nsample the values of any field (all fields are functors) with this object\nhttps://mooseframework.inl.gov/source/vectorpostprocessors/PositionsFunctorValueSampler.html\n\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/26931#discussioncomment-8633411",
                  "updatedAt": "2024-02-29T19:36:19Z",
                  "publishedAt": "2024-02-29T16:42:14Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "mcacace"
                          },
                          "bodyText": "Will have a look at it. Thanks",
                          "url": "https://github.com/idaholab/moose/discussions/26931#discussioncomment-8634579",
                          "updatedAt": "2024-02-29T18:44:03Z",
                          "publishedAt": "2024-02-29T18:44:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "mcacace"
                          },
                          "bodyText": "It does seem to work quite nicely. Thanks @GiudGiud",
                          "url": "https://github.com/idaholab/moose/discussions/26931#discussioncomment-8641364",
                          "updatedAt": "2024-03-01T10:24:58Z",
                          "publishedAt": "2024-03-01T10:24:57Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Encounter error message",
          "author": {
            "login": "chunhuizhao478"
          },
          "bodyText": "Hi all, I'm doing a dynamic explicit solve (with material damage), and I encounter the following error, I wonder what does it mean?\nTime Step 225, time = 1.3275e-05, dt = 5.9e-08\nsub_app0: \nsub_app0: Time Step 225, time = 1.3275e-05, dt = 5.9e-08\nsub_app0:  Solve Converged!\n  Elem Information\n   id()=19736, unique_id()=39144, subdomain_id()=3, processor_id()=6\n   type()=TRI3\n   dim()=2\n   n_nodes()=3\n   mapping=LAGRANGE_MAP\n    0  Node id()=9019, processor_id()=6, Point=(x,y,z)=( -609491, -1.17629e+06,        0)\n    DoFs=(0/0/30546) (0/1/30547) (1/0/2060807) (1/1/2060808) (1/2/2060809) (1/3/2060810) (1/4/2060811) (1/5/2060812) (1/6/2060813) (1/7/2060814) (1/10/2081423) (1/13/2094118) (1/14/2094119) (1/28/2176726) (1/32/2193007) \n    1  Node id()=6808, processor_id()=6, Point=(x,y,z)=(0.000442485, 0.0127508,        0)\n    DoFs=(0/0/29990) (0/1/29991) (1/0/2058583) (1/1/2058584) (1/2/2058585) (1/3/2058586) (1/4/2058587) (1/5/2058588) (1/6/2058589) (1/7/2058590) (1/10/2081145) (1/13/2093562) (1/14/2093563) (1/28/2176448) (1/32/2192729) \n    2  Node id()=14429, processor_id()=6, Point=(x,y,z)=(-0.000402603, 0.0129598,        0)\n    DoFs=(0/0/32026) (0/1/32027) (1/0/2066727) (1/1/2066728) (1/2/2066729) (1/3/2066730) (1/4/2066731) (1/5/2066732) (1/6/2066733) (1/7/2066734) (1/10/2082163) (1/13/2095598) (1/14/2095599) (1/28/2177466) (1/32/2193747) \n   n_sides()=3\n    neighbor(0)=19704\n    neighbor(1)=25192\n    neighbor(2)=19734\n   hmin()=0.000870569, hmax()=1.32482e+06\n   volume()=560.753\n   active()=1, ancestor()=0, subactive()=0, has_children()=0\n   parent()=nullptr\n   level()=0, p_level()=0\n   refinement_flag()=DO_NOTHING\n   p_refinement_flag()=DO_NOTHING\n   DoFs=(1/8/2075961) (1/9/2075962) (1/11/2087596) (1/12/2087597) (1/15/2113799) (1/16/2113800) (1/17/2113801) (1/18/2113802) (1/19/2113803) (1/20/2113804) (1/21/2113805) (1/22/2143876) (1/22/2143877) (1/22/2143878) (1/23/2143879) (1/23/2143880) (1/23/2143881) (1/24/2166862) (1/25/2166863) (1/26/2166864) (1/27/2166865) (1/29/2185344) (1/30/2185345) (1/31/2185346) (1/33/2299425) (1/34/2299426) (1/35/2299427) (1/36/2299428) (1/37/2299429) (1/38/2299430) (1/39/2299431) (1/40/2299432) (1/41/2299433) (1/42/2299434) (1/43/2299435) (1/44/2299436) (1/45/2299437) (1/46/2299438) (1/47/2299439) (1/48/2299440) (1/49/2299441) (1/50/2299442) (1/51/2299443) (1/52/2299444) (1/53/2299445) (1/54/2299446) (1/55/2299447) (1/56/2299448) (1/57/2299449) (1/58/2299450) (1/59/2299451) (1/60/2299452) (1/61/2299453) (1/62/2299454) (1/63/2299455) (1/64/2299456) (1/65/2299457) (1/66/2299458) (1/67/2299459) (1/68/2299460) (1/69/2299461) (1/70/2299462) (1/71/2299463) (1/72/2299464) (1/73/2299465) (1/74/2299466) (1/75/2299467) \nWe caught a libMesh error in ThreadedElementLoopBase:ERROR: negative Jacobian 0 at point (x,y,z)=( -406159,  -783870,        0) in element 19736\n[6] ../src/fe/fe_map.C, line 908, compiled Jan 30 2024 at 13:33:06\n\n[0]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------\n[0]PETSC ERROR: Object is in wrong state\n[0]PETSC ERROR: Not for unassembled vector, did you call VecAssemblyBegin()/VecAssemblyEnd()?\n[0]PETSC ERROR: WARNING! There are unused option(s) set! Could be the program crashed before usage or a spelling mistake, etc!\n[0]PETSC ERROR:   Option left: name:-i value: examples/cdbm_borehole_thermal_effect/temp200degree/test_borehole_main.i source: command line\n[0]PETSC ERROR:   Option left: name:-ksp_converged_reason value: ::failed source: code\n[0]PETSC ERROR:   Option left: name:-options_left value: 0 source: code\n[0]PETSC ERROR:   Option left: name:-snes_converged_reason value: ::failed source: code\n[0]PETSC ERROR:   Option left: name:-snes_monitor_cancel (no value) source: code\n[0]PETSC ERROR:   Option left: name:-snes_type value: ksponly source: code\n[0]PETSC ERROR: See https://petsc.org/release/faq/ for trouble shooting.\n[0]PETSC ERROR: Petsc Release Version 3.20.3, unknown \n[0]PETSC ERROR: ./farms-opt on a  named Chunhuis-MBP-2.connectivityu.com by andyz Tue Feb 27 21:21:36 2024\n[0]PETSC ERROR: Configure options --with-64-bit-indices --with-cxx-dialect=C++17 --with-debugging=no --with-fortran-bindings=0 --with-mpi=1 --with-openmp=1 --with-shared-libraries=1 --with-sowing=0 --download-fblaslapack=1 --download-hypre=1 --download-metis=1 --download-mumps=1 --download-ptscotch=1 --download-parmetis=1 --download-scalapack=1 --download-slepc=1 --download-strumpack=1 --download-superlu_dist=1 --with-hdf5-dir=${PREFIX} --with-make-np=8 --COPTFLAGS=-O3 --CXXOPTFLAGS=-O3 --FOPTFLAGS=-O3 --with-x=0 --with-ssl=0 --with-mpi-dir=/Users/andyz/miniforge/envs/moose AR=arm64-apple-darwin20.0.0-ar RANLIB=arm64-apple-darwin20.0.0-ranlib CFLAGS=\"-ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O2 -pipe -isystem /Users/andyz/miniforge/envs/moose/include   -mcpu=apple-a12\" CXXFLAGS=\"-ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O2 -pipe -stdlib=libc++ -fvisibility-inlines-hidden -fmessage-length=0 -isystem ${PREFIX}/include  -mcpu=apple-a12\" CPPFLAGS=\"-D_FORTIFY_SOURCE=2 -isystem /Users/andyz/miniforge/envs/moose/include -mmacosx-version-min=11.3\" FFLAGS=\"-march=armv8.3-a -ftree-vectorize -fPIC -fno-stack-protector -O2 -pipe -isystem /Users/andyz/miniforge/envs/moose/include   -march=armv8.3-a\" FCFLAGS=\"-march=armv8.3-a -ftree-vectorize -fPIC -fno-stack-protector -O2 -pipe -isystem /Users/andyz/miniforge/envs/moose/include   -march=armv8.3-a\" LDFLAGS=\"-Wl,-pie -Wl,-headerpad_max_install_names -Wl,-dead_strip_dylibs -Wl,-rpath,/Users/andyz/miniforge/envs/moose/lib -L/Users/andyz/miniforge/envs/moose/lib\" --prefix=/Users/andyz/miniforge/envs/moose\n[0]PETSC ERROR: #1 VecScaleAsync_Private() at /opt/civet0/build/conda/conda-bld/moose-petsc_1706648823690/work/src/vec/vec/interface/rvector.c:439\n[0]PETSC ERROR: #2 VecScale() at /opt/civet0/build/conda/conda-bld/moose-petsc_1706648823690/work/src/vec/vec/interface/rvector.c:478",
          "url": "https://github.com/idaholab/moose/discussions/26917",
          "updatedAt": "2024-02-29T21:24:38Z",
          "publishedAt": "2024-02-28T05:28:54Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nWe caught a libMesh error in ThreadedElementLoopBase:ERROR: negative Jacobian 0 at point (x,y,z)=( -406159,  -783870,        0) in element 19736\n\none of your elements got flipped (or distorted too much to be valid).\nWhat you can do are:\n\nuse smaller time steps\nset preset = false to your dirichletBCs. Preset dirichletBCs force the displacement on some nodes which can be too much and distort the elements. If you solve for the displacement instead, you should follow a convergence path with normally shaped elements\ncoarsen your mesh in that area\n\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/26917#discussioncomment-8613691",
                  "updatedAt": "2024-02-28T05:33:27Z",
                  "publishedAt": "2024-02-28T05:33:27Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "chunhuizhao478"
                          },
                          "bodyText": "It appears the \"use_constant_mass = True\" for \"CentralDifference\" causes the issue, now the problem is resolved.",
                          "url": "https://github.com/idaholab/moose/discussions/26917#discussioncomment-8635900",
                          "updatedAt": "2024-02-29T21:24:26Z",
                          "publishedAt": "2024-02-29T21:24:25Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "yaml file after building app",
          "author": {
            "login": "jessecarterMOOSE"
          },
          "bodyText": "Recently updated my local copy of the framework and now my app produces an .yaml \"resource file\" when compiling. What's that used for? I'm inclined to toss it in my .gitignore.",
          "url": "https://github.com/idaholab/moose/discussions/24990",
          "updatedAt": "2024-02-29T20:25:08Z",
          "publishedAt": "2023-07-19T12:24:21Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "milljm"
                  },
                  "bodyText": "It's a dynamically generated file containing information about the build. It has potential for other things we might want to track down the road. But for now, the TestHarness uses it to understand if your build is an in-tree build, or out-of-tree build (like an install or not).\nIt's safe to add this file to your .gitignore.\nEdit:\nTest Spec file making use of this feature:\n[Tests]\n  [./in_tree_type]\n    type = RunCommand\n    command = \"true\"\n    # Test will only run if application was built in-tree\n    installation_type = IN_TREE\n  [../]\n  [./installed_type]\n    type = RunCommand\n    command = \"true\"\n    # Test will only run if application is installed\n    installation_type = INSTALLED\n  [../]\n  [./all_type]\n    type = RunCommand\n    command = \"true\"\n    # Test will always run (default)\n    installation_type = ALL\n  [../]\n[]",
                  "url": "https://github.com/idaholab/moose/discussions/24990#discussioncomment-6488341",
                  "updatedAt": "2023-07-19T12:34:21Z",
                  "publishedAt": "2023-07-19T12:30:42Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aarograh"
                          },
                          "bodyText": "Hello,\nPiggybacking off this question, I have a couple of other apps that are coupled to my app.  I've set up the tests files like so:\n[Tests]\n  [griffin_standalone]\n    type = Exodiff\n    input = griffin_standalone.i\n    exodiff = griffin_standalone_out.e\n    group = 'griffin_coupled'\n    required_applications = GriffinApp\n  []\n[]\n\nfor each of the tests.\nHowever, when I run the tests, I get this:\ntest:coupled/griffin/full_coupling.griffin_standalone ..... [App GriffinApp not registered in executable] SKIP\n\nI see this in my app's .yml file:\nregistered_apps:\n- WASPAPP\n- MOLEAPP\n- MOLETESTAPP\n\nI've confirmed that the tests file is reading the .yaml file to find GRIFFINAPP and SAMAPP and then skipping those tests when it does not see them (I manually added them to the .yaml file to confirm this).  Obviously there is some sort of registration step I'm missing, but I don't know what it is.  Could you help me understand how to ensure that griffin and SAM apps are registered as well?",
                          "url": "https://github.com/idaholab/moose/discussions/24990#discussioncomment-8634664",
                          "updatedAt": "2024-02-29T18:52:10Z",
                          "publishedAt": "2024-02-29T18:52:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "you can register apps in the XXXApp.C file\nvoid\nMyApp::registerApps()\n{\n  registerApp(MyApp);\n#ifdef GRIFFIN_ENABLED\n  GriffinApp::registerApps();\n#endif",
                          "url": "https://github.com/idaholab/moose/discussions/24990#discussioncomment-8635033",
                          "updatedAt": "2024-02-29T19:35:52Z",
                          "publishedAt": "2024-02-29T19:35:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aarograh"
                          },
                          "bodyText": "Thank you for the response.  I actually already had that in there.  After grepping around the guts of MOOSE I figured out that the issue was that ADDITIONAL_CPPFLAGS += -DGRIFFIN_ENABLED in the Makefile should have been libmesh_CXXFLAGS += -DGRIFFIN_ENABLED.  Once I made that change it worked correctly",
                          "url": "https://github.com/idaholab/moose/discussions/24990#discussioncomment-8635410",
                          "updatedAt": "2024-02-29T20:23:54Z",
                          "publishedAt": "2024-02-29T20:23:54Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "ADDITIONAL_CPPFLAGS += -DGRIFFIN_ENABLED in the Makefile should have been libmesh_CXXFLAGS += -DGRIFFIN_ENABLED\n\nthat does not seem right but if it works let s go",
                          "url": "https://github.com/idaholab/moose/discussions/24990#discussioncomment-8635420",
                          "updatedAt": "2024-02-29T20:25:09Z",
                          "publishedAt": "2024-02-29T20:25:08Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "How to access residual vector when doing computeJacobian()",
          "author": {
            "login": "doquang"
          },
          "bodyText": "Hi,\nI am trying to extract the computed residual vector from the scope of class BC::computeJacobian(), but I am getting an error message when using this command _sys.getVector(_sys.residualVectorTag());\nCan someone help?\nThanks in advance,\nM.\nlibMesh terminating:\nCannot retreive vector with tag 1 in system 'nl0'\nbecause a vector has not been associated with that tag.",
          "url": "https://github.com/idaholab/moose/discussions/26896",
          "updatedAt": "2024-03-07T10:28:52Z",
          "publishedAt": "2024-02-26T21:15:18Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@YaqiWang and @NamjaeChoi just looked at tags, do you know?",
                  "url": "https://github.com/idaholab/moose/discussions/26896#discussioncomment-8598829",
                  "updatedAt": "2024-02-26T23:56:46Z",
                  "publishedAt": "2024-02-26T23:56:45Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "NamjaeChoi"
                          },
                          "bodyText": "It seems that the tag gets associated with the residual vector at FEProblemBase::computeResidual and FEProblemBase::computeResidualAndJacobian. But not sure if your call to BC::computeJacobian went through these functions.",
                          "url": "https://github.com/idaholab/moose/discussions/26896#discussioncomment-8599551",
                          "updatedAt": "2024-02-27T01:56:14Z",
                          "publishedAt": "2024-02-27T01:56:13Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "Right, the residualVectorTag() is not persistently associated with the residual vector because we could in theory be processing a different residual vector for different invocations of computeResidualXXX",
                          "url": "https://github.com/idaholab/moose/discussions/26896#discussioncomment-8601099",
                          "updatedAt": "2024-02-27T06:25:04Z",
                          "publishedAt": "2024-02-27T06:25:03Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "@NamjaeChoi referred to code like this:\nvoid\nFEProblemBase::computeResidual(const NumericVector<Number> & soln,\n                               NumericVector<Number> & residual,\n                               const unsigned int nl_sys_num)\n{\n  setCurrentNonlinearSystem(nl_sys_num);\n\n  // We associate the residual tag with the given residual vector to make sure we\n  // don't filter it out below\n  _current_nl_sys->associateVectorToTag(residual, _current_nl_sys->residualVectorTag());\nwhich indeed is not called during Jacobian evaluation",
                          "url": "https://github.com/idaholab/moose/discussions/26896#discussioncomment-8601111",
                          "updatedAt": "2024-02-27T06:26:20Z",
                          "publishedAt": "2024-02-27T06:26:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "doquang"
                          },
                          "bodyText": "Can I get / set the residual values from NonlinearSystemBase::RHS() ?",
                          "url": "https://github.com/idaholab/moose/discussions/26896#discussioncomment-8615465",
                          "updatedAt": "2024-02-28T09:00:07Z",
                          "publishedAt": "2024-02-28T08:59:51Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "why do you need this? Setting the residual values during Jacobian evaluation is something like undefined behavior.\nRHS() will give you the residual vector, yes",
                          "url": "https://github.com/idaholab/moose/discussions/26896#discussioncomment-8623013",
                          "updatedAt": "2024-02-28T20:42:38Z",
                          "publishedAt": "2024-02-28T20:42:37Z",
                          "isAnswer": true
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "doquang"
                          },
                          "bodyText": "I am trying to impose a strong free-slip BC, and I would like to estimate the larger shear stress on the two tangent directions. That why I need to modify both Jacobian & residual.",
                          "url": "https://github.com/idaholab/moose/discussions/26896#discussioncomment-8629974",
                          "updatedAt": "2024-02-29T12:06:03Z",
                          "publishedAt": "2024-02-29T12:06:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "if you modify the residual during the residual loop and the Jacobian during the Jacobian loop you should not have to use the tags.",
                          "url": "https://github.com/idaholab/moose/discussions/26896#discussioncomment-8633082",
                          "updatedAt": "2024-02-29T16:16:30Z",
                          "publishedAt": "2024-02-29T16:16:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "doquang"
                          },
                          "bodyText": "Thanks @GiudGiud. It is what I am doing for now. It is too difficult, and it may not correct for changing both jacobian and residual in the same time, when using SNES solver.",
                          "url": "https://github.com/idaholab/moose/discussions/26896#discussioncomment-8633618",
                          "updatedAt": "2024-02-29T17:10:01Z",
                          "publishedAt": "2024-02-29T16:59:43Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "ok feel free to use RHS in the residual loop\nthe tag should also work in the residual loop",
                          "url": "https://github.com/idaholab/moose/discussions/26896#discussioncomment-8633919",
                          "updatedAt": "2024-02-29T17:25:21Z",
                          "publishedAt": "2024-02-29T17:25:20Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Seeking Assistance with Custom UserObject Execution between InversePowerMethod Iterations",
          "author": {
            "login": "hityyds"
          },
          "bodyText": "Hello everyone,\nI am currently working with the InversePowerMethod executioner in MOOSE and have encountered an issue regarding the execution timing of a custom userobject. I want it to be executed between power iterations. When using the InversePowerMethod, the iteration process looks like this:\nPower iteration= 0\n 0 Nonlinear |R| = 1.478162e-02\n      0 Linear |R| = 1.478162e-02\n      1 Linear |R| = 1.755819e-07\n 1 Nonlinear |R| = 1.755819e-07\n\n +================+=====================+=====================+\n | iteration      | eigenvalue          | solution_difference |\n +================+=====================+=====================+\n |              0 |      4.29166712e-01 |      1.86513876e-03 |\n +================+=====================+=====================+\n Chebyshev step: 0\n ________________________________________________________________________________ \n Power iteration= 1\n 0 Nonlinear |R| = 1.776508e-02\n      0 Linear |R| = 1.776508e-02\n      1 Linear |R| = 9.905756e-08\n 1 Nonlinear |R| = 9.905756e-08\n\nSpecifically, I am wanting my userobject to be executed before the '0 Nonlinear |R|' of each power iteration.\nI've tried setting execute_on to NONLINEAR, but it only causes my userobject to be executed before the Linear iteration. The SetupInterface page describes common Execute Flags, but none of them are what I need. I know there are other Execute Flags such as FORWARD, ADJOINT, HOMOGENEOUS_FORWARD, ADJOINT_TIMESTEP_BEGIN, ADJOINT_TIMESTEP_END, etc. How do I find out what these Execute Flags do?\nAdditionally, considering that none of the standard flags fulfill my need, I suspect I might need to define a custom Execute Flag. However, the information on creating custom Execute Flags in the SetupInterface is quite brief. Can anyone recommend a more detailed tutorial or resource on how to create and utilize a custom Execute Flag in this context?\nYour help and insights would be greatly appreciated!",
          "url": "https://github.com/idaholab/moose/discussions/26933",
          "updatedAt": "2024-02-29T16:34:55Z",
          "publishedAt": "2024-02-29T14:57:10Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\n\nHowever, the information on creating custom Execute Flags in the SetupInterface is quite brief.\n\nbut that s nice because this is litterally all you need to do to get it work. We cant get more detailed, you do those 3 steps and you can use it in your input already\nLooking through the repo, LevelSet and XFEM modules have examples of doing this (use grep to find them)\nalso Cardinal does it too\nhttps://github.com/neams-th-coe/cardinal\nsrc/base/CardinalAppTypes.C:const ExecFlagType EXEC_SEND_OPENMC_DENSITIES = registerExecFlag(\"SEND_OPENMC_DENSITIES\");\n\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/26933#discussioncomment-8633317",
                  "updatedAt": "2024-02-29T16:34:56Z",
                  "publishedAt": "2024-02-29T16:34:54Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "ADScalarTimeKernel problem",
          "author": {
            "login": "SomnusYu"
          },
          "bodyText": "Hi all,\nI would like to use _pressure_dot(adCoupledScalarDot(\"pressure\")),  based on ADScalarTimeKernel. But this type (adCoupledScalarDot ) is not declared in this scope. What should I do? Could anyone kindly help me?\nThanks!",
          "url": "https://github.com/idaholab/moose/discussions/26891",
          "updatedAt": "2024-02-29T04:38:06Z",
          "publishedAt": "2024-02-26T15:27:09Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nThis has not been implemented yet. It would need to be a new definition in ScalarCoupleable.\n@lindsayad do you want to do it or should I take a stab?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/26891#discussioncomment-8595962",
                  "updatedAt": "2024-02-26T17:57:36Z",
                  "publishedAt": "2024-02-26T17:57:35Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "I appreciate the invitation to briefly foray into coding again \ud83d\ude06 I've opened #26898",
                          "url": "https://github.com/idaholab/moose/discussions/26891#discussioncomment-8601820",
                          "updatedAt": "2024-02-27T07:51:37Z",
                          "publishedAt": "2024-02-27T07:51:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "SomnusYu"
                          },
                          "bodyText": "Thanks!",
                          "url": "https://github.com/idaholab/moose/discussions/26891#discussioncomment-8612660",
                          "updatedAt": "2024-02-28T02:29:43Z",
                          "publishedAt": "2024-02-28T02:29:42Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "lindsayad"
                          },
                          "bodyText": "that PR is now merged",
                          "url": "https://github.com/idaholab/moose/discussions/26891#discussioncomment-8622392",
                          "updatedAt": "2024-02-28T19:21:16Z",
                          "publishedAt": "2024-02-28T19:21:16Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "SomnusYu"
                          },
                          "bodyText": "Thanks, so what should I do? update MOOSE, and then I can use it?",
                          "url": "https://github.com/idaholab/moose/discussions/26891#discussioncomment-8624680",
                          "updatedAt": "2024-02-29T01:04:48Z",
                          "publishedAt": "2024-02-29T01:04:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "exactly. use the next branch",
                          "url": "https://github.com/idaholab/moose/discussions/26891#discussioncomment-8624693",
                          "updatedAt": "2024-02-29T01:06:33Z",
                          "publishedAt": "2024-02-29T01:06:33Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "git fetch origin\ngit checkout origin/next",
                          "url": "https://github.com/idaholab/moose/discussions/26891#discussioncomment-8624694",
                          "updatedAt": "2024-02-29T01:06:51Z",
                          "publishedAt": "2024-02-29T01:06:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "SomnusYu"
                          },
                          "bodyText": "Thanks!",
                          "url": "https://github.com/idaholab/moose/discussions/26891#discussioncomment-8624703",
                          "updatedAt": "2024-02-29T01:08:11Z",
                          "publishedAt": "2024-02-29T01:08:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "SomnusYu"
                          },
                          "bodyText": "Hi @GiudGiud,\nI used this to update MOOSE, but some errors occurred.\n\ngit fetch origin\ngit checkout origin/next\n\neg:\n\nDoes this branch finish?",
                          "url": "https://github.com/idaholab/moose/discussions/26891#discussioncomment-8624798",
                          "updatedAt": "2024-02-29T01:26:56Z",
                          "publishedAt": "2024-02-29T01:26:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Hello\nSo the problem is that you updated moose but did not update libmesh and wasp\nRun conda update --all",
                          "url": "https://github.com/idaholab/moose/discussions/26891#discussioncomment-8624816",
                          "updatedAt": "2024-02-29T01:30:21Z",
                          "publishedAt": "2024-02-29T01:30:19Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "SomnusYu"
                          },
                          "bodyText": "Ok, let me have a try.",
                          "url": "https://github.com/idaholab/moose/discussions/26891#discussioncomment-8624832",
                          "updatedAt": "2024-02-29T01:32:38Z",
                          "publishedAt": "2024-02-29T01:32:37Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Some confusion about ADVolumeJunction1PhaseUserObject in THM",
          "author": {
            "login": "SomnusYu"
          },
          "bodyText": "Hi @GiudGiud and @jasondhales,\nI noticed that we just calculate the S_loss at c==0 in ADVolumeJunction1PhaseUserObject, which is the first inlet section in this junction. Why do not we calculate the S_loss of other inlet sections (if this junction contains more than one inlet section)? I'm really confused about it. Could you please tell me?\nThanks!",
          "url": "https://github.com/idaholab/moose/discussions/26889",
          "updatedAt": "2024-02-29T01:02:36Z",
          "publishedAt": "2024-02-26T13:29:32Z",
          "category": {
            "name": "Q&A Modules: Thermal Hydraulics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@joshuahansel",
                  "url": "https://github.com/idaholab/moose/discussions/26889#discussioncomment-8592703",
                  "updatedAt": "2024-02-26T13:42:53Z",
                  "publishedAt": "2024-02-26T13:42:52Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "joshuahansel"
                  },
                  "bodyText": "The term is not meant to be a per-connection term. It looks like we've just chosen the first connection arbitrarily for the reference values. I agree that something needs to be done - we shouldn't have the property the that the solution depends on the ordering of the connections. @licharlot What do you think is the right solution? I guess we want some consistency with legacy systems codes? Do any of those have per-connection form loss terms, or should we do something like use an average inlet condition?",
                  "url": "https://github.com/idaholab/moose/discussions/26889#discussioncomment-8593174",
                  "updatedAt": "2024-02-26T14:15:21Z",
                  "publishedAt": "2024-02-26T14:15:20Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "licharlot"
                  },
                  "bodyText": "Correct, the loss coefficient in the volume junction is associated with the flow conditions of the first connection. The associated area can be user defined, or is the one of the first connection only.  Most codes have a loss coefficient associated with each connection, forward and reverse loss coefficients.",
                  "url": "https://github.com/idaholab/moose/discussions/26889#discussioncomment-8593837",
                  "updatedAt": "2024-02-26T15:07:48Z",
                  "publishedAt": "2024-02-26T15:07:48Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "SomnusYu"
                          },
                          "bodyText": "That's to say, we truly need to calculate the loss coefficient of each connection, but THM just supports the loss coefficient of the first connection (just for example). We still need to improve THM to include all connections. Is that right?",
                          "url": "https://github.com/idaholab/moose/discussions/26889#discussioncomment-8593956",
                          "updatedAt": "2024-02-26T15:17:33Z",
                          "publishedAt": "2024-02-26T15:17:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "licharlot"
                          },
                          "bodyText": "Yes, we'd have to go back to the volume junction formulation and see how we can integrate this.",
                          "url": "https://github.com/idaholab/moose/discussions/26889#discussioncomment-8596720",
                          "updatedAt": "2024-02-26T19:18:39Z",
                          "publishedAt": "2024-02-26T19:18:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "SomnusYu"
                          },
                          "bodyText": "Thanks!",
                          "url": "https://github.com/idaholab/moose/discussions/26889#discussioncomment-8599145",
                          "updatedAt": "2024-02-27T00:57:00Z",
                          "publishedAt": "2024-02-27T00:56:59Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "joshuahansel"
                          },
                          "bodyText": "Yeah, formulation-wise, it seems straightforward. It's mostly just a matter of transitioning the new \"interface\" with some temporary backwards compatibility.",
                          "url": "https://github.com/idaholab/moose/discussions/26889#discussioncomment-8605341",
                          "updatedAt": "2024-02-27T13:31:37Z",
                          "publishedAt": "2024-02-27T13:31:36Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "SomnusYu"
                          },
                          "bodyText": "By the way, I would like to know if it is two-phase flow, what the momentum residual should be. I just write these terms according to single phase flow, could you please tell me if it is correct?\nFor single phase, it is:\n  _residual[VolumeJunction1Phase::RHOUV_INDEX] -=\n      di(0) * din * _flux[c][THM3Eqn::CONS_VAR_RHOUA] - pJ * ni(0) * _A[0];\n  _residual[VolumeJunction1Phase::RHOVV_INDEX] -=\n      di(1) * din * _flux[c][THM3Eqn::CONS_VAR_RHOUA] - pJ * ni(1) * _A[0];\n  _residual[VolumeJunction1Phase::RHOWV_INDEX] -=\n      di(2) * din * _flux[c][THM3Eqn::CONS_VAR_RHOUA] - pJ * ni(2) * _A[0];\n\nFor two phase:\n  _residual[VolumeJunction2Phase::VEL_LIQUID_U_INDEX] -=\n                        di(0) * din * _flux[c][THM6Eqn::CONS_VAR_VEL_LIQ] - (1.0 - alpha_J)* pJ * ni(0) * _A[0];\n  _residual[VolumeJunction2Phase::VEL_LIQUID_V_INDEX] -=\n                        di(1) * din * _flux[c][THM6Eqn::CONS_VAR_VEL_LIQ] -  (1.0 - alpha_J)* pJ * ni(1) * _A[0];\n  _residual[VolumeJunction2Phase::VEL_LIQUID_W_INDEX] -=\n                        di(2) * din * _flux[c][THM6Eqn::CONS_VAR_VEL_LIQ] -  (1.0 - alpha_J)* pJ * ni(2) * _A[0];\n  _residual[VolumeJunction2Phase::VEL_VAPOUR_U_INDEX] -=\n                        di(0) * din * _flux[c][THM6Eqn::CONS_VAR_VEL_VAP] - alpha_J* pJ * ni(0) * _A[0];\n  _residual[VolumeJunction2Phase::VEL_VAPOUR_V_INDEX] -=\n                        di(1) * din * _flux[c][THM6Eqn::CONS_VAR_VEL_VAP] - alpha_J* pJ * ni(1) * _A[0];\n  _residual[VolumeJunction2Phase::VEL_VAPOUR_W_INDEX] -=\n                        di(2) * din * _flux[c][THM6Eqn::CONS_VAR_VEL_VAP] - alpha_J* pJ * ni(2) * _A[0];",
                          "url": "https://github.com/idaholab/moose/discussions/26889#discussioncomment-8612361",
                          "updatedAt": "2024-02-28T01:49:44Z",
                          "publishedAt": "2024-02-28T01:49:43Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "joshuahansel"
                          },
                          "bodyText": "Looks right, assuming your alpha is the void fraction, not 1 - alpha.",
                          "url": "https://github.com/idaholab/moose/discussions/26889#discussioncomment-8622334",
                          "updatedAt": "2024-02-28T19:14:47Z",
                          "publishedAt": "2024-02-28T19:14:46Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "SomnusYu"
                          },
                          "bodyText": "Yes, alpha is the void fraction. Thanks a lot!",
                          "url": "https://github.com/idaholab/moose/discussions/26889#discussioncomment-8624667",
                          "updatedAt": "2024-02-29T01:02:36Z",
                          "publishedAt": "2024-02-29T01:02:36Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}