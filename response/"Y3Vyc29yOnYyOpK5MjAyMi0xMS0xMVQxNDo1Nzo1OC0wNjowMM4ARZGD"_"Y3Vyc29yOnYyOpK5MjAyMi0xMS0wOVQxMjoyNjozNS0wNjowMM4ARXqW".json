{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMi0xMS0wOVQxMjoyNjozNS0wNjowMM4ARXqW"
    },
    "edges": [
      {
        "node": {
          "title": "Can we build a static library of an App and easily used it in other computers with the same OS",
          "author": {
            "login": "zx1987"
          },
          "bodyText": "Dear Moose user group,\nI was hoping to compile a static library of an App, to use it on different computers with the same OS by just copying that compiled app. I was searching and found this discussion: #22326\nI was thinking maybe I can build libmesh and moose statically as described in the above post, and then compile our app after that. Will this give us a static library of the app, or there are additional steps I should consider? Thank you!\nBest,\nXiang",
          "url": "https://github.com/idaholab/moose/discussions/22653",
          "updatedAt": "2022-11-15T20:15:27Z",
          "publishedAt": "2022-11-10T19:46:39Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "You'll have to follow the post you linked to, then add the static flags in the CXXFLAGS environment variable.\n@milljm",
                  "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4111016",
                  "updatedAt": "2022-11-10T20:03:17Z",
                  "publishedAt": "2022-11-10T20:03:17Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "I agree, the post you linked, is basically the gist of what needs to happen. MOOSE based apps only build according to how libMesh was built. But if you're after a total relocatable binary, you may need to build statically, starting with PETSc.",
                          "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4111187",
                          "updatedAt": "2022-11-10T20:24:23Z",
                          "publishedAt": "2022-11-10T20:24:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "zx1987"
                          },
                          "bodyText": "Thank you @milljm @GiudGiud for your confirmation. I will test this out and let you know. Thanks.",
                          "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4111305",
                          "updatedAt": "2022-11-10T20:40:21Z",
                          "publishedAt": "2022-11-10T20:40:20Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "zx1987"
                          },
                          "bodyText": "I tried to do the static build of petsc, but came across the error like \"/home/xzhang16/mambaforge3/envs/petsc/bin/../lib/gcc/x86_64-conda-linux-gnu/10.4.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -lhdf5_cpp: No such file or directory\"\nDo you have any idea what might be wrong? @milljm @GiudGiud  I have more detailed error message attached in case it could be helpful. Thank you!\nStaticLibmeshError.txt",
                          "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4118392",
                          "updatedAt": "2022-11-11T15:00:23Z",
                          "publishedAt": "2022-11-11T15:00:22Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "which HDF5 library are you trying to use? One provided by your local environment or by PETSc ?",
                          "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4118418",
                          "updatedAt": "2022-11-11T15:03:24Z",
                          "publishedAt": "2022-11-11T15:03:24Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "zx1987"
                          },
                          "bodyText": "I did not really specify which hdf5 to use and was assuming if I take the stand installation procedure, it should be using the one from PETSc.  So I just did this again, by resetting my $PATH so the system only have access to the mamabaforge3 folder hence libraries from PETSc. It turns out I had the same error.  I tried to search lhdf5 in the mambaforge3 and nothing was found.  Tere are the steps I took in this new attempt:\n`curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh`\n`bash Mambaforge-Linux-x86_64.sh -b -p ~/mambaforge3`\n`unset LD_LIBRARY_PATH`\n`PATH=$(getconf PATH)` \n`export PATH=$HOME/mambaforge3/bin:$PATH  # reset the PATH such that I will not mistakenly use things other than from the the mambaforge3 folder`\n`conda config --add channels https://conda.software.inl.gov/public`\n\nsteps taken from post  https://github.com/idaholab/moose/discussions/22326\n`mamba activate base    # get back to the original environment`\n`mamba create -n petsc moose-petsc moose-tools`\n`mamba activate petsc`  \n`cd ~/projects/moose`\n`git clean -xfd`\n`git submodule foreach --recursive git clean -xfd`\n\n`export MOOSE_JOBS=8   # replace this number with how many cores your machine has`\n`export METHODS=opt`\n`scripts/update_and_rebuild_libmesh.sh --enable-all-static --enable-static`",
                          "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4118597",
                          "updatedAt": "2022-11-11T16:36:52Z",
                          "publishedAt": "2022-11-11T15:28:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "If you're going to use Mamba, you might as well create and distribute a mamba package containing your binary instead (since if using Mamba, you'll need to have each of your users also install Mamba).\nHave a look at moose/conda/generate_recipe.sh. The gist of this tool's use is as follows:\ncd ~/projects\ngit clone https://github.com/idaholab/moose\ngit clone <your moose-based application>\nexport MOOSE_SKIP_DOCS=True\nmoose/conda/generate_recipe.sh /absolute/path/to/<your moose-based application> 12\n\n12 being the number of cores you can use on this machine\nMOOSE_SKIP_DOCS=True telling the make install process to ignore building documentation if you prefer\n\nThis will pre-install everything necessary (including Conda, boa, etc) into a temporary directory, and proceed to building your application as a relocatable package (A conda package). Much like; moose-libmesh, moose-tools, etc.\nOnce/If successful, your package can be installed by others, via:\nmamba install /path/to/created/conda-package.tar.gz",
                          "url": "https://github.com/idaholab/moose/discussions/22653#discussioncomment-4120445",
                          "updatedAt": "2022-11-11T20:50:34Z",
                          "publishedAt": "2022-11-11T20:44:26Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Gradient of the hydrostatic stress \\sigma_H",
          "author": {
            "login": "saturn00000"
          },
          "bodyText": "Dear MOOSE Team\ncan we define the gradient of the hydrostatic stress, \\sigma_H, which is computed at the integration points from the nodal displacements in MOOSE?\nThe test input file looks like:\n...\n\n[AuxVariables]\n  [hydrostatic]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n  [grad_u_x]\n    order = CONSTANT\n    family = MONOMIAL\n  []\n[]\n\n[AuxKernels]\n  [hydrostatic]\n    type = ADRankTwoScalarAux\n    rank_two_tensor = stress\n    variable = hydrostatic\n    scalar_type = Hydrostatic\n  []\n\n  [grad_u_x_aux]\n    type = VariableGradientComponent\n    variable = grad_u_x\n    component = x\n    gradient_variable = hydrostatic\n  []\n\n[]\n...\n\nThe results show that the value of the gradient of the hydrostatic stress in x direction (defined as grad_u_x) is 0...",
          "url": "https://github.com/idaholab/moose/discussions/22661",
          "updatedAt": "2022-11-16T07:03:15Z",
          "publishedAt": "2022-11-11T01:08:48Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "hugary1995"
                  },
                  "bodyText": "You can do a local L2 projection which preserves dual numbers. See e.g. https://github.com/hugary1995/eel/blob/main/src/materials/chemistry/ChemicalPotential.C",
                  "url": "https://github.com/idaholab/moose/discussions/22661#discussioncomment-4113067",
                  "updatedAt": "2022-11-11T01:55:45Z",
                  "publishedAt": "2022-11-11T01:55:44Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "saturn00000"
                          },
                          "bodyText": "can we just set order = second\ne.g.\n  [hydrostatic]\n    order = second \n    family = MONOMIAL\n  []",
                          "url": "https://github.com/idaholab/moose/discussions/22661#discussioncomment-4113184",
                          "updatedAt": "2022-11-11T02:20:17Z",
                          "publishedAt": "2022-11-11T02:20:16Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hugary1995"
                          },
                          "bodyText": "Yes, actually you can get it to work using any monomial equal or above first order. Please be reminded that all derivatives in the ADReal will be lost by projecting it onto an AuxVariable. So if your model is somehow coupled to the gradient of the hydrostatic stress, the Jacobian will no longer be exact.",
                          "url": "https://github.com/idaholab/moose/discussions/22661#discussioncomment-4119774",
                          "updatedAt": "2022-11-11T18:26:32Z",
                          "publishedAt": "2022-11-11T18:26:31Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "moose-tools installation issues",
          "author": {
            "login": "MusannaGalib"
          },
          "bodyText": "Hello,\nI am trying to install MOOSE in HPC. After installing miniconda, I did -\nconda config --add channels https://conda.software.inl.gov/public\nconda create --name moose -q -y\n\nwhen I am trying to install moose-tools, the following problem occurs.\n(moose) [galibubc@cedar5 MOOSE]$ conda install moose-tools\nCollecting package metadata (current_repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\nCollecting package metadata (repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: \\ \nFound conflicts! Looking for incompatible packages.\nThis can take several minutes.  Press CTRL-C to abort.\nfailed                                                                          \n\nUnsatisfiableError:",
          "url": "https://github.com/idaholab/moose/discussions/22617",
          "updatedAt": "2022-11-15T20:09:52Z",
          "publishedAt": "2022-11-08T05:42:52Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "so moose-tools is the only package you are trying to install in that environment right?\n@milljm",
                  "url": "https://github.com/idaholab/moose/discussions/22617#discussioncomment-4086629",
                  "updatedAt": "2022-11-08T13:12:56Z",
                  "publishedAt": "2022-11-08T13:12:55Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "MusannaGalib"
                          },
                          "bodyText": "yes. After installing the python 3.x development libraries I will install petsc and libmesh - if I am not wrong.",
                          "url": "https://github.com/idaholab/moose/discussions/22617#discussioncomment-4090854",
                          "updatedAt": "2022-11-08T21:03:03Z",
                          "publishedAt": "2022-11-08T21:03:02Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "It's possible the Python version built-in to your installed version of miniconda, is too far outdated to support Python >= 3.7.\nThe good news is, it sounds like you don't need our Conda stack. Normally in an HPC environment, that environment will supply a working stack better suited for the hardware that makes up your HPC environment. Conda is great for workstations. Not so great for HPC clusters.",
                          "url": "https://github.com/idaholab/moose/discussions/22617#discussioncomment-4096859",
                          "updatedAt": "2022-11-09T13:01:28Z",
                          "publishedAt": "2022-11-09T13:00:54Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "MusannaGalib"
                          },
                          "bodyText": "Hello @milljm\nThanks for the reply. I installed the latest version of miniconda. Are you saying I do not need to install moose-tools in our HPC?\nWithout installing the moose tools I installed petsc successfully.\nunset PETSC_DIR PETSC_ARCH\n./scripts/update_and_rebuild_petsc.sh\n\nHowever when I am trying to install libmesh, facing the following error:\n(moose) [galibubc@cedar1 moose]$ ./scripts/update_and_rebuild_libmesh.sh\nPETSc submodule will be used. PETSc submodule is our default solver.\nIMPORTANT: If you did not run the update_and_rebuild_petsc.sh script yet, please run it before building libMesh\n---------------------------------------------\n----------- Configuring libMesh -------------\n---------------------------------------------\nchecking build system type... x86_64-pc-linux-gnu\nchecking host system type... x86_64-pc-linux-gnu\nchecking target system type... x86_64-pc-linux-gnu\nchecking for a BSD-compatible install... /home/galibubc/projects/def-mponga/galibubc/MOOSE/projects/moose/scripts/../libmesh/build-aux/install-sh -C\nchecking whether build environment is sane... yes\nchecking for a thread-safe mkdir -p... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/mkdir -p\nchecking for gawk... gawk\nchecking whether make sets $(MAKE)... yes\nchecking whether make supports nested variables... yes\nchecking whether UID '3115128' is supported by ustar format... no\nchecking whether GID '3115128' is supported by ustar format... no\nchecking how to create a ustar tar archive... none\nchecking whether make supports nested variables... (cached) yes\nchecking whether to enable maintainer-specific portions of Makefiles... no\nchecking for src/base/libmesh.C... no\n<<< Configuring build directory for VPATH build >>>\nchecking for perl... /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/perl\nnote: MPI library path not given...\nnote: MPI library path not given...\nchecking whether make supports the include directive... yes (GNU style)\nchecking whether the C compiler works... yes\nchecking for C compiler default output file name... a.out\nchecking for suffix of executables... \nchecking whether we are cross compiling... no\nchecking for suffix of object files... o\nchecking whether we are using the GNU C compiler... yes\nchecking whether mpicc accepts -g... yes\nchecking for mpicc option to accept ISO C89... none needed\nchecking whether mpicc understands -c and -o together... yes\nchecking dependency style of mpicc... gcc3\nchecking whether we are using the GNU Fortran compiler... yes\nchecking whether mpif90 accepts -g... yes\nchecking whether we are using the GNU Fortran 77 compiler... yes\nchecking whether mpif77 accepts -g... yes\nchecking whether we are using the GNU C++ compiler... yes\nchecking whether mpicxx accepts -g... yes\nchecking dependency style of mpicxx... gcc3\n<<< C++ compiler is gcc-11.x >>>\nchecking for a sed that does not truncate output... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/sed\nchecking for C++ compiler vendor... gnu\nconfigure: Seeking a C++ standard between \"2014\" and \"2017\"\nchecking whether mpicxx supports C++17 features by default... yes\nchecking for C++11 auto keyword support... yes\nchecking for C++11 range-based for loop support... yes\nchecking for C++11 initializer list support... yes\nchecking for C++11 std::unique_ptr support... yes\nchecking for C++11 std::make_unique workaround support... yes\nchecking for C++11 std::tuple support... yes\nchecking for C++11 lambda support... yes\nchecking for C++11 fixed type enumeration support... yes\nchecking for C++11 fixed type enumeration forward declaration support... yes\nchecking for C++11 override keyword support... yes\nchecking for C++11 move constructor support... yes\nchecking for C++11 deleted functions support... yes\nchecking for C++11 defaulted functions support... yes\nchecking for C++11 nullptr support... yes\nchecking for C++11 'final' keyword support... yes\nchecking for C++11 decltype support... yes\nchecking for C++11 std::begin/end support for arrays... yes\nchecking for C++11 std container erase() functions returning iterators... yes\nchecking for C++11 std container emplace() functions... yes\nchecking for C++11 std::iota algorithm... yes\nchecking for C++11 std::vector::data() API... yes\nchecking for C++11 std::shared_ptr support... yes\nchecking for C++11 rvalue references support... yes\nchecking for C++11 std::to_string() support... yes\nchecking for C++11 constexpr support... yes\nchecking for C++11 variadic template support... yes\nchecking for C++11 alias declarations support... yes\nchecking for C++11 std::array... yes\nchecking for C++11 std::isnan... yes\nchecking for C++11 std::isinf... yes\nchecking for C++17 std::*::merge... yes\nconfigure: Found C++17 standard support\nchecking whether mpicxx supports C++14 features by default... yes\nconfigure: Found C++14 standard support\nchecking whether mpicxx supports C++11 features by default... yes\nconfigure: Found C++11 standard support\nconfigure: Using support for C++17 standard\n<<< Configuring libMesh with methods \"opt oprof devel dbg\" >>>\n<<< Compiler warnings are just warnings >>>\n<<< Disabling extra paranoid compiler warnings >>>\nchecking for C++14 std::make_unique support... yes\nchecking for C++11 std::regex support... yes\nchecking for C++11 <thread> support... yes\nchecking for C++11 <condition_variable> support... yes\nchecking for C++11 <type_traits> support... yes\nchecking for C++11 std::asinh support in <cmath>... yes\nchecking for C++11 std::acosh support in <cmath>... yes\nchecking for C++11 std::atanh support in <cmath>... yes\nchecking for C++11 std::asinh(complex) support in <complex>... yes\nchecking for C++11 std::acosh(complex) support in <complex>... yes\nchecking for C++11 std::atanh(complex) support in <complex>... yes\nchecking for C++11 std::erf support in <cmath>... yes\nchecking for C++17 fallthrough attribute support... yes, but disabled.\nchecking for __attribute__ ((fallthrough)) support... yes\nchecking how to print strings... printf\nchecking for a sed that does not truncate output... (cached) /cvmfs/soft.computecanada.ca/gentoo/2020/bin/sed\nchecking for grep that handles long lines and -e... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/grep\nchecking for egrep... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/grep -E\nchecking for fgrep... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/grep -F\nchecking for ld used by mpicc... /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld\nchecking if the linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld) is GNU ld... yes\nchecking for BSD- or MS-compatible name lister (nm)... /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/nm -B\nchecking the name lister (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/nm -B) interface... BSD nm\nchecking whether ln -s works... yes\nchecking the maximum length of command line arguments... 1572864\nchecking how to convert x86_64-pc-linux-gnu file names to x86_64-pc-linux-gnu format... func_convert_file_noop\nchecking how to convert x86_64-pc-linux-gnu file names to toolchain format... func_convert_file_noop\nchecking for /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld option to reload object files... -r\nchecking for objdump... objdump\nchecking how to recognize dependent libraries... pass_all\nchecking for dlltool... no\nchecking how to associate runtime and link libraries... printf %s\\n\nchecking for ar... ar\nchecking for archiver @FILE support... @\nchecking for strip... strip\nchecking for ranlib... ranlib\nchecking command to parse /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/nm -B output from mpicc object... ok\nchecking for sysroot... no\nchecking for a working dd... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/dd\nchecking how to truncate binary pipes... /cvmfs/soft.computecanada.ca/gentoo/2020/bin/dd bs=4096 count=1\nchecking for mt... no\nchecking if : is a manifest tool... no\nchecking how to run the C preprocessor... mpicc -E\nchecking for ANSI C header files... yes\nchecking for sys/types.h... yes\nchecking for sys/stat.h... yes\nchecking for stdlib.h... yes\nchecking for string.h... yes\nchecking for memory.h... yes\nchecking for strings.h... yes\nchecking for inttypes.h... yes\nchecking for stdint.h... yes\nchecking for unistd.h... yes\nchecking for dlfcn.h... yes\nchecking for objdir... .libs\nchecking if mpicc supports -fno-rtti -fno-exceptions... no\nchecking for mpicc option to produce PIC... -fPIC -DPIC\nchecking if mpicc PIC flag -fPIC -DPIC works... yes\nchecking if mpicc static flag -static works... no\nchecking if mpicc supports -c -o file.o... yes\nchecking if mpicc supports -c -o file.o... (cached) yes\nchecking whether the mpicc linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\nchecking whether -lc should be explicitly linked in... no\nchecking dynamic linker characteristics... GNU/Linux ld.so\nchecking how to hardcode library paths into programs... immediate\nchecking whether stripping libraries is possible... yes\nchecking if libtool supports shared libraries... yes\nchecking whether to build shared libraries... yes\nchecking whether to build static libraries... no\nchecking how to run the C++ preprocessor... mpicxx -E\nchecking for ld used by mpicxx... /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64\nchecking if the linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64) is GNU ld... yes\nchecking whether the mpicxx linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\nchecking for mpicxx option to produce PIC... -fPIC -DPIC\nchecking if mpicxx PIC flag -fPIC -DPIC works... yes\nchecking if mpicxx static flag -static works... no\nchecking if mpicxx supports -c -o file.o... yes\nchecking if mpicxx supports -c -o file.o... (cached) yes\nchecking whether the mpicxx linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\nchecking dynamic linker characteristics... (cached) GNU/Linux ld.so\nchecking how to hardcode library paths into programs... immediate\nchecking if libtool supports shared libraries... yes\nchecking whether to build shared libraries... yes\nchecking whether to build static libraries... no\nchecking for mpif77 option to produce PIC... -fPIC\nchecking if mpif77 PIC flag -fPIC works... yes\nchecking if mpif77 static flag -static works... no\nchecking if mpif77 supports -c -o file.o... yes\nchecking if mpif77 supports -c -o file.o... (cached) yes\nchecking whether the mpif77 linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\nchecking dynamic linker characteristics... (cached) GNU/Linux ld.so\nchecking how to hardcode library paths into programs... immediate\nchecking if libtool supports shared libraries... yes\nchecking whether to build shared libraries... yes\nchecking whether to build static libraries... no\nchecking for mpif90 option to produce PIC... -fPIC\nchecking if mpif90 PIC flag -fPIC works... yes\nchecking if mpif90 static flag -static works... no\nchecking if mpif90 supports -c -o file.o... yes\nchecking if mpif90 supports -c -o file.o... (cached) yes\nchecking whether the mpif90 linker (/cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\nchecking dynamic linker characteristics... (cached) GNU/Linux ld.so\nchecking how to hardcode library paths into programs... immediate\nchecking Major version... 1\nchecking Minor version... 8\nchecking Point version... 0-pre\nchecking whether ln -s works... yes\nchecking for a sed that does not truncate output... (cached) /cvmfs/soft.computecanada.ca/gentoo/2020/bin/sed\nchecking for pkg-config... /cvmfs/soft.computecanada.ca/gentoo/2020/usr/bin/pkg-config\nchecking whether the compiler implements namespaces... yes\n---------------------------------------------\n------- Configuring compiler features -------\n---------------------------------------------\n<<< Default floating point is double precision (double) >>>\nchecking for C/C++ restrict keyword... __restrict\nchecking pwd.h usability... yes\nchecking pwd.h presence... yes\nchecking for pwd.h... yes\n<<< Configuring library with getpwuid >>>\n<<< Configuring library with exception throwing support >>>\n<<< Configuring library with compile timestamps >>>\nchecking size of short int... 2\nchecking size of int... 4\nchecking size of unsigned int... 4\nchecking size of size_t... 8\nchecking size of long int... 8\nchecking size of float... 4\nchecking size of double... 8\nchecking size of void *... 8\nchecking size of function_pointer... 8\nchecking whether the compiler supports Run-Time Type Identification... yes\nchecking getopt.h usability... yes\nchecking getopt.h presence... yes\nchecking for getopt.h... yes\nchecking sys/time.h usability... yes\nchecking sys/time.h presence... yes\nchecking for sys/time.h... yes\nchecking process.h usability... no\nchecking process.h presence... no\nchecking for process.h... no\nchecking csignal usability... yes\nchecking csignal presence... yes\nchecking for csignal... yes\nchecking sys/resource.h usability... yes\nchecking sys/resource.h presence... yes\nchecking for sys/resource.h... yes\nchecking whether the compiler has locale... yes\nchecking whether the compiler has stringstream... yes\nchecking fenv.h usability... yes\nchecking fenv.h presence... yes\nchecking for fenv.h... yes\nchecking xmmintrin.h usability... yes\nchecking xmmintrin.h presence... yes\nchecking for xmmintrin.h... yes\nchecking whether sigaction is declared... yes\nchecking for mkdir with two arguments... yes\nchecking direct.h usability... no\nchecking direct.h presence... no\nchecking for direct.h... no\nchecking whether _mkdir is declared... no\nchecking for mkstemp... yes\nchecking for gettimeofday... yes\nchecking sys/utsname.h usability... yes\nchecking sys/utsname.h presence... yes\nchecking for sys/utsname.h... yes\nchecking whether the compiler supports std::unordered_multimap... yes\nchecking whether the compiler supports std::unordered_map... yes\nchecking whether the compiler supports std::unordered_multiset... yes\nchecking whether the compiler supports std::unordered_set... yes\nchecking whether the compiler supports std::hash... yes\nchecking for library containing dlopen... -ldl\nchecking whether the c++ compiler supports dlopen/dlsym/dlclose... yes\nchecking whether the compiler supports GCC C++ ABI name demangling... yes\nchecking whether the c++ compiler supports glibc backtrace... yes\nchecking if errno.h can be wrapped in namespace... yes\n---------------------------------------------\n----- Done configuring compiler features ----\n---------------------------------------------\n---------------------------------------------\n----- Configuring core library features -----\n---------------------------------------------\nconfiguring gdb command... \"no\"\n>>> INFO: Disabling library warnings <<<\n>>> Configuring library without warnings <<<\n<<< Configuring library with deprecated code support >>>\n../configure: line 46713: irrelevant=yes: command not found\n<<< Configuring library to require ``include \"libmesh/etc.h\"'' style >>>\n<<< Configuring library to keep names in libMesh namespace >>>\nconfiguring size of boundary_id... 2\nconfiguring size of dof_id... 4\nconfiguring size of processor_id... 4\nconfiguring size of subdomain_id... 2\n<<< Configuring library with unique id support >>>\nconfiguring size of unique_id... 8\n<<< Configuring library with AMR support >>>\n<<< Configuring library with variational smoother support >>>\n<<< Configuring library with periodic BC support >>>\n<<< Configuring library with Dirichlet constraint support >>>\n<<< --enable-parmesh is deprecated; use --enable-distmesh >>>\nconfiguring size of mapvector chunks: 1\n<<< Configuring library to use ghosted local vectors >>>\n<<< Configuring library to store node valence >>>\n<<< Configuring library with higher order p-FEM shapes >>>\n<<< Configuring library with second derivatives >>>\n<<< Configuring library with real number support >>>\n<<< Configuring library with reference counting support >>>\n<<< Configuring library example suite support >>>\n---------------------------------------------\n-- Done configuring core library features ---\n---------------------------------------------\n---------------------------------------------\n----- Configuring for optional packages -----\n---------------------------------------------\nchecking for built-in XDR support... no\nchecking for XDR support in /usr/include/tirpc... no\nconfigure: error: *** XDR was not found, but --enable-xdr-required was specified.\nRunning make -j 1...\nmake: *** No targets specified and no makefile found.  Stop.\n(moose) [galibubc@cedar1 moose]$ \n\n\nI checked previous discussion threads on how to install xdr on HPC but couldn't understand it correctly. Can you suggest on this? Thanks.",
                          "url": "https://github.com/idaholab/moose/discussions/22617#discussioncomment-4119077",
                          "updatedAt": "2022-11-11T16:32:39Z",
                          "publishedAt": "2022-11-11T16:32:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Hello\nYou're going to have to install libtirpc-devel.\nIt s likely easier to ask the cluster administrators to do it\nGuillaume",
                          "url": "https://github.com/idaholab/moose/discussions/22617#discussioncomment-4119101",
                          "updatedAt": "2022-11-11T16:36:29Z",
                          "publishedAt": "2022-11-11T16:36:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "MusannaGalib"
                          },
                          "bodyText": "Hello Guillaume,\nThanks. I will contact them then!",
                          "url": "https://github.com/idaholab/moose/discussions/22617#discussioncomment-4119150",
                          "updatedAt": "2022-11-11T16:43:27Z",
                          "publishedAt": "2022-11-11T16:43:26Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "hypre AMG does not converge in thermomechanical coupling problem",
          "author": {
            "login": "js-jixu"
          },
          "bodyText": "Hi, experts.\nI want to compute some large scale thermomechanical coupling problem, with about millions of degrees of freedom. Obviously, it is not suitable to use LU, because it requires too much computing resources. So I want to try other preconditioners. After reading about the Hypre/BoomerAMG on the MOOSE website, I figured it might be appropriate.\nThere is a thermomechanical coupling model that can be solved well with lu. This model is not large, with only 60,000 degrees of freedom. Here is its Executioner block:\n[Executioner]\n  type = Transient\n  dt = 1\n  end_time = 50\n  steady_state_detection = true\n\n  solve_type = 'PJFNK'\n  petsc_options = '-snes_converged_reason -ksp_converged_reason -snes_linesearch_monitor'\n  petsc_options_iname = '-pc_type -pc_factor_shift_type'\n  petsc_options_value = 'lu       NONZERO'\n  line_search = 'none'\n\n  nl_rel_tol = 1e-8\n  nl_abs_tol = 1e-8\n  nl_max_its = 30\n  l_max_its = 100\n  automatic_scaling = true\n  compute_scaling_once = false\n  off_diagonals_in_auto_scaling = true\n[]\n\nBut when I changed the preconditioner to hypre, it was difficult to converge;\n  petsc_options_iname = '-pc_type -pc_hypre_type -pc_hypre_boomeramg_strong_threshold -pc_hypre_boomeramg_agg_nl -pc_hypre_boomeramg_agg_num_paths -pc_hypre_boomeramg_max_levels -pc_hypre_boomeramg_coarsen_type -pc_hypre_boomeramg_interp_type -pc_hypre_boomeramg_P_max -pc_hypre_boomeramg_truncfactor'\n  petsc_options_value = 'hypre    boomeramg      0.7                                  4                          5                                  25                            HMIS                             ext+i                           2                         0.3                            '\n\nI want to know where should I improve it?\nBesides, I've found two simple spelling mistakes on the website.",
          "url": "https://github.com/idaholab/moose/discussions/22468",
          "updatedAt": "2022-12-06T14:25:10Z",
          "publishedAt": "2022-10-22T15:51:31Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nI d start with something with less options active and with less truncation, higher cutoff thresholds, try to get good (fewer iterations) but more expensive (each iteration takes long) convergence .\nThen work from there to reduce costs.\nIs this only thermo mechanics? No fluids?\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3941125",
                  "updatedAt": "2022-10-22T18:52:56Z",
                  "publishedAt": "2022-10-22T18:52:55Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "My problem also has fluids. Does hypre perform well in the INS problem?",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3941827",
                          "updatedAt": "2022-10-22T23:20:55Z",
                          "publishedAt": "2022-10-22T23:20:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "I reduced the number of options and lowered -pc_hypre_boomeramg_strong_threshold and -pc_hypre_boomeramg_truncfactor as much as possible to get better convergence:\n  petsc_options_iname = '-pc_type -pc_hypre_type -pc_hypre_boomeramg_strong_threshold -pc_hypre_boomeramg_interp_type -pc_hypre_boomeramg_truncfactor'\n  petsc_options_value = 'hypre    boomeramg      0                                    ext+i                           0.1                            '\n\nBut it doesn't work. My problem is a thermal-mechanical-fluid coupling problem. There is a heating rod in the middle with fluid flowing around it. And the heating rod will expand as the temperature rises.\nI have two questions. The first is whether AMG is only suitable for solving solid mechanics problems, not for solving INS problems. Since I saw @friedmud and Jed Brown in the moose-users group saying that BoomerAMG was originally designed to solve the steady state scalar problem, convergence was difficult when I coupled the fluid flow.\nThe second is whether there is a combination of options with the strongest convergence in AMG's options. This combination does not consider the computational resources consumed, as long as it can converge. I even set the -pc_hypre_boomeramg_strong_threshold to 0, but it still doesn't converge:\nTime Step 1, time = 0.25, dt = 0.25\n\nPerforming automatic scaling calculation\n\n 0 Nonlinear |R| = 4.647580e+03\n    |residual|_2 of individual variables:\n                   velocity: 4647.58\n                   p:        9.10215e-06\n                   Tf:       4.78304e-13\n                   Ts:       0.327606\n                   disp_x:   5.46689e-19\n                   disp_y:   5.46689e-19\n                   disp_z:   2.5208e-20\n      0 Linear |R| = 4.647580e+03\n      1 Linear |R| = 4.647580e+03\n      2 Linear |R| = 4.647580e+03\n      3 Linear |R| = 4.647580e+03\n      4 Linear |R| = 4.647580e+03\n      5 Linear |R| = 4.647580e+03\n      6 Linear |R| = 4.647580e+03\n      7 Linear |R| = 4.647580e+03\n      8 Linear |R| = 4.647580e+03\n      9 Linear |R| = 4.647580e+03\n     10 Linear |R| = 4.647580e+03\n     11 Linear |R| = 4.647580e+03\n     12 Linear |R| = 4.647580e+03\n     13 Linear |R| = 4.647580e+03\n     14 Linear |R| = 4.647580e+03\n     15 Linear |R| = 4.647580e+03\n     16 Linear |R| = 4.647580e+03\n     17 Linear |R| = 4.647580e+03\n     18 Linear |R| = 4.647580e+03\n     19 Linear |R| = 4.647580e+03\n     20 Linear |R| = 4.647580e+03\n     21 Linear |R| = 4.647580e+03\n     22 Linear |R| = 4.647580e+03\n     23 Linear |R| = 4.647580e+03\n     24 Linear |R| = 4.647580e+03\n     25 Linear |R| = 4.647580e+03\n     26 Linear |R| = 4.647580e+03\n     27 Linear |R| = 4.647580e+03\n     28 Linear |R| = 4.647580e+03\n     29 Linear |R| = 4.647580e+03\n     30 Linear |R| = 4.647580e+03\n     31 Linear |R| = 4.647580e+03\n     32 Linear |R| = 4.647580e+03\n     33 Linear |R| = 4.647580e+03\n     34 Linear |R| = 4.647580e+03\n     35 Linear |R| = 4.647580e+03\n     36 Linear |R| = 4.647580e+03\n     37 Linear |R| = 4.647580e+03\n     38 Linear |R| = 4.647580e+03\n     39 Linear |R| = 4.647580e+03\n     40 Linear |R| = 4.647580e+03\n     41 Linear |R| = 4.647580e+03\n     42 Linear |R| = 4.647580e+03\n     43 Linear |R| = 4.647580e+03\n     44 Linear |R| = 4.647580e+03\n     45 Linear |R| = 4.647580e+03\n     46 Linear |R| = 4.647580e+03\n     47 Linear |R| = 4.647580e+03\n     48 Linear |R| = 4.647580e+03\n     49 Linear |R| = 4.647580e+03\n     50 Linear |R| = 4.647580e+03\n     51 Linear |R| = 4.647580e+03\n     52 Linear |R| = 4.647580e+03\n     53 Linear |R| = 4.647580e+03\n     54 Linear |R| = 4.647580e+03\n     55 Linear |R| = 4.647580e+03\n     56 Linear |R| = 4.647580e+03\n     57 Linear |R| = 4.647580e+03\n     58 Linear |R| = 4.647580e+03\n     59 Linear |R| = 4.647580e+03\n     60 Linear |R| = 4.647580e+03\n     61 Linear |R| = 4.647580e+03\n     62 Linear |R| = 4.647580e+03\n     63 Linear |R| = 4.647580e+03\n     64 Linear |R| = 4.647580e+03\n     65 Linear |R| = 4.647580e+03\n     66 Linear |R| = 4.647580e+03\n     67 Linear |R| = 4.647580e+03\n     68 Linear |R| = 4.647580e+03\n     69 Linear |R| = 4.647580e+03\n     70 Linear |R| = 4.647580e+03\n     71 Linear |R| = 4.647580e+03\n     72 Linear |R| = 4.647580e+03\n     73 Linear |R| = 4.647580e+03\n     74 Linear |R| = 4.647580e+03\n     75 Linear |R| = 4.647580e+03\n     76 Linear |R| = 4.647580e+03\n     77 Linear |R| = 4.647580e+03\n     78 Linear |R| = 4.647580e+03\n     79 Linear |R| = 4.647580e+03\n     80 Linear |R| = 4.647580e+03\n     81 Linear |R| = 4.647580e+03\n     82 Linear |R| = 4.647580e+03\n     83 Linear |R| = 4.647580e+03\n     84 Linear |R| = 4.647580e+03\n     85 Linear |R| = 4.647580e+03\n     86 Linear |R| = 4.647580e+03\n     87 Linear |R| = 4.647580e+03\n     88 Linear |R| = 4.647580e+03\n     89 Linear |R| = 4.647580e+03\n     90 Linear |R| = 4.647580e+03\n     91 Linear |R| = 4.647580e+03\n     92 Linear |R| = 4.647580e+03\n     93 Linear |R| = 4.647580e+03\n     94 Linear |R| = 4.647580e+03\n     95 Linear |R| = 4.647580e+03\n     96 Linear |R| = 4.647580e+03\n     97 Linear |R| = 4.647580e+03\n     98 Linear |R| = 4.647580e+03\n     99 Linear |R| = 4.647580e+03\n    100 Linear |R| = 4.647580e+03\n  Linear solve did not converge due to DIVERGED_ITS iterations 100",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3942250",
                          "updatedAt": "2022-10-23T03:26:07Z",
                          "publishedAt": "2022-10-23T03:26:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Yeah I don\u2019t think that will work for fluids. You should look into field splits in moose. This will allow you to use different preconditionning for each physics",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3942407",
                          "updatedAt": "2022-10-23T05:05:52Z",
                          "publishedAt": "2022-10-23T05:05:52Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "Do you mean that I should use AMG for thermal-mechanical field and use other preconditioner for fluid field? Is there any case about field splits in MOOSE? I thought that MOOSE can only use one preconditioner in the Executioner block.",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3942421",
                          "updatedAt": "2022-10-23T05:15:27Z",
                          "publishedAt": "2022-10-23T05:15:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "AMG for thermomechanical, and maybe LU for fluids for now, or a nested field split on pressure and velocity",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3942424",
                          "updatedAt": "2022-10-23T05:17:53Z",
                          "publishedAt": "2022-10-23T05:17:53Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "I'll try this method as soon as possibile. Let's see if it solves the problem.",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3942475",
                          "updatedAt": "2022-10-23T13:54:47Z",
                          "publishedAt": "2022-10-23T05:49:55Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "https://mooseframework.inl.gov/source/preconditioners/FieldSplitPreconditioner.html",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3944126",
                          "updatedAt": "2022-10-23T14:50:23Z",
                          "publishedAt": "2022-10-23T14:50:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "I have tried various preconditioners. But since I don't know much about the math behind these preconditioners, I'm trying blindly. I've tried [Preconditioning] with both FSP and SMP, and here are some of what I've tried:\n# [Preconditioning]\n#   active = 'FSP'\n#   [FSP]\n#     type = FSP\n#     topsplit = 'up'\n#     [up]\n#       splitting = 'u p'\n\n#       splitting_type = additive\n\n#       # splitting_type = schur\n#       # petsc_options_iname = '-pc_fieldsplit_schur_fact_type  -pc_fieldsplit_schur_precondition'\n#       # petsc_options_value = 'full                            selfp'\n#     []\n#     [u]\n#       vars = 'velocity p'\n#       # petsc_options_iname = '-pc_type -sub_pc_type -sub_pc_factor_levels -ksp_gmres_restart'\n#       # petsc_options_value = 'asm      ilu          4                     200               '\n#       petsc_options_iname = '-pc_type -pc_factor_shift_type'\n#       petsc_options_value = 'lu       NONZERO'\n#     []\n#     [p]\n#       vars = 'disp_x disp_y disp_z Ts Tf'\n#       petsc_options_iname = '-pc_type -pc_hypre_type -pc_hypre_boomeramg_strong_threshold -pc_hypre_boomeramg_interp_type -pc_hypre_boomeramg_truncfactor'\n#       petsc_options_value = 'hypre    boomeramg      0.7                                    ext+i                           0.2                            '\n#     []\n#   []\n# []\n\n# [Preconditioning]\n#   [fsp]\n#     type = FSP\n#     topsplit = 'up'\n#     [up]\n#       splitting = 'u p'\n#       splitting_type = schur\n#       petsc_options_iname = '-pc_fieldsplit_schur_fact_type  -pc_fieldsplit_schur_precondition'\n#       petsc_options_value = 'full selfp'\n#     []\n#     [u]\n#       vars = 'velocity'\n#       petsc_options_iname = '-pc_type -ksp_type'\n#       petsc_options_value = '     hypre gmres'\n#     []\n#     [p]\n#       vars = 'p Ts Tf disp_x disp_y disp_z'\n#       petsc_options_iname = '-pc_type -ksp_type'\n#       petsc_options_value = '   jacobi    gmres'\n#     []\n#   []\n# []\n\n# [Preconditioning]\n#   [FSP]\n#     type = FSP\n#     petsc_options_iname = '-snes_type -ksp_type -ksp_rtol -ksp_atol -ksp_max_it -snes_atol -snes_rtol -snes_max_it -snes_max_funcs'\n#     petsc_options_value = 'newtonls     fgmres     1e-2     1e-15       200       1e-10        1e-15       200           100000'\n#     topsplit = 'uv'\n#     [uv]\n#       petsc_options_iname = '-pc_fieldsplit_schur_fact_type -pc_fieldsplit_schur_precondition'\n#       petsc_options_value = 'upper selfp'\n#       splitting = 'u v'\n#       splitting_type = schur\n#     []\n#     [u]\n#       vars = 'velocity'\n#       petsc_options_iname = '-pc_type -ksp_type -pc_hypre_type'\n#       petsc_options_value = '  hypre    preonly     boomeramg '\n#     []\n#     [v]\n#       vars = 'p Ts Tf disp_x disp_y disp_z'\n#       petsc_options_iname = '-pc_type -ksp_type -sub_pc_type -sub_pc_factor_levels'\n#       petsc_options_value = '  jacobi  preonly        ilu            3'\n#     []\n#   []\n# []\n\n# [Preconditioning]\n#   [SMP]\n#     type = SMP\n#     full = true\n#     solve_type = 'NEWTON'\n#   []\n# []\n\n[Executioner]\n  type = Transient\n  dt = 0.25\n  end_time = 0.5\n  steady_state_detection = true\n\n  solve_type = 'PJFNK'\n  petsc_options = '-snes_converged_reason -ksp_converged_reason -snes_linesearch_monitor'\n\n  # petsc_options_iname = '-pc_type -pc_factor_shift_type'\n  # petsc_options_value = 'lu       NONZERO'\n\n  # petsc_options_iname = '-pc_type -sub_pc_type -sub_pc_factor_levels -ksp_gmres_restart'\n  # petsc_options_value = 'asm      ilu          3                     200               '\n\n  # petsc_options_iname = '-pc_type -sub_pc_type'\n  # petsc_options_value = 'asm      lu          '\n\n  # petsc_options_iname = '-pc_type -sub_pc_type -pc_hypre_type'\n  # petsc_options_value = 'asm      hypre        boomeramg     '\n\n  # petsc_options_iname = '-pc_type -pc_hypre_type'\n  # petsc_options_value = 'hypre euclid'\n\n  # petsc_options_iname = '-pc_type -pc_factor_mat_solver_package'\n  # petsc_options_value = 'lu       mumps'\n\n  # petsc_options_iname = '-pc_type -pc_hypre_type -pc_hypre_boomeramg_strong_threshold -pc_hypre_boomeramg_interp_type -pc_hypre_boomeramg_truncfactor'\n  # petsc_options_value = 'hypre    boomeramg      0.7                                    ext+i                           0.2                            '\n\n  # petsc_options_iname = '-pc_type -pc_hypre_type -pc_hypre_boomeramg_strong_threshold -pc_hypre_boomeramg_agg_nl -pc_hypre_boomeramg_agg_num_paths -pc_hypre_boomeramg_max_levels -pc_hypre_boomeramg_coarsen_type -pc_hypre_boomeramg_interp_type -pc_hypre_boomeramg_P_max -pc_hypre_boomeramg_truncfactor'\n  # petsc_options_value = 'hypre    boomeramg      0.7                                  3                          4                                  25                            HMIS                             ext+i                           2                         0.3                            '\n\n  line_search = 'none'\n\n  nl_rel_tol = 1e-8\n  nl_abs_tol = 1e-8\n\n  nl_max_its = 30\n  l_max_its = 100\n  automatic_scaling = true\n  compute_scaling_once = false\n  off_diagonals_in_auto_scaling = true\n[]\n\nThese preconditioners look different, but they have one thing in common - the convergence is far less than -pc_type lu. \ud83e\udd21\nThat's all I understand about preconditioner right now. lu is the most convergent preconditioner because it is a direct solution method. But I saw on the website that LU is serial only. So is it that when I set -pc_type lu directly in the Executioner block, even though I use mpiexec -n 8 for the calculation, the computer is solving the problem serially. If I want to solve the problem with LU in parallel, I have to set -pc_type asm -sub_pc_type lu? Then I tried -pc_type asm -sub_pc_type lu, but the convergence is far worse than -pc_type lu, can you tell me what is the reason?\nFrom reading the moose-users group, the petsc manual and the information on the website I know that ilu is an incomplete lu, it has worse convergence than lu but is more memory efficient. As for the hypre boomramg, I tried a few settings, but none of them converged. Can you give me some advice on what to try next?",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3951770",
                          "updatedAt": "2022-10-24T14:39:47Z",
                          "publishedAt": "2022-10-24T14:39:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "A few things you could try:\n\nuse different solver packages for LU. Some perform better than others, some are parallel.\ntry a segregated physics setup using MultiApps. Solve the fluids and the thermo-mechanical problem in two different apps and use transfers to couple them",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3951994",
                          "updatedAt": "2022-10-24T14:55:58Z",
                          "publishedAt": "2022-10-24T14:55:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "js-jixu"
                          },
                          "bodyText": "use different solver packages for LU. Some perform better than others, some are parallel.\n\nSuch as mumps for LU? Is there any other solver package for LU?",
                          "url": "https://github.com/idaholab/moose/discussions/22468#discussioncomment-3952047",
                          "updatedAt": "2022-10-24T15:00:37Z",
                          "publishedAt": "2022-10-24T15:00:37Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "[Porousflow] PorousFlowSink is independent to time for some reason",
          "author": {
            "login": "Traiwit"
          },
          "bodyText": "Hi guys,\nso my PorousFlowSink is independent to time for some reason\n[rainfall_recharge]\n   type = PorousFlowSink\n    boundary = 'left'\n    variable = porepressure\n    flux_function = -1\n     save_in = fluxes_out\n[]\n\nI check the total flux via NodalSum\n  [left_flux]\n    type = NodalSum\n    boundary = 'left'\n    variable = fluxes_out\n    execute_on = 'timestep_end'\n  []\n\nhere are my [Executioner] and [PorousFlowUnsaturated] blocks:\n[PorousFlowUnsaturated]\nporepressure = porepressure\ncoupling_type = Hydro\ngravity = '0 0 -9.81'\nfp = the_simple_fluid\ntime_unit = years\nadd_darcy_aux = false\n[]\n\n[Executioner]\ntype = Transient\nstart_time = 0\ndt = 0.001\nend_time = 0.01\nsolve_type = NEWTON\npetsc_options = '-snes_converged_reason'\npetsc_options_iname = '-pc_type -pc_hypre_type'\npetsc_options_value = 'hypre    boomeramg'\nnl_rel_tol = 1e-3\nnl_abs_tol = 8e0\nl_tol = 1e-5\nl_max_its = 150\nnl_max_its = 50\nline_search = none\nautomatic_scaling = true\n[]\n\nthe surface area of the 'left' boundary is 350 m2\nfrom the document flux_function of the PorousFlowSink is in kg.m-2.s-1\nAs can be seen above, my time unit is 'year' and dt is 0.001\nHOWEVER, the Nodalsum still gives me 350 kg which is the case for time unit = sec and dt = 1\nand doesn't matter what the dt is, it still gives me the same value\nPostprocessor Values:\n+----------------+----------------+\n| time           | left_flux      |\n+----------------+----------------+\n|   0.000000e+00 |   0.000000e+00 |\n|   1.000000e-03 |  -3.500000e+02 |\n|   2.000000e-03 |  -3.500000e+02 |\n|   3.000000e-03 |  -3.500000e+02 |\n|   4.000000e-03 |  -3.500000e+02 |\n|   5.000000e-03 |  -3.500000e+02 |\n|   6.000000e-03 |  -3.500000e+02 |\n|   7.000000e-03 |  -3.500000e+02 |\n|   8.000000e-03 |  -3.500000e+02 |\n|   9.000000e-03 |  -3.500000e+02 |\n|   1.000000e-02 |  -3.500000e+02 |\n+----------------+----------------+\nNot sure if I've missed anything, if you have an idea please let me know.\nThank you!\nTraiwit",
          "url": "https://github.com/idaholab/moose/discussions/22645",
          "updatedAt": "2022-11-11T04:24:53Z",
          "publishedAt": "2022-11-10T01:37:50Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "Traiwit"
                  },
                  "bodyText": "The same thing also happens when I checked with\n/modules/porous_flow/examples/groundwater/ex02_steady_state.i\nNot sure if NodalSum does not read the flux properly or if something is wrong with the BC",
                  "url": "https://github.com/idaholab/moose/discussions/22645#discussioncomment-4103822",
                  "updatedAt": "2022-11-10T04:28:56Z",
                  "publishedAt": "2022-11-10T04:28:55Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "Hi @Traiwit ,\nHave a look at https://mooseframework.inl.gov/modules/porous_flow/boundaries.html .   You'll see the NodalSum is measured in kg/s.   In your case, it will be kg/year - see the \"Alternative time units\" section of https://mooseframework.inl.gov/source/materials/PorousFlowSingleComponentFluid.html , viz \"fluid sources must be measured in kg/m3/time\" (and areal sources in kg/m2/time , but i didn't write that in the doco, ooops).",
                  "url": "https://github.com/idaholab/moose/discussions/22645#discussioncomment-4106031",
                  "updatedAt": "2022-11-10T10:10:19Z",
                  "publishedAt": "2022-11-10T10:10:18Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Traiwit"
                          },
                          "bodyText": "Noted, thanks @WilkAndy\nI thought NodalSum would sum to mass (or volume) that passes thru the boundary at a particular time.\njust wondering is there any object that can do that kinda thing?",
                          "url": "https://github.com/idaholab/moose/discussions/22645#discussioncomment-4112400",
                          "updatedAt": "2022-11-10T23:52:09Z",
                          "publishedAt": "2022-11-10T23:52:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "WilkAndy"
                          },
                          "bodyText": "Not that i know of, @Traiwit .   I usually use a Postprocessor to capture \"dt\", and then a ParsedAux to multiply by it in order to get the mass flowing through the boundary for a particular time step",
                          "url": "https://github.com/idaholab/moose/discussions/22645#discussioncomment-4113755",
                          "updatedAt": "2022-11-11T04:24:53Z",
                          "publishedAt": "2022-11-11T04:24:52Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "The distribution within an element for a 1 D transport problem",
          "author": {
            "login": "hhy2022"
          },
          "bodyText": "I am trying to solve for a 1 D transport problem. I got the result and found that there was a distribution inside a single element. I am a little confused about that.\nThe problem definition was like this: A species transported from the left to right. It was driven by the velocity. I had a left and right boundary condition given the amount of the species and would like to know the amount distribution along the domain. The geometry was 5 cm with 10 elements.\nI could compile my application and get the result. The question was, there was a distribution inside a single element. But I thought it should be a unifrom distribution inside a single element and the changes should only located between elements since each element should be regared as a \"unit\" one.\nI am trying to find out a explanation on this. MOOSE is computing the kernel at quadrature points. But I think this is not going to cause any difference inside the element.\nAny help are appreciated.\nYang",
          "url": "https://github.com/idaholab/moose/discussions/22621",
          "updatedAt": "2022-11-15T20:08:56Z",
          "publishedAt": "2022-11-08T11:06:10Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nWhat kind of variables are you using?\nThe default variable type is 1st order lagrange, which is linear across each element\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22621#discussioncomment-4086666",
                  "updatedAt": "2022-11-08T13:16:19Z",
                  "publishedAt": "2022-11-08T13:16:19Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "hhy2022"
                          },
                          "bodyText": "I didn't specify the variable type. When I defined the variable, I just gave the name.\nSo my variable is 1st order lagrange, right? Does this mean the shape functions are first order?\nBeside, how the result for one single element was comupted? Is there any functions or kernels that I can use to compute the relationship between the species ammout with the x axis?",
                          "url": "https://github.com/idaholab/moose/discussions/22621#discussioncomment-4091096",
                          "updatedAt": "2022-11-08T21:40:28Z",
                          "publishedAt": "2022-11-08T21:40:27Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "yes then it is the default, and the shape functions are first order.\nThe solution is defined continuously over the domain. If you want the average over a single element you ll have to project it to a CONSTANT MONOMIAL using a SelfAux",
                          "url": "https://github.com/idaholab/moose/discussions/22621#discussioncomment-4091194",
                          "updatedAt": "2022-11-08T21:57:18Z",
                          "publishedAt": "2022-11-08T21:57:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hhy2022"
                          },
                          "bodyText": "OK. Thank you very much for your help.\nBesides, is there any syntax specified the number of quadrature points? What is the relationship between the qp point result and the result for one element?",
                          "url": "https://github.com/idaholab/moose/discussions/22621#discussioncomment-4091511",
                          "updatedAt": "2022-11-08T22:50:44Z",
                          "publishedAt": "2022-11-08T22:50:43Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "There is the quadrature block under the executioner.\nhttps://mooseframework.inl.gov/source/actions/SetupQuadratureAction.html\nThe qp value can be computed from the nodal values and vice-versa. We output and store nodal values, computations like the residuals use the qp values",
                          "url": "https://github.com/idaholab/moose/discussions/22621#discussioncomment-4091566",
                          "updatedAt": "2022-11-08T22:59:01Z",
                          "publishedAt": "2022-11-08T22:59:01Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hhy2022"
                          },
                          "bodyText": "Then what is the relationship between nodal and element? For a 1 D problem, if I had 10 elements, does it mean I had 11 nodes? If qp can be computed by nodal values, then there would be 11 qp values?",
                          "url": "https://github.com/idaholab/moose/discussions/22621#discussioncomment-4092470",
                          "updatedAt": "2022-11-09T02:09:43Z",
                          "publishedAt": "2022-11-09T02:09:43Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "10 elements -> 11 nodes but for the Qps it will depend on the quadrature order",
                          "url": "https://github.com/idaholab/moose/discussions/22621#discussioncomment-4092538",
                          "updatedAt": "2022-11-09T02:24:26Z",
                          "publishedAt": "2022-11-09T02:24:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hhy2022"
                          },
                          "bodyText": "I see. So the Qp only relevant to the quadrature order, right? I mean, if I defined the order of my variable, then the qps for each element will be decided. Is it correct? Or is there another function to specify the qp.",
                          "url": "https://github.com/idaholab/moose/discussions/22621#discussioncomment-4092675",
                          "updatedAt": "2022-11-09T02:50:05Z",
                          "publishedAt": "2022-11-09T02:50:04Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "no the variable order and the quadrature order are different.\nthe quadrature may be changed in Executioner/quadrature.\nIt is also adjusted by default to be able to integrate the variable family types used",
                          "url": "https://github.com/idaholab/moose/discussions/22621#discussioncomment-4092689",
                          "updatedAt": "2022-11-09T02:53:17Z",
                          "publishedAt": "2022-11-09T02:53:17Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hhy2022"
                          },
                          "bodyText": "Usually we don't need to define the qp right? Or it is defined by the variable family? Are they relevant to the geometry/mesh ?\nSorry I am kind of confused about this part. Especially when I got a result plot in peacock with colorbar. I am curious on how these values are computed.",
                          "url": "https://github.com/idaholab/moose/discussions/22621#discussioncomment-4092820",
                          "updatedAt": "2022-11-09T03:28:49Z",
                          "publishedAt": "2022-11-09T03:28:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "The Qps, and their weight, are defined by the quadrature.\nWhat you are seeing in paraview are the nodal value, and paraview knows to draw them continuously for point data",
                          "url": "https://github.com/idaholab/moose/discussions/22621#discussioncomment-4097149",
                          "updatedAt": "2022-11-09T13:35:25Z",
                          "publishedAt": "2022-11-09T13:35:25Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Compilation with libtorch",
          "author": {
            "login": "aiskhak"
          },
          "bodyText": "I would like to use libtorch capabilities within MOOSE.\nI am using linux machine and followed the installation instructions for HPC:\nhttps://mooseframework.inl.gov/getting_started/installation/hpc_install_moose.html\nThen I installed libtorch:\nhttps://mooseframework.inl.gov/getting_started/installation/install_libtorch.html\nI am able to execute tests:\n./run_tests -j 8 --re libtorch_nn\nHowever, when I create a custom app and enable in the Makefile the Stochastic Tools module:\nSTOCHASTIC_TOOLS := yes\nit kind of does not see the module and as a result, stochastic tools do not work.\nSO in general the problem is that the custom app does not see individal modules, while\nALL_MODULES := yes\nworks. How to fix this?",
          "url": "https://github.com/idaholab/moose/discussions/22631",
          "updatedAt": "2022-11-10T21:24:06Z",
          "publishedAt": "2022-11-08T19:59:14Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@grmnptr",
                  "url": "https://github.com/idaholab/moose/discussions/22631#discussioncomment-4090604",
                  "updatedAt": "2022-11-08T20:25:53Z",
                  "publishedAt": "2022-11-08T20:25:52Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "grmnptr"
                  },
                  "bodyText": "Could you write here down step by step what you are doing? I mean during the installation of the custom app.",
                  "url": "https://github.com/idaholab/moose/discussions/22631#discussioncomment-4092179",
                  "updatedAt": "2022-11-09T01:14:07Z",
                  "publishedAt": "2022-11-09T01:14:06Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aiskhak"
                          },
                          "bodyText": "sorry, the problem was is that I did not understand the meaning of:\nifeq ($(ENABLE_LIBTORCH),true)\napp_non_unity_dirs = %src/surrogates\nendif",
                          "url": "https://github.com/idaholab/moose/discussions/22631#discussioncomment-4111586",
                          "updatedAt": "2022-11-10T21:24:00Z",
                          "publishedAt": "2022-11-10T21:23:59Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Change mesh from one simulation to another",
          "author": {
            "login": "krb-nantes"
          },
          "bodyText": "Hi everybody!\nI need to simulate a Zry cladding oxide spallation, making the oxide grow before spalling. So, I planned to first do the oxide growth on a whole block until the desired thickness and then, make a second simulation where I would remove part of this block (this would be the spalled part), but I wanted to use some data from the first simulation, as the temperature profile, by setting the \"restar_file_base\" on [Problem] block, however, I receive an error doing this, I must use the same mesh for both.\nSo, is there a way that I can make modifications in the mesh on the second simulation and use the data from the first one?",
          "url": "https://github.com/idaholab/moose/discussions/22638",
          "updatedAt": "2022-11-15T20:08:41Z",
          "publishedAt": "2022-11-09T16:26:36Z",
          "category": {
            "name": "Q&A Meshing"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nYou ll want to use the SolutionUserObject to do that.\nAlternatively you can load the other mesh in a MultiApp and transfer information from there\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/22638#discussioncomment-4099126",
                  "updatedAt": "2022-11-09T16:54:12Z",
                  "publishedAt": "2022-11-09T16:54:11Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "krb-nantes"
                          },
                          "bodyText": "I was able to load the variable values and use as IC for the second simulation, however I could not retrieve the oxide thickness, because it is set as AuxVariable, and I cannot set IC for AuxVariable.",
                          "url": "https://github.com/idaholab/moose/discussions/22638#discussioncomment-4110449",
                          "updatedAt": "2022-11-10T18:51:10Z",
                          "publishedAt": "2022-11-10T18:51:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "use an auxkernel executed on INITIAL for an IC of an AuxVariable",
                          "url": "https://github.com/idaholab/moose/discussions/22638#discussioncomment-4110487",
                          "updatedAt": "2022-11-10T18:56:19Z",
                          "publishedAt": "2022-11-10T18:56:18Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Implementing user-defined Permeability Material in PorousFlow",
          "author": {
            "login": "thewhitewalker10"
          },
          "bodyText": "Hello,\nI\u2019m following the layout of Kozeny-Carman permeability material in PorousFlow to develop my own permeability material. I\u2019m kinda stuck on how the Jacobian/derivative of the K-C material was derived w.r.t to the Variables (i.e., _dpermeability_qp_dvar[_qp][v]). Can someone pls walk me through it? Btw, is there a way to add these derivatives automatically or you need to manually compute and implement these derivatives? My permeability model is not dependent on the porosity, but on the strain as follows:\nk=k_m*I + b/a [(b^2/12 - k_m)] (I-M), where b=b_0 + /Deltab and /Deltab=a \u2329/epsilon_n -/epsilon_0\u232a.\nI already derived the derivative of k with respect to the strain (/epsilon) but I\u2019m not sure if I need to compute and implement the derivative of k with respect to porosity. Thanks.",
          "url": "https://github.com/idaholab/moose/discussions/22626",
          "updatedAt": "2022-11-15T20:07:00Z",
          "publishedAt": "2022-11-08T16:18:05Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "thewhitewalker10"
                  },
                  "bodyText": "Hi, @cpgr and @WilkAndy\nI\u2019m trying to implement the permeability model described on page 6 of Zill et al. (https://doi.org/10.1016/j.ijrmms.2021.104879). I\u2019m following the layout of PorousFlowPermeabilityKozenyCarman. Is this the right approach to implement a user-defined permeability in PorousFlow? or do I have to follow the layout of PorousFlowPorosityLinear since my permeability does not depend on porosity? I got stuck with computing the derivatives while following PorousFlowPermeabilityKozenyCarman. If I have to go with the PorousFlowPermeabilityKozenyCarman, do I need to find the derivative wrt porosity or the strain? Thanks.",
                  "url": "https://github.com/idaholab/moose/discussions/22626#discussioncomment-4091122",
                  "updatedAt": "2022-11-08T21:45:00Z",
                  "publishedAt": "2022-11-08T21:45:00Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "cpgr"
                          },
                          "bodyText": "If permeability doesn't depend on porosity, then the simpler option of following PorousFlowPorosityLinear should be ok (ie you get the strain and it's derivatives as material properties, and use them when calculating your permeability.\nPorousFlow isn't set up to make full use of AD yet, so this would need to be by hand.",
                          "url": "https://github.com/idaholab/moose/discussions/22626#discussioncomment-4092802",
                          "updatedAt": "2022-11-09T03:24:15Z",
                          "publishedAt": "2022-11-09T03:24:14Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "thewhitewalker10"
                          },
                          "bodyText": "Thanks, @cpgr.\nJust a couple of questions: What material provides the derivatives of the porosity (i.e.,_dporosity_qp_dvar and _dporosity_qp_dgradvar ) on lines 66 and 67 of PorousFlowPermeabilityKozenyCarman? I\u2019m guessing that I can use the following derivatives for the strain in my implementation: _dvol_strain_qp_dvar and _dvol_strain_qp_dgradvar. Correct?\nWhy were _dpermeability_qp_dvar[_qp][v] and _dpermeability_qp_dgradvar[_qp][i][v] calculated on lines 100 and 106 in the PorousFlowPermeabilityKozenyCarman permeability model? I\u2019m trying to implement _dpermeability_qp_dgradvar[_qp][i][v] in my own model, but I can\u2019t find _dvol_strain_qp_dgradvar in any of the source or header files in PorousFlow. How do I obtain _dvol_strain_qp_dgradvar? Thanks.",
                          "url": "https://github.com/idaholab/moose/discussions/22626#discussioncomment-4093164",
                          "updatedAt": "2022-11-09T04:56:26Z",
                          "publishedAt": "2022-11-09T04:56:26Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "This \"answer\" just collects a variety of my thoughts - hopefully one might be useful.\n\nYour formula for permeability (Zill et al) means that it depends on strain in the normal direction to the fracture.  This is a little different than the other perm formulations, which assume that permeability depends on volumetric strain.  When creating PorousFlow initially, we considered the idea of allowing Material properties to be functions of arbitrary derivatives of variables, but rejected the idea as being too costly, both in memory and compute (almost every model would repeatedly just compute a bunch of zeroes for the derivatives).\nThis is possibly the most obscure and complicated part of PorousFlow, sorry, because the derivatives are a bit mind-bending\nYou do not need to calculate the derivatives for PorousFlow to work.  If you don't, they will be assumed to be zero and you will get an inexact Jacobian and poorer convergence, BUT maybe that doesn't really matter in your case.\nIf you look at \n  \n    \n      moose/modules/porous_flow/include/materials/PorousFlowVolumetricStrain.h\n    \n    \n        Lines 57 to 62\n      in\n      ecb6d9c\n    \n  \n  \n    \n\n        \n          \n             /** \n        \n\n        \n          \n              * The derivative of the total volumetric strain with respect to the porous flow variables. \n        \n\n        \n          \n              * Since the total volumetric strain depends on derivatives of the displacement variables, \n        \n\n        \n          \n              * this should be multiplied by _grad_phi in kernels \n        \n\n        \n          \n              */ \n        \n\n        \n          \n             MaterialProperty<std::vector<RealGradient>> & _dvol_total_strain_qp_dvar; \n        \n    \n  \n\n  and \n  \n    \n      moose/modules/porous_flow/src/materials/PorousFlowVolumetricStrain.C\n    \n    \n        Lines 47 to 48\n      in\n      ecb6d9c\n    \n  \n  \n    \n\n        \n          \n           _dvol_total_strain_qp_dvar( \n        \n\n        \n          \n               declareProperty<std::vector<RealGradient>>(\"dPorousFlow_total_volumetric_strain_qp_dvar\")) \n        \n    \n  \n\n  and the code for calculating this object \n  \n    \n      moose/modules/porous_flow/src/materials/PorousFlowVolumetricStrain.C\n    \n    \n        Lines 71 to 79\n      in\n      ecb6d9c\n    \n  \n  \n    \n\n        \n          \n           _dvol_total_strain_qp_dvar[_qp].resize(_num_var, RealGradient()); \n        \n\n        \n          \n           for (unsigned i = 0; i < _ndisp; ++i) \n        \n\n        \n          \n             if (_dictator.isPorousFlowVariable(_disp_var_num[i])) \n        \n\n        \n          \n             { \n        \n\n        \n          \n               // the i_th displacement is a PorousFlow variable \n        \n\n        \n          \n               const unsigned int pvar = _dictator.porousFlowVariableNum(_disp_var_num[i]); \n        \n\n        \n          \n               _dvol_strain_rate_qp_dvar[_qp][pvar](i) = 1.0 / _dt; \n        \n\n        \n          \n               _dvol_total_strain_qp_dvar[_qp][pvar](i) = 1.0; \n        \n\n        \n          \n             } \n        \n    \n  \n\n  you'll see that the Material Property called dPorousFlow_total_volumetric_strain_qp_dvar , is \"d(volumetric strain) / d(displacement)\".   I write this in quotes because it's not strictly notationally correct (and that's why the object is a std::vector<RealGradient> not just a Real)   To understand further, and understand why this dPorousFlow_total_volumetric_strain_qp_dvar is needed, imagine a Kernel that is exactly residual = volumetric_strain.  Then, a Jacobian entry is d(residual) / d(displacement_j) = 1 * grad_j (shape function) .   If you don't understand this, please ask, as this is the key point.   The \"1\" in the previous formula is a real number (1) and is exactly a component of dPorousFlow_total_volumetric_strain_qp_dvar.  More generally, imagine a Kernel that is residual = f(volumetric_strain).  Then, a Jacobian entry is d(residual) / d(displacement_j) = sum_over_i f'(volumetric_strain) * dPorousFlow_total_volumetric_strain_qp_dvar(j, i) grad_i (shape function).   In MOOSE language, the \"j\" is the std::vector part, and the \"i\" is the RealGradient, and grad_i (shape function) is grad_phi.\nProbably the above will explain why there is no _dvol_strain_qp_dgradvar.  The Material called dPorousFlow_total_volumetric_strain_qp_dvar` is closest to what you want.\nIf you look at \n  \n    \n      moose/modules/porous_flow/include/materials/PorousFlowPermeabilityBase.h\n    \n    \n        Lines 28 to 32\n      in\n      ecb6d9c\n    \n  \n  \n    \n\n        \n          \n           /// d(quadpoint permeability)/d(PorousFlow variable) \n        \n\n        \n          \n           MaterialProperty<std::vector<RealTensorValue>> & _dpermeability_qp_dvar; \n        \n\n        \n          \n            \n        \n\n        \n          \n           /// d(quadpoint permeability)/d(grad(PorousFlow variable)) \n        \n\n        \n          \n           MaterialProperty<std::vector<std::vector<RealTensorValue>>> & _dpermeability_qp_dgradvar; \n        \n    \n  \n\n you'll see the definition d(perm)/d(var) and d(perm)/d(gradvar).  Consider the case that kernel = perm, so Jacobian = d(perm)/d(var) * phi + d(perm)/d(gradvar) * grad_phi.  Hopefully this makes sense: the key is, we need derivatives of Materials with respect to variables, and the gradients of variables, because we need to know whether the Jacobian entries should be multiplied by phi or grad_phi.",
                  "url": "https://github.com/idaholab/moose/discussions/22626#discussioncomment-4101619",
                  "updatedAt": "2022-11-09T21:55:23Z",
                  "publishedAt": "2022-11-09T21:55:22Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "thewhitewalker10"
                          },
                          "bodyText": "Thanks, @WilkAndy\nFrom your feedback, I don\u2019t need the derivatives after all. I\u2019m going to go ahead and implement the permeability following PorousFlowPermeabilityKozenyCarman w/o them. Please, keep this ticket open for now, as I need to sit down on your feedback to grasp it fully. I\u2019m going to be chipping in some questions from time to time. Thanks a lot guys @WilkAndy @cpgr !",
                          "url": "https://github.com/idaholab/moose/discussions/22626#discussioncomment-4102808",
                          "updatedAt": "2022-11-10T00:56:19Z",
                          "publishedAt": "2022-11-10T00:56:19Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Using source files in tests directory of modules",
          "author": {
            "login": "ttruster"
          },
          "bodyText": "I am working on some module and framework development, and I would like to put the source files in the tests directory rather than the main framework as they are specialized rather than general. In particular, I'm in the Tensor Mechanics Module.\nI have registered the files in TensorMechanicsTestApp like the other files in there. However, when I use either the moose/modules/tensor_mechanics/tensor_mechanics-opt executable or the combined-opt executable, both times I get an error message from running input files:\n*** ERROR ***\nA 'MyTestObject' is not a registered object.\nThe same thing happens when I run the modules/tensor_mechanics/test/tests/domain_integral_thermal/interaction_integral_2d_eig_grad.i input file:\n*** ERROR ***\nA 'FunctionIsotropicEigenstrain' is not a registered object.\nThe Makefile of those codes has the USE_TEST_LIBS     := yes flag. But is there something else I need in order to actually use those compiled objects? For the framework, I know that the moose_test-opt executable does contain the test objects.",
          "url": "https://github.com/idaholab/moose/discussions/22642",
          "updatedAt": "2022-11-09T20:20:29Z",
          "publishedAt": "2022-11-09T18:23:34Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "You ll need to pass --allow-test-object on the command line\nsame in the tests configuration files iirc",
                  "url": "https://github.com/idaholab/moose/discussions/22642#discussioncomment-4100005",
                  "updatedAt": "2022-11-09T18:25:47Z",
                  "publishedAt": "2022-11-09T18:25:47Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "actually no it s the other way, there is a flag to disallow them\n--disallow-test-objects                           Don't register test objects and syntax",
                          "url": "https://github.com/idaholab/moose/discussions/22642#discussioncomment-4100011",
                          "updatedAt": "2022-11-09T18:26:35Z",
                          "publishedAt": "2022-11-09T18:26:34Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}