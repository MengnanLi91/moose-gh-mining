{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMS0wMS0wNlQxMTo0NzoxNi0wNjowMM4AAUgE"
    },
    "edges": [
      {
        "node": {
          "title": "Finite strain simulations with the Maxwell Viscoelastic model",
          "author": {
            "login": "veevee1208"
          },
          "bodyText": "Hello MOOSE team,\nI have been running some finite strain simulations with the viscoelastic Kelvin Voigt model and I do not have any issues with convergence. However, when I try to run the finite strain simulation with the Maxwell model, I seem to run into a convergence issue . I tried using the PJFNK and AD but they seem to be of no effect. I was wondering if someone has experience running viscoelastic models on MOOSE and have any suggestions ? I have attached a copy of my input file.\nAny help will be appreciated.\nBest Regards\nVishal\nMaxwell-finite.txt",
          "url": "https://github.com/idaholab/moose/discussions/16600",
          "updatedAt": "2022-07-14T06:45:54Z",
          "publishedAt": "2020-12-30T20:28:24Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "crswong888"
                  },
                  "bodyText": "Hi @veevee1208, I tried playing around with your input file and I improved a bit the performance, but I think the problem you are having is related to very high strains. Please make sure that all of your units are consistent and that the forces and boundary conditions you're applying are realistic. I changed the axial force in the x-direction from 10e3 to just 10, and at 30 seconds the strain in the x-direction is 380%, which is a really high number for most solid materials (even viscoelastic ones) and leads to poor conditioning in the Jacobian.\nYou might find my version of your input file helpful: github.com/crswong888/scorpion/blob/master/inputs/users/Maxwell-finite.i. It diverges at about 30 seconds though.\nIf you continue to have issues, it may be helpful for me to take a look at the version of your input file for which you had none.",
                  "url": "https://github.com/idaholab/moose/discussions/16600#discussioncomment-275818",
                  "updatedAt": "2023-01-19T21:27:39Z",
                  "publishedAt": "2021-01-12T03:15:33Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Redirect external app std::cout to _console?",
          "author": {
            "login": "aprilnovak"
          },
          "bodyText": "Hi all,\nI'm running an external app (nekRS) through the ExternalProblem interface, and it would be nice to redirect nekRS's std::cout through MOOSE's _console to make the output prettier.\nFor instance, nekRS uses std::cout, which when run as a sub-app, looks like this on my console. Lines 4 and 5 come from nekRS.\nnek0: Time Step 17, time = 0.029, dt = 0.002\nnek0: Sending heat flux to nekRS boundary 1...\nnek0: Normalizing total nekRS flux of 389.376 to the conserved MOOSE value of 386.989...\nstep= 17  t= 2.90000000e-02  dt=2.0e-03  C= 0.05  UVW: 6  P: 201  S: 157  eTime= 6.60e-01, 1.08991e+01 s\ncopying solution to nek\nnek0: Extracting nekRS temperature from boundary 1...\nnek0: Interpolated temperature min/max values on interface: 628.15, 628.952\nnek0:  Solve Converged!\nDoes MOOSE have a capability like this? If this is obvious, my apologies - nothing jumped out at me on _console!\nThanks!\n-April",
          "url": "https://github.com/idaholab/moose/discussions/16647",
          "updatedAt": "2022-06-02T14:54:56Z",
          "publishedAt": "2021-01-08T21:11:17Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "aeslaughter"
                  },
                  "bodyText": "I don't know how that could be done. @permcody do you know if this would be possible?",
                  "url": "https://github.com/idaholab/moose/discussions/16647#discussioncomment-270226",
                  "updatedAt": "2022-06-02T14:55:16Z",
                  "publishedAt": "2021-01-08T21:29:34Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "permcody"
                          },
                          "bodyText": "To the best of my knowledge a simple redirect definitely isn't possible. The _console is a C++ object that manages it's own stream. It may be possible to share the underlying stream but even that would take a bit of gymnastics.\nI think a better idea would be to add a new API (extern C linkage) that developers of other applications could call that would invoke the MOOSE console object. This would be fairly trivial to implement and would automatically give you the coloring, indentation, and input file based control we are accustomed to. The big disadvantage is that this would be very disruptive for applications that have output spread all over through their application as it would require them to go through their application and update everything. Worse yet, you'd have to have make this a macro to handle the cases when you are wrapped in MOOSE or not.\nAgain there are ways of sharing file system streams at the OS level, but I'm not sure of a way we could put all of the MOOSE functionality into one of those and share it. It may be doable, but we'd need to build a demo project to try a few things out.",
                          "url": "https://github.com/idaholab/moose/discussions/16647#discussioncomment-274706",
                          "updatedAt": "2022-06-02T14:55:20Z",
                          "publishedAt": "2021-01-11T15:58:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aprilnovak"
                          },
                          "bodyText": "Thanks for explaining everything! Unfortunately, nekRS has cout scattered over the entire project, so I agree that this would be pretty tricky to implement. And the nekRS devs are pretty against having any trace of \"MOOSE\" things in their project from a modularization perspective, understandably.\nThis was just something I thought would be nice for formatting, so this is very low priority anyways. Just wanted to check that that feature didn't exist yet!\nThanks!",
                          "url": "https://github.com/idaholab/moose/discussions/16647#discussioncomment-275573",
                          "updatedAt": "2022-06-02T14:55:23Z",
                          "publishedAt": "2021-01-11T23:09:09Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Solve failure with no information",
          "author": {
            "login": "dcolema4"
          },
          "bodyText": "My solve fails after multiple time steps without producing any error messages. The solution fails on the second nonlinear iteration. Here is the output using '-snes_converged_reason -ksp_converged_reason -ksp_monitor_true_residual -ksp_view':\nPerforming automatic scaling calculation\n0 Nonlinear |R| = [32m6.158493e+01[39m\n|residual|2 of individual variables:\ntemperature:     61.5849\nbinder_fraction: 0.00398115\n0 Linear |R| = [32m6.158493e+01[39m\n0 KSP unpreconditioned resid norm 6.158493137943e+01 true resid norm 6.158493137943e+01 ||r(i)||/||b|| 1.000000000000e+00\n1 Linear |R| = [32m1.528537e-02[39m\n1 KSP unpreconditioned resid norm 1.528537014084e-02 true resid norm 1.528537014084e-02 ||r(i)||/||b|| 2.481998404230e-04\n2 Linear |R| = [32m2.259913e-05[39m\n2 KSP unpreconditioned resid norm 2.259913355890e-05 true resid norm 2.185523824273e-04 ||r(i)||/||b|| 3.548796394378e-06\nLinear solve converged due to CONVERGED_RTOL iterations 2\nKSP Object: 1 MPI processes\ntype: fgmres\nrestart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement\nhappy breakdown tolerance 1e-30\nmaximum iterations=20, initial guess is zero\ntolerances:  relative=1e-06, absolute=1e-50, divergence=1e+100\nright preconditioning\nusing UNPRECONDITIONED norm type for convergence test\nPC Object: 1 MPI processes\ntype: bjacobi\nnumber of blocks = 1\nLocal solve is same for all blocks, in the following KSP and PC objects:\nKSP Object: (sub) 1 MPI processes\ntype: preonly\nmaximum iterations=10000, initial guess is zero\ntolerances:  relative=1e-05, absolute=1e-50, divergence=10000.\nleft preconditioning\nusing NONE norm type for convergence test\nPC Object: (sub_) 1 MPI processes\ntype: ilu\nout-of-place factorization\n4 levels of fill\ntolerance for zero pivot 2.22045e-14\nmatrix ordering: natural\nfactor fill ratio given 1., needed 20.6539\nFactored matrix follows:\nMat Object: 1 MPI processes\ntype: seqaij\nrows=6749, cols=6749\npackage used to perform factorization: petsc\ntotal: nonzeros=9791613, allocated nonzeros=9791613\ntotal number of mallocs used during MatSetValues calls=0\nusing I-node routines: found 4137 nodes, limit used is 5\nlinear system matrix = precond matrix:\nMat Object: () 1 MPI processes\ntype: seqaij\nrows=6749, cols=6749\ntotal: nonzeros=474081, allocated nonzeros=474081\ntotal number of mallocs used during MatSetValues calls=0\nnot using I-node routines\nlinear system matrix followed by preconditioner matrix:\nMat Object: 1 MPI processes\ntype: mffd\nrows=6749, cols=6749\nMatrix-free approximation:\nerr=1.49012e-08 (relative error in function evaluation)\nUsing wp compute h routine\nDoes not compute normU\nMat Object: () 1 MPI processes\ntype: seqaij\nrows=6749, cols=6749\ntotal: nonzeros=474081, allocated nonzeros=474081\ntotal number of mallocs used during MatSetValues calls=0\nnot using I-node routines\n1 Nonlinear |R| = [32m7.386756e-01[39m\n|residual|_2 of individual variables:\ntemperature:     0.738676\nbinder_fraction: 0.000231372\n0 Linear |R| = [32m7.386756e-01[39m\n0 KSP unpreconditioned resid norm 7.386756405972e-01 true resid norm 7.386756405972e-01 ||r(i)||/||b|| 1.000000000000e+00\nAfter this line the program exits with the following response on the command line:\napplication called MPI_Abort(MPI_COMM_WORLD, 1) - process 0\n[unset]: write_line error; fd=-1 buf=:cmd=abort exitcode=1\n:\nsystem msg for write_line failure : Bad file descriptor\nI'm not sure how to go about debugging this issue, so any help would be greatly appreciated.\nThanks!\ndusty",
          "url": "https://github.com/idaholab/moose/discussions/16615",
          "updatedAt": "2022-07-01T01:56:03Z",
          "publishedAt": "2021-01-04T15:55:51Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hi Dusty\nCan you run this through a debugger, see moose-debugging ?\nThis will help locate the issue.\nBest,\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-260362",
                  "updatedAt": "2022-07-01T01:56:17Z",
                  "publishedAt": "2021-01-04T16:02:33Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "fdkong"
                  },
                  "bodyText": "Add a breakpoint on MPI_Abort using your favorite debugger",
                  "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-260372",
                  "updatedAt": "2022-07-01T01:56:22Z",
                  "publishedAt": "2021-01-04T16:05:30Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "dcolema4"
                          },
                          "bodyText": "So after adding breakpoints for MPI_Abort and exit I get:\nInferior 1 (process 20352) exited with code 0220\nHowever, no breakpoint seemed to be reached. I'm using gdb to debug but I'm also not very familiar with it's operation.",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-260682",
                          "updatedAt": "2022-07-01T01:56:22Z",
                          "publishedAt": "2021-01-04T17:55:54Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "can you type 'bt' in GDB to get the backtrace",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-260686",
                          "updatedAt": "2022-07-01T01:56:22Z",
                          "publishedAt": "2021-01-04T17:57:00Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dcolema4"
                          },
                          "bodyText": "'bt' results in 'No stack.'",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-260717",
                          "updatedAt": "2022-07-01T01:56:22Z",
                          "publishedAt": "2021-01-04T18:06:08Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "It really should break on MPI_Abort. How did you set the breakpoint? The backtrace would be really helpful",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-260878",
                          "updatedAt": "2023-02-16T16:53:38Z",
                          "publishedAt": "2021-01-04T19:05:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dcolema4"
                          },
                          "bodyText": "I'm running gdb on the debug version of the code. The following shows my gdb inputs:\n(gdb) b MPI_Abort\nFunction \"MPI_Abort\" not defined.\nMake breakpoint pending on future shared library load? (y or [n]) y\nBreakpoint 1 (MPI_Abort) pending.\n(gdb) r",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-260931",
                          "updatedAt": "2023-02-16T16:53:38Z",
                          "publishedAt": "2021-01-04T19:26:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "It's odd that MPI_Abort isn't found. Which MPI distribution are you using?",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-260981",
                          "updatedAt": "2023-02-16T16:53:38Z",
                          "publishedAt": "2021-01-04T19:45:27Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "Are you using moose-mpich (delivered via  conda)?",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-261047",
                          "updatedAt": "2023-02-16T16:53:39Z",
                          "publishedAt": "2021-01-04T20:07:54Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dcolema4"
                          },
                          "bodyText": "I installed MOOSE using the conda environment method so I'm assuming it is using moose-mpich",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-261168",
                          "updatedAt": "2023-02-16T16:53:34Z",
                          "publishedAt": "2021-01-04T20:59:12Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "Is it called PMPI_Abort in that one?",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-261307",
                          "updatedAt": "2023-02-16T16:53:34Z",
                          "publishedAt": "2021-01-04T22:04:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dcolema4"
                          },
                          "bodyText": "With both MPI_Abort and PMPI_Abort I'm getting this output:\nPerforming automatic scaling calculation\n0 Nonlinear |R| = 6.158493e+01\n[Thread 0x7fffeb7b0700 (LWP 23304) exited]\n--Type  for more, q to quit, c to continue without paging--\n[Inferior 1 (process 23255) exited with code 0220]\n(gdb) bt\nNo stack.\n(gdb)",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-261322",
                          "updatedAt": "2023-02-16T16:53:34Z",
                          "publishedAt": "2021-01-04T22:12:49Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "dcolema4"
                  },
                  "bodyText": "gdb --args ../my-app/my-app-dbg -i debug_input.i\nReading symbols from ../my-app/my-app-dbg...\n(gdb) b MPI_Abort\nFunction \"MPI_Abort\" not defined.\nMake breakpoint pending on future shared library load? (y or [n]) y\nBreakpoint 1 (MPI_Abort) pending.\n(gdb) r\nStarting program: /home/colemand/projects/my-app/my-app-dbg -i debug_input.i\nLots of initialization here...\n...........\n0 Nonlinear |R| = 6.158493e+01\n[Thread 0x7fffeb7b0700 (LWP 23304) exited]\n--Type for more, q to quit, c to continue without paging--\n[Inferior 1 (process 23255) exited with code 0220]\n(gdb) bt\nNo stack.\n(gdb)",
                  "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-261341",
                  "updatedAt": "2022-07-01T01:56:22Z",
                  "publishedAt": "2021-01-04T22:25:48Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "dcolema4"
                          },
                          "bodyText": "When I use lldb I don't get the last line you have there. Instead I get:\n(lldb) b MPI_Abort\nBreakpoint 1: no locations (pending).\nWARNING:  Unable to resolve breakpoint to any actual locations.",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-261354",
                          "updatedAt": "2022-07-01T01:56:22Z",
                          "publishedAt": "2021-01-04T22:31:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "@milljm Do you have any thought on this? Did we use \"-g\" when compiling mpich?",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-263694",
                          "updatedAt": "2022-07-01T01:56:22Z",
                          "publishedAt": "2021-01-05T23:20:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "@dcolema4 appears to be running Linux (/home instead of /Users as it would be on the Mac). And is using LLVM compilers (lldb)... which we do not create.\nSo no... I have no idea how mpich was created on this machine. Conda will not give you LLVM compilers when installing moose-libmesh, moose-petsc, etc on Linux machines.\nThis would appear to be a custom build at first glance (unless your use of /home was a typo).",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-264910",
                          "updatedAt": "2022-07-01T01:56:22Z",
                          "publishedAt": "2021-01-06T14:54:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dcolema4"
                          },
                          "bodyText": "I'm using Ubuntu on WSL and originally went through the conda environment installation. Looking again I see there I may not have executed the hostname change on my Windows side. Perhaps that's the issue?",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-264991",
                          "updatedAt": "2022-08-02T15:21:11Z",
                          "publishedAt": "2021-01-06T15:23:46Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "Looking again, I see you are also using gdb (GCC). That and you mentioning conda, probably means you are using conda :)\nI don't think -g is being thrown when building moose-mpich. But I am not 100% sure. I'll have to dig in and watch a build of that package to know for sure.\nI don't know what -g actually does...",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-265008",
                          "updatedAt": "2022-08-02T15:21:11Z",
                          "publishedAt": "2021-01-06T15:29:59Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "friedmud"
                  },
                  "bodyText": "My guess here is is that you have crossed up your MPI installations somehow (i.e. you are compiling/linking against one MPI and running with a different one).  Can you describe what your installation process was like?",
                  "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-265017",
                  "updatedAt": "2022-07-01T01:56:22Z",
                  "publishedAt": "2021-01-06T15:33:41Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "dcolema4"
                          },
                          "bodyText": "I followed the process listed here: https://mooseframework.inl.gov/getting_started/installation/conda.html\nHowever, I did miss the WSL info.",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-265029",
                          "updatedAt": "2022-07-01T01:56:22Z",
                          "publishedAt": "2021-01-06T15:38:30Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "friedmud"
                          },
                          "bodyText": "Did you already have some other MPI installed on your system?\nAny chance you could start \"clean\" and make another attempt at it?",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-265312",
                          "updatedAt": "2022-07-01T01:56:22Z",
                          "publishedAt": "2021-01-06T17:48:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dcolema4"
                          },
                          "bodyText": "Not that I'm aware of. I'm starting a clean install now.",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-265340",
                          "updatedAt": "2022-07-01T01:56:22Z",
                          "publishedAt": "2021-01-06T18:01:25Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dcolema4"
                          },
                          "bodyText": "After doing a clean install I'm trying to run the test shown by @fdkong above. It appears that the mpi library isn't being found.\n(moose) colemand@L2006040A:/projects/moose/test/tests/kernels/2d_diffusion$ gdb --args ../../../moose_test-dbg -i 2d_diffusion_test.i\nGNU gdb (Ubuntu 9.2-0ubuntu120.04) 9.2\nCopyright (C) 2020 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later http://gnu.org/licenses/gpl.html\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\nType \"show copying\" and \"show warranty\" for details.\nThis GDB was configured as \"x86_64-linux-gnu\".\nType \"show configuration\" for configuration details.\nFor bug reporting instructions, please see:\nhttp://www.gnu.org/software/gdb/bugs/.\nFind the GDB manual and other documentation resources online at:\nhttp://www.gnu.org/software/gdb/documentation/.\nFor help, type \"help\".\nType \"apropos word\" to search for commands related to \"word\"...\nReading symbols from ../../../moose_test-dbg...\n(gdb) b MPI_Abort\nFunction \"MPI_Abort\" not defined.\nMake breakpoint pending on future shared library load? (y or [n]) y\nBreakpoint 1 (MPI_Abort) pending.\n(gdb)",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-267481",
                          "updatedAt": "2022-08-02T15:21:15Z",
                          "publishedAt": "2021-01-07T17:17:47Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "friedmud"
                          },
                          "bodyText": "That's ok - the MPI_Abort may not be loaded yet at the beginning - are you still getting similar errors to what you were?",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-267553",
                          "updatedAt": "2022-08-02T15:21:18Z",
                          "publishedAt": "2021-01-07T17:58:50Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dcolema4"
                          },
                          "bodyText": "I am. When I run the debugger on my input file it gets to the end of the first nonlinear iteration to show:\n0 Nonlinear |R| = 6.158493e+01\n[Thread 0x7fffeb7b0700 (LWP 23304) exited]\n--Type for more, q to quit, c to continue without paging--\nThen no matter what I type it exits out showing:\n[Inferior 1 (process 23255) exited with code 0220]\n(gdb)\nI'm kind of at a loss for what to do.",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-267571",
                          "updatedAt": "2022-08-02T15:21:18Z",
                          "publishedAt": "2021-01-07T18:10:04Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "friedmud"
                          },
                          "bodyText": "That is absolutely bizarre.  To be able to make it that far and then go wrong is just odd.\nI literally can't think of anything that would cause that.\n@milljm I'm punting - any other ideas?",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-267826",
                          "updatedAt": "2022-08-02T15:21:18Z",
                          "publishedAt": "2021-01-07T20:49:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "I am going to try and debug that same problem on my windows WSL... just gotta build in debug mode on my little 8 core machine :)\nI'll post when I am able/done. The only thing that comes to mind, is if the Windows host file is not configured to use MPI. But @dcolema4 mentioned they saw that step later on, so... I figure that was completed.",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-269385",
                          "updatedAt": "2022-08-02T15:21:19Z",
                          "publishedAt": "2021-01-08T15:18:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "Here are my results:\nmilljm@DESKTOP-M0OU23R:~/projects/moose/test/tests/kernels/simple_diffusion$ gdb --args ../../../moose_test-dbg -i simple_diffusion.i\nGNU gdb (GDB) 9.2\nCopyright (C) 2020 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\nType \"show copying\" and \"show warranty\" for details.\nThis GDB was configured as \"x86_64-conda-linux-gnu\".\nType \"show configuration\" for configuration details.\nFor bug reporting instructions, please see:\n<http://www.gnu.org/software/gdb/bugs/>.\nFind the GDB manual and other documentation resources online at:\n    <http://www.gnu.org/software/gdb/documentation/>.\n\nFor help, type \"help\".\nType \"apropos word\" to search for commands related to \"word\"...\nReading symbols from ../../../moose_test-dbg...\n(gdb) b MPI_ABORT\nFunction \"MPI_ABORT\" not defined.\nMake breakpoint pending on future shared library load? (y or [n]) y\nBreakpoint 1 (MPI_ABORT) pending.\n(gdb) r\nStarting program: /home/milljm/projects/moose/test/moose_test-dbg -i simple_diffusion.i\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n\n[New Thread 0x7f0875f20700 (LWP 373)]\n[Thread 0x7f0875f20700 (LWP 373) exited]\n[New Thread 0x7f0875f20700 (LWP 374)]\n[Thread 0x7f0875f20700 (LWP 374) exited]\n[New Thread 0x7f0875f20700 (LWP 375)]\n[Thread 0x7f0875f20700 (LWP 375) exited]\n[New Thread 0x7f0875f20700 (LWP 376)]\n[Thread 0x7f0875f20700 (LWP 376) exited]\n[New Thread 0x7f0875f20700 (LWP 377)]\n[Thread 0x7f0875f20700 (LWP 377) exited]\n[New Thread 0x7f0875f20700 (LWP 378)]\n[Thread 0x7f0875f20700 (LWP 378) exited]\n[New Thread 0x7f0875f20700 (LWP 379)]\n[Thread 0x7f0875f20700 (LWP 379) exited]\n[New Thread 0x7f0875f20700 (LWP 380)]\n[Thread 0x7f0875f20700 (LWP 380) exited]\n[New Thread 0x7f0875f20700 (LWP 381)]\n[Thread 0x7f0875f20700 (LWP 381) exited]\n[New Thread 0x7f0875f20700 (LWP 382)]\n[New Thread 0x7f0875f20700 (LWP 383)]\n[Thread 0x7f0875f20700 (LWP 382) exited]\n[Thread 0x7f0875f20700 (LWP 383) exited]\n[New Thread 0x7f0875f20700 (LWP 384)]\n[Thread 0x7f0875f20700 (LWP 384) exited]\n[New Thread 0x7f0875f20700 (LWP 385)]\n[Thread 0x7f0875f20700 (LWP 385) exited]\n[New Thread 0x7f0875f20700 (LWP 386)]\n[Thread 0x7f0875f20700 (LWP 386) exited]\n[New Thread 0x7f0875f20700 (LWP 387)]\n[Thread 0x7f0875f20700 (LWP 387) exited]\n[New Thread 0x7f0875f20700 (LWP 388)]\n[Thread 0x7f0875f20700 (LWP 388) exited]\n[New Thread 0x7f0875f20700 (LWP 389)]\n[Thread 0x7f0875f20700 (LWP 389) exited]\n[New Thread 0x7f0875f20700 (LWP 390)]\n[Thread 0x7f0875f20700 (LWP 390) exited]\n\nFramework Information:\nMOOSE Version:           git commit 9937196945 on 2020-08-05\nLibMesh Version:         4bf75a35d0f989335a2eb716912c3de4e7be20ea\nPETSc Version:           3.14.2\nSLEPc Version:           3.14.0\nCurrent Time:            Fri Jan  8 08:31:32 2021\nExecutable Timestamp:    Fri Jan  8 08:20:37 2021\n\nParallelism:\n  Num Processors:          1\n  Num Threads:             1\n\nMesh:\n  Parallel Type:           replicated\n  Mesh Dimension:          2\n  Spatial Dimension:       2\n  Nodes:\n    Total:                 121\n    Local:                 121\n  Elems:\n    Total:                 100\n    Local:                 100\n  Num Subdomains:          1\n  Num Partitions:          1\n\nNonlinear System:\n  Num DOFs:                121\n  Num Local DOFs:          121\n  Variables:               \"u\"\n  Finite Element Types:    \"LAGRANGE\"\n  Approximation Orders:    \"FIRST\"\n\nExecution Information:\n  Executioner:             Steady\n  Solver Mode:             Preconditioned JFNK\n  PETSc Preconditioner:    hypre boomeramg\n\n[New Thread 0x7f0875f20700 (LWP 391)]\n[Thread 0x7f0875f20700 (LWP 391) exited]\n[New Thread 0x7f0875f20700 (LWP 392)]\n[Thread 0x7f0875f20700 (LWP 392) exited]\n[New Thread 0x7f0875f20700 (LWP 393)]\n[Thread 0x7f0875f20700 (LWP 393) exited]\n[New Thread 0x7f0875f20700 (LWP 394)]\n[Thread 0x7f0875f20700 (LWP 394) exited]\n[New Thread 0x7f0875f20700 (LWP 395)]\n[Thread 0x7f0875f20700 (LWP 395) exited]\n[New Thread 0x7f0875f20700 (LWP 396)]\n[New Thread 0x7f0875f20700 (LWP 397)]\n[Thread 0x7f0875f20700 (LWP 396) exited]\n[Thread 0x7f0875f20700 (LWP 397) exited]\n[New Thread 0x7f0875f20700 (LWP 398)]\n[Thread 0x7f0875f20700 (LWP 398) exited]\n[New Thread 0x7f0875f20700 (LWP 399)]\n[Thread 0x7f0875f20700 (LWP 399) exited]\n[New Thread 0x7f0875f20700 (LWP 400)]\n[Thread 0x7f0875f20700 (LWP 400) exited]\n[New Thread 0x7f0875f20700 (LWP 401)]\n[Thread 0x7f0875f20700 (LWP 401) exited]\n[New Thread 0x7f0875f20700 (LWP 402)]\n[New Thread 0x7f0875f20700 (LWP 403)]\n[Thread 0x7f0875f20700 (LWP 402) exited]\n[Thread 0x7f0875f20700 (LWP 403) exited]\n[New Thread 0x7f0875f20700 (LWP 404)]\n[Thread 0x7f0875f20700 (LWP 404) exited]\n[New Thread 0x7f0875f20700 (LWP 405)]\n[Thread 0x7f0875f20700 (LWP 405) exited]\n[New Thread 0x7f0875f20700 (LWP 406)]\n[Thread 0x7f0875f20700 (LWP 406) exited]\n[New Thread 0x7f0875f20700 (LWP 407)]\n[Thread 0x7f0875f20700 (LWP 407) exited]\n[New Thread 0x7f0875f20700 (LWP 408)]\n[Thread 0x7f0875f20700 (LWP 408) exited]\n[New Thread 0x7f0875f20700 (LWP 409)]\n[Thread 0x7f0875f20700 (LWP 409) exited]\n[New Thread 0x7f0875f20700 (LWP 410)]\n[New Thread 0x7f0875f20700 (LWP 411)]\n[Thread 0x7f0875f20700 (LWP 410) exited]\n[Thread 0x7f0875f20700 (LWP 411) exited]\n[New Thread 0x7f0875f20700 (LWP 412)]\n[Thread 0x7f0875f20700 (LWP 412) exited]\n[New Thread 0x7f0875f20700 (LWP 413)]\n[Thread 0x7f0875f20700 (LWP 413) exited]\n[New Thread 0x7f0875f20700 (LWP 414)]\n[Thread 0x7f0875f20700 (LWP 414) exited]\n[New Thread 0x7f0875f20700 (LWP 415)]\n 0 Nonlinear |R| = 3.082207e+00\n[Thread 0x7f0875f20700 (LWP 415) exited]\n[New Thread 0x7f0875f20700 (LWP 416)]\n      0 Linear |R| = 3.082207e+00\n[Thread 0x7f0875f20700 (LWP 416) exited]\n[New Thread 0x7f0875f20700 (LWP 417)]\n      1 Linear |R| = 1.034260e-01\n[Thread 0x7f0875f20700 (LWP 417) exited]\n[New Thread 0x7f0875f20700 (LWP 418)]\n      2 Linear |R| = 2.616261e-03\n[Thread 0x7f0875f20700 (LWP 418) exited]\n[New Thread 0x7f0875f20700 (LWP 419)]\n[Thread 0x7f0875f20700 (LWP 419) exited]\n      3 Linear |R| = 9.194723e-05\n[New Thread 0x7f0875f20700 (LWP 420)]\n      4 Linear |R| = 1.366911e-06\n[Thread 0x7f0875f20700 (LWP 420) exited]\n  Linear solve converged due to CONVERGED_RTOL iterations 4\n[New Thread 0x7f0875f20700 (LWP 421)]\n[Thread 0x7f0875f20700 (LWP 421) exited]\n 1 Nonlinear |R| = 1.373820e-06\n[New Thread 0x7f0875f20700 (LWP 422)]\n[Thread 0x7f0875f20700 (LWP 422) exited]\n      0 Linear |R| = 1.373820e-06\n[New Thread 0x7f0875f20700 (LWP 423)]\n[Thread 0x7f0875f20700 (LWP 423) exited]\n      1 Linear |R| = 3.507042e-08\n[New Thread 0x7f0875f20700 (LWP 424)]\n[Thread 0x7f0875f20700 (LWP 424) exited]\n      2 Linear |R| = 4.049791e-10\n[New Thread 0x7f0875f20700 (LWP 425)]\n      3 Linear |R| = 1.351613e-11\n[Thread 0x7f0875f20700 (LWP 425) exited]\n  Linear solve converged due to CONVERGED_RTOL iterations 3\n[New Thread 0x7f0875f20700 (LWP 426)]\n[Thread 0x7f0875f20700 (LWP 426) exited]\n 2 Nonlinear |R| = 1.352021e-11\nNonlinear solve converged due to CONVERGED_FNORM_RELATIVE iterations 2\n Solve Converged!\n[New Thread 0x7f0875f20700 (LWP 427)]\n[Thread 0x7f0875f20700 (LWP 427) exited]\n[New Thread 0x7f0875f20700 (LWP 428)]\n[Thread 0x7f0875f20700 (LWP 428) exited]\n[New Thread 0x7f0875f20700 (LWP 429)]\n[Thread 0x7f0875f20700 (LWP 429) exited]\n[New Thread 0x7f0875f20700 (LWP 430)]\n[Thread 0x7f0875f20700 (LWP 430) exited]\n\n ----------------------------------------------------------------------------\n| Reference count information                                                |\n ----------------------------------------------------------------------------\n| N7libMesh10FEAbstractE reference count information:\n|  Creations:    17\n|  Destructions: 17\n| N7libMesh10Parameters5ValueE reference count information:\n|  Creations:    5762\n|  Destructions: 5762\n| N7libMesh12SparseMatrixIdEE reference count information:\n|  Creations:    6\n|  Destructions: 6\n| N7libMesh13NumericVectorIdEE reference count information:\n|  Creations:    63\n|  Destructions: 63\n| N7libMesh15EquationSystemsE reference count information:\n|  Creations:    1\n|  Destructions: 1\n| N7libMesh15GhostingFunctorE reference count information:\n|  Creations:    6\n|  Destructions: 6\n| N7libMesh15NonlinearSolverIdEE reference count information:\n|  Creations:    1\n|  Destructions: 1\n| N7libMesh4ElemE reference count information:\n|  Creations:    108\n|  Destructions: 108\n| N7libMesh4NodeE reference count information:\n|  Creations:    121\n|  Destructions: 121\n| N7libMesh5QBaseE reference count information:\n|  Creations:    20\n|  Destructions: 20\n| N7libMesh6DofMapE reference count information:\n|  Creations:    2\n|  Destructions: 2\n| N7libMesh6SystemE reference count information:\n|  Creations:    2\n|  Destructions: 2\n| N7libMesh9DofObjectE reference count information:\n|  Creations:    229\n|  Destructions: 229\n ----------------------------------------------------------------------------\n--Type <RET> for more, q to quit, c to continue without paging--c\n[Inferior 1 (process 369) exited normally]\n(gdb)\n\nI had to install gdb via Conda as well. That might make a difference if you happened to install Ubuntu's system debugger instead (honestly can't imagine why).\nconda install gdb\nI ended up grabbing the latest version (9.2).\nI suppose the larger issue, is that my solve converges and works. Can you perform an ldd on moose_test-dbg? I want to see what libraries it is linked to:\nmilljm@DESKTOP-M0OU23R:~/projects/moose/test$ ldd moose_test-dbg\n        linux-vdso.so.1 (0x00007fffc030c000)\n        libmoose_test-dbg.so.0 => /home/milljm/projects/moose/test/lib/libmoose_test-dbg.so.0 (0x00007f8a41287000)\n        libmoose-dbg.so.0 => /home/milljm/projects/moose/framework/libmoose-dbg.so.0 (0x00007f8a3c9c9000)\n        libhit-dbg.so.0 => /home/milljm/projects/moose/framework/contrib/hit/libhit-dbg.so.0 (0x00007f8a3c868000)\n        libmesh_dbg.so.0 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/libmesh_dbg.so.0 (0x00007f8a38c97000)\n        libtimpi_dbg.so.2 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/libtimpi_dbg.so.2 (0x00007f8a38c46000)\n        libgfortran.so.4 => /home/milljm/libs/miniconda3/envs/newmoose/lib/libgfortran.so.4 (0x00007f8a38b17000)\n        libgcc_s.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/lib/libgcc_s.so.1 (0x00007f8a38b03000)\n        libstdc++.so.6 => /home/milljm/libs/miniconda3/envs/newmoose/lib/libstdc++.so.6 (0x00007f8a3898f000)\n        libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f8a38838000)\n        libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8a38630000)\n        libmpi.so.12 => /home/milljm/libs/miniconda3/envs/newmoose/lib/libmpi.so.12 (0x00007f8a382e5000)\n        libpcre-dbg.so.0 => /home/milljm/projects/moose/framework/contrib/pcre/libpcre-dbg.so.0 (0x00007f8a382b1000)\n        libvtkCommonCore-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/libvtkCommonCore-6.3.so.1 (0x00007f8a37e59000)\n        libvtkCommonDataModel-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/libvtkCommonDataModel-6.3.so.1 (0x00007f8a37b42000)\n        libvtkImagingCore-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/libvtkImagingCore-6.3.so.1 (0x00007f8a378e4000)\n        libvtkIOImage-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/libvtkIOImage-6.3.so.1 (0x00007f8a37768000)\n        libvtkImagingMath-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/libvtkImagingMath-6.3.so.1 (0x00007f8a3771f000)\n        libvtkCommonExecutionModel-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/libvtkCommonExecutionModel-6.3.so.1 (0x00007f8a37689000)\n        libpetsc.so.3.14 => /home/milljm/libs/miniconda3/envs/newmoose/lib/libpetsc.so.3.14 (0x00007f8a35ef0000)\n        libHYPRE-2.19.0.so => /home/milljm/libs/miniconda3/envs/newmoose/lib/libHYPRE-2.19.0.so (0x00007f8a35a23000)\n        libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f8a35a00000)\n        libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8a359f0000)\n        /lib64/ld-linux-x86-64.so.2 (0x00007f8a4245a000)\n        libgomp.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/lib/libgomp.so.1 (0x00007f8a359c3000)\n        libnetcdf.so.13 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/libnetcdf.so.13 (0x00007f8a35877000)\n        libvtkIOXML-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../libmesh-vtk/lib/libvtkIOXML-6.3.so.1 (0x00007f8a357a6000)\n        libvtkIOParallelXML-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../libmesh-vtk/lib/libvtkIOParallelXML-6.3.so.1 (0x00007f8a3577e000)\n        libvtkParallelMPI-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../libmesh-vtk/lib/libvtkParallelMPI-6.3.so.1 (0x00007f8a35767000)\n        libvtkParallelCore-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../libmesh-vtk/lib/libvtkParallelCore-6.3.so.1 (0x00007f8a3570e000)\n        libz.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/libz.so.1 (0x00007f8a356f4000)\n        libslepc.so.3.14 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/libslepc.so.3.14 (0x00007f8a35337000)\n        libparmetis.so => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/libparmetis.so (0x00007f8a352e6000)\n        libmetis.so => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/libmetis.so (0x00007f8a35272000)\n        libquadmath.so.0 => /lib/x86_64-linux-gnu/libquadmath.so.0 (0x00007f8a35220000)\n        librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f8a35210000)\n        libvtksys-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/./libvtksys-6.3.so.1 (0x00007f8a351c0000)\n        libvtkCommonMisc-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/./libvtkCommonMisc-6.3.so.1 (0x00007f8a351a9000)\n        libvtkCommonSystem-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/./libvtkCommonSystem-6.3.so.1 (0x00007f8a35193000)\n        libvtkCommonTransforms-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/./libvtkCommonTransforms-6.3.so.1 (0x00007f8a3515f000)\n        libvtkCommonMath-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/./libvtkCommonMath-6.3.so.1 (0x00007f8a3512d000)\n        libvtkpng-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/./libvtkpng-6.3.so.1 (0x00007f8a350fa000)\n        libvtktiff-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/./libvtktiff-6.3.so.1 (0x00007f8a3508b000)\n        libvtkmetaio-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/./libvtkmetaio-6.3.so.1 (0x00007f8a34fe8000)\n        libvtkDICOMParser-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/./libvtkDICOMParser-6.3.so.1 (0x00007f8a34fc7000)\n        libvtkzlib-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/./libvtkzlib-6.3.so.1 (0x00007f8a34fa6000)\n        libvtkjpeg-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh-vtk/lib/./libvtkjpeg-6.3.so.1 (0x00007f8a34f70000)\n        libstrumpack.so => /home/milljm/libs/miniconda3/envs/newmoose/lib/./libstrumpack.so (0x00007f8a345c6000)\n        libsuperlu_dist.so.6 => /home/milljm/libs/miniconda3/envs/newmoose/lib/./libsuperlu_dist.so.6 (0x00007f8a344b9000)\n        libmpifort.so.12 => /home/milljm/libs/miniconda3/envs/newmoose/lib/./libmpifort.so.12 (0x00007f8a3447a000)\n        libmfhdf.so.0 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/./libmfhdf.so.0 (0x00007f8a34444000)\n        libdf.so.0 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/./libdf.so.0 (0x00007f8a34390000)\n        libhdf5_hl.so.100 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/./libhdf5_hl.so.100 (0x00007f8a3436a000)\n        libhdf5.so.103 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/./libhdf5.so.103 (0x00007f8a33fc9000)\n        libcurl.so.4 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/./libcurl.so.4 (0x00007f8a33f3a000)\n        libvtkIOXMLParser-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../libmesh-vtk/lib/./libvtkIOXMLParser-6.3.so.1 (0x00007f8a33f21000)\n        libvtkIOCore-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../libmesh-vtk/lib/./libvtkIOCore-6.3.so.1 (0x00007f8a33ea9000)\n        libvtkIOLegacy-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../libmesh-vtk/lib/./libvtkIOLegacy-6.3.so.1 (0x00007f8a33e04000)\n        libjpeg.so.9 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/././libjpeg.so.9 (0x00007f8a33dc2000)\n        libnghttp2.so.14 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/././libnghttp2.so.14 (0x00007f8a33d9a000)\n        libssh2.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/././libssh2.so.1 (0x00007f8a33d56000)\n        libssl.so.1.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/././libssl.so.1.1 (0x00007f8a33cc6000)\n        libcrypto.so.1.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/././libcrypto.so.1.1 (0x00007f8a339fa000)\n        libgssapi_krb5.so.2 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/././libgssapi_krb5.so.2 (0x00007f8a339a1000)\n        libkrb5.so.3 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/././libkrb5.so.3 (0x00007f8a338c8000)\n        libk5crypto.so.3 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/././libk5crypto.so.3 (0x00007f8a338a9000)\n        libcom_err.so.3 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/././libcom_err.so.3 (0x00007f8a3c862000)\n        libvtkexpat-6.3.so.1 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../libmesh-vtk/lib/././libvtkexpat-6.3.so.1 (0x00007f8a33872000)\n        libkrb5support.so.0 => /home/milljm/libs/miniconda3/envs/newmoose/libmesh/lib/../../lib/./././libkrb5support.so.0 (0x00007f8a33861000)\n        libresolv.so.2 => /lib/x86_64-linux-gnu/libresolv.so.2 (0x00007f8a33840000)",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-269446",
                          "updatedAt": "2022-08-02T15:21:19Z",
                          "publishedAt": "2021-01-08T15:40:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "dcolema4"
                          },
                          "bodyText": "@milljm I get the same results as you when I run the 2d diffusion case. It is on my problem where the issue is showing up. Despite not being able to get the debugger to work, I was able to determine that the issue was coming from a vector material property. I still don't know why it caused the program to fail, but when I changed it to a scalar and updated my kernels to accept the scalar value everything worked fine.",
                          "url": "https://github.com/idaholab/moose/discussions/16615#discussioncomment-274646",
                          "updatedAt": "2022-08-02T15:21:26Z",
                          "publishedAt": "2021-01-11T15:26:23Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "CompositeElasticityTensor for crystal plasticity",
          "author": {
            "login": "Bala-1005"
          },
          "bodyText": "Hello everyone,\nI am working on coupling phase field and crystal plasticity. I have used ComputeElasticityTensorCP for describing the elasticity tensors for different phases in the system. I would like to combine them as in normal tensor mechanics using CompositeElasticityTensor.\nDoes crystal plasticity allow using CompositeElasticityTensor for its computations? Or should I create a custom material to achieve this functionality?\nThanks,\nBala",
          "url": "https://github.com/idaholab/moose/discussions/16638",
          "updatedAt": "2022-06-13T08:36:36Z",
          "publishedAt": "2021-01-08T01:22:46Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "ngrilli"
                  },
                  "bodyText": "Dear Bala @Bala-1005\nThe specific feature of ComputeElasticityTensorCP is the usage of the Euler angle reader.\nIf you want to use FiniteStrainCrystalPlasticity, you will always need those Euler angles.\nYou can start from another object to calculate the elasticity tensor, like CompositeElasticityTensor, and create your custom object in which\nyou add the Euler angle reader part of ComputeElasticityTensorCP.\nI did something similar here:\nhttps://github.com/ngrilli/c_pfor_am/blob/main/src/materials/ComputeElasticityTensorMelting.C\nHope this helps,\nBest Regards,\nNicol\u00f2 Grilli\nNational University of Singapore",
                  "url": "https://github.com/idaholab/moose/discussions/16638#discussioncomment-273477",
                  "updatedAt": "2022-06-13T08:36:38Z",
                  "publishedAt": "2021-01-11T03:23:35Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "Bala-1005"
                          },
                          "bodyText": "Thank you Nicolo @ngrilli .I will take a look at your code and see if I can come up with something similar for compositeelasticity.\nBala",
                          "url": "https://github.com/idaholab/moose/discussions/16638#discussioncomment-273494",
                          "updatedAt": "2022-06-13T08:36:38Z",
                          "publishedAt": "2021-01-11T03:44:00Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "MeshGenerators during simulation?",
          "author": {
            "login": "aeslaughter"
          },
          "bodyText": "#16060 brings up a question. At what point should we invest time to enable the running a MeshGenerator after each timestep to allow dynamic mesh modification? For the problem in #16060 this would allow define/redefine the subdomains based on the level set? @friedmud @permcody @lindsayad @fdkong\nIf there is desire and funding I would love to implement that, I have always thought it would be useful for this reason. There is a version of this in Mastodon that uses Aux variables that could go away as well.",
          "url": "https://github.com/idaholab/moose/discussions/16635",
          "updatedAt": "2022-07-19T19:30:08Z",
          "publishedAt": "2021-01-07T21:35:30Z",
          "category": {
            "name": "Q&A Meshing"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "fdkong"
                  },
                  "bodyText": "The mesh modification after each time step is already possible. Here is an example #16008\nAre you asking for regenerating a different mesh  after each time step?",
                  "url": "https://github.com/idaholab/moose/discussions/16635#discussioncomment-268014",
                  "updatedAt": "2022-07-19T19:27:37Z",
                  "publishedAt": "2021-01-07T22:43:56Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "I would like to modify the subdomains",
                          "url": "https://github.com/idaholab/moose/discussions/16635#discussioncomment-269956",
                          "updatedAt": "2022-07-19T19:27:37Z",
                          "publishedAt": "2021-01-08T19:03:38Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "YaqiWang"
                  },
                  "bodyText": "Will the entire mesh be regenerated or just applying some mesh generators on the existing mesh? This sounds to me should be done in a specific user object with meshChanged function. This may complicate our design a lot.",
                  "url": "https://github.com/idaholab/moose/discussions/16635#discussioncomment-268061",
                  "updatedAt": "2022-07-19T19:27:40Z",
                  "publishedAt": "2021-01-07T23:10:37Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "hugary1995"
                  },
                  "bodyText": "I think the phrase \"dynamic mesh modification\" is too general. There are mesh cutting, interface movement, element addition/deletion, dynamic remeshing, etc. How do you handle stateful properties in all scenarios in a unified way?",
                  "url": "https://github.com/idaholab/moose/discussions/16635#discussioncomment-268171",
                  "updatedAt": "2022-07-19T19:27:50Z",
                  "publishedAt": "2021-01-08T01:14:07Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ngrilli"
                  },
                  "bodyText": "I am currently testing the approach in #16008\nto move elements from on subdomain to another.\nThis is useful for me to add elements for additive manufacturing simulations.\nThe material properties in the added elements are reinitialized properly, for instance plastic deformation\nYou can find some example tests here:\nhttps://github.com/ngrilli/c_pfor_am/tree/main/test/tests/ElementAddDelete\nI am currently having some negative Jacobian error when I run large simulations with lots of element deleted at each time step\nand I am investigating the issue. But I think it's not related to the method itself, it's my material model.\nBest Regards,\nNicol\u00f2 Grilli\nNational University of Singapore",
                  "url": "https://github.com/idaholab/moose/discussions/16635#discussioncomment-270948",
                  "updatedAt": "2022-07-19T19:27:52Z",
                  "publishedAt": "2021-01-09T11:25:15Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Call function in kernel or materials",
          "author": {
            "login": "kunokchang"
          },
          "bodyText": "I posted a question yesterday, but it seems to be lacking in explanation, so I will replenish it.\nI would like to call our custom function in kernel or materials.\nMaterials]\n[./bulk_free_energy]\ntype = DerivativeParsedMaterial\nf_name = fb\nargs = 'eta1'\nconstant_names = 'a'\nconstant_expressions = '2.057'\nfunction = 'a*((eta1)^2'\nderivative_order = 2\n[../]\nI need to add result of Fermi-Dirac function like a*((eta1)^2+F_{1/2}(eta1)\nWhich is given here\n[Functions]\n[./fermi]\ntype = PiecewiseLinear\ndata_file = fermi.csv\nformat = columns\n[../]\n[]\nfermi.csv is given by (part of it)\n-7.9899997711181641        2.1235612216047891E-004\n-7.9800000190734863        2.1449011174362248E-004\n-7.9699997901916504        2.1664564757151034E-004\n-7.9600000381469727        2.1882273951932466E-004\n-7.9499998092651367        2.2102181283188398E-004\n-7.9400000572204590        2.2324287758167501E-004\n-7.9299998283386230        2.2548636760039243E-004\n-7.9200000762939453        2.2775229316172307E-004\n-7.9099998474121094        2.3004109685755749E-004\n-7.9000000953674316        2.3235278916675431E-004\n-7.8899998664855957        2.3468782161821161E-004\nBut we are not clear how can we call result of Fermi-Dirac function with argument eta1.\nIf there is a better way to do this, we would really appreciate any comments.",
          "url": "https://github.com/idaholab/moose/discussions/16297",
          "updatedAt": "2022-06-14T11:54:58Z",
          "publishedAt": "2020-11-25T01:09:17Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "laagesen"
                  },
                  "bodyText": "Hi Kunok, I just commented on the other post, but let me amplify a little bit based on the extra detail in this post. Since you want the Fermi-Dirac distribution as a function of eta1, you can just add that term to the function you are defining in your DerivativeParsedMaterial, using the analytical form shown here:\nhttps://www.doitpoms.ac.uk/tlplib/semiconductors/fermi.php",
                  "url": "https://github.com/idaholab/moose/discussions/16297#discussioncomment-138689",
                  "updatedAt": "2022-06-14T12:12:49Z",
                  "publishedAt": "2020-11-25T15:19:52Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "kunokchang"
                          },
                          "bodyText": "Dear Laagesen\nSorry for confusion we cause. We want to calculate Fermi-Dirac integration, not distribution function.\nThe analytic form is given below and take integration is not a trivial job so we try to interpolate it.\nhttps://en.wikipedia.org/wiki/Complete_Fermi%E2%80%93Dirac_integral",
                          "url": "https://github.com/idaholab/moose/discussions/16297#discussioncomment-139097",
                          "updatedAt": "2022-06-14T12:13:15Z",
                          "publishedAt": "2020-11-26T00:46:00Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "kunokchang"
                          },
                          "bodyText": "We try to evaluate F_{1/2}(eta)",
                          "url": "https://github.com/idaholab/moose/discussions/16297#discussioncomment-139098",
                          "updatedAt": "2022-06-14T12:13:15Z",
                          "publishedAt": "2020-11-26T00:46:34Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "laagesen"
                          },
                          "bodyText": "I see-  so are you assuming F_{1/2}(eta) is not changing at each time step and using the same .csv file at each time step? Or are you wanting to output eta, interpolate it using the method that is generating the .csv file, then read it back in?",
                          "url": "https://github.com/idaholab/moose/discussions/16297#discussioncomment-140108",
                          "updatedAt": "2022-06-14T12:13:15Z",
                          "publishedAt": "2020-11-27T14:43:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "kunokchang"
                          },
                          "bodyText": "We assume F_{1/2}(eta) is not changing at each time step and using the same .csv file, however, eta is time-dependent term.",
                          "url": "https://github.com/idaholab/moose/discussions/16297#discussioncomment-140273",
                          "updatedAt": "2022-06-14T12:14:42Z",
                          "publishedAt": "2020-11-27T22:46:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "laagesen"
                          },
                          "bodyText": "Hm, I don't think there is a way to do what you are wanting to with the PiecewiseLinear function. PiecewiseLinear assumes the first part of the data in the csv file is either time (by default) or x,y, or z positions (with optional argument). See https://mooseframework.inl.gov/source/functions/PiecewiseLinear.html for more details on this. It's not set up to take problem variables as an argument.\nAn alternative that I think would work would be to use the PiecewiseLinearInterpolationMaterial. See here for details and examples. https://mooseframework.inl.gov/source/materials/PiecewiseLinearInterpolationMaterial.html\nYou would use this to create a material property that depends on eta1. Unfortunately it does not look like it has the capability to read in a csv file to get the x-y pairs, so you would have to specify them in the input file (although you could probably add the functionality to read csv files pretty easily using the code from the PiecewiseLinear function as an example). So PiecewiseLinearInterpolationMaterial would create a material property, say it's called F. You would then make that available to your existing DerivativeParsedMaterial called bulk_free_energy using material_property_names = F.\nIt does look like PiecewiseLinearInterpolationMaterial calculates derivatives, which I'm assuming you're going to need since most phase-field models need the derivative of the free energy. However just be aware that since you are using linear interpolation, all of your second derivatives are going to be zero; these are used to calculate Jacobians by the preconditioners, so convergence in your solve may be hurt.",
                          "url": "https://github.com/idaholab/moose/discussions/16297#discussioncomment-142897",
                          "updatedAt": "2022-06-14T12:14:42Z",
                          "publishedAt": "2020-11-30T17:09:15Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "kunokchang"
                          },
                          "bodyText": "Sorry for delayed response. I gave my grades at the end of the semester, and now I am back with this problem.\nThe answers you gave are very helpful in approaching the problem. I would like to express our sincere thanks.\nWe declare PiecewiseLinearInterpolationMaterial property as below and we want to call it in DerivativeParsedMaterial and is it possible to pass fermi_test(eta1/2.0) like this way? We are not clear how to pass argument of function.\n[./fermi_test]\ntype = PiecewiseLinearInterpolationMaterial\nproperty = fermi_test\nvariable = fermi\nx = '2.3235278916675431E-004 2.5678716657140193E-004 2.8379094144941774E-004 3.1363395344228466E-004 3.4661480184293897E-004 3.8306332338290775E-004 4.2334400591023457E-004 4.6785984730409537E-004 5.1705550309345436E-004 5.7142299341010746E-004 6.3150577678226284E-004 6.9790436428065117E-004 7.7128266457680090E-004 8.5237315288779500E-004 9.4198625416296500E-004 1.0410170287445100E-003 1.1504543904029938E-003 1.2713915208859713E-003 1.4050343362219744E-003 1.5527168865464539E-003 1.7159122952076673E-003 1.8962478534793204E-003 2.0955220648618544E-003 2.3157184525443913E-003 2.5590307589031741E-003 2.8278807548148058E-003 3.1249428476409127E-003 3.4531718412657711E-003 3.8158252930559911E-003 4.2165045470864424E-003 4.6591834873861418E-003 5.1482483588226420E-003 5.6885426181912955E-003 6.2854027000215241E-003 6.9447242909850462E-003 7.6730081043849289E-003 8.4774235261575424E-003 9.3658801128583824E-003 1.0347083644346118E-002 1.1430641727716809E-002 1.2627134940562407E-002 1.3948216455171785E-002 1.5406723459013859E-002 1.7016761909108134E-002 1.8793871039066580E-002 2.0755129368957407E-002 2.2919305158910545E-002 2.5307023402706061E-002 2.7940885872608706E-002 3.0845717761828609E-002 3.4048713809169372E-002 3.7579651543448035E-002 4.1471124785238581E-002 4.5758692787145720E-002 5.0481226394378478E-002 5.5681079412960861E-002  6.1404356606654949E-002  6.7701199554686134E-002  7.4625918988119933E-002  8.2237426265194619E-002  9.0599359529987766E-002  9.9780341016472748E-002 0.10985423431455218 0.12090012503482848 0.13300274604701343 0.14625237774326805 0.16074492035514423 0.17658192596875985 0.19387015748734349 0.21272181018402139 0.23325387611972009 0.25558775599966849 0.27984879160089887 0.30616507367908830 0.33466728239940641 0.36548725419244205 0.39875699587613084 0.43460766605346784 0.47316760840632061 0.51456206161858054 0.55891138443652488 0.60632883599122311 0.65692179481661872 0.71078722503159686 0.76801459136108396 0.82868157559417333 0.89285491195281386 0.96059203187739461 1.0319365775923359 1.1069236669593814 1.1855755056991080 1.2679037300406737 1.3539125176629796 1.4435937108406798 1.5369341623179518 1.6339106689096636 1.7344932376333677 1.8386489768331284 1.9463361365213048 2.0575128598853629 2.1721308396961607 2.2901389570235700 2.4114874479487196 2.5361205226177570 2.6639861303092491 2.7950281621238084 2.9291902642563219 3.0664201414726628 3.2066608072888370 3.3498612866938982 3.4959675214463499 3.6449264163040018 3.7966903498567839 3.9512072564175238 4.1084322668677187 4.2683174995857973 4.4308163880114391 4.5958884506057514 4.7634883782231263 4.9335786157998385 5.1061182183151681 5.2810675193328223 5.4583932138892495 5.6380565883668146 5.8200270067518005 6.0042699264614274 6.1907518921002884 6.3794459195002933 6.5703189478053332 6.7633461920765487 6.9584984147593936 7.1557472593657199 7.3550709491787369 7.5564410324326055 7.7598375481000117 7.9652355894842275 8.1726109369660396 8.3819460365873244 8.5932160735643013 8.8064049118334271 9.0214910110319586 9.2384533674000124 9.4572777810297612 9.6779423044161685 9.9004339103835033 10.124733776288622 10.350823490228317 10.578691569533502 10.808318301835646 11.039693111246226 11.272799257988478 11.507620323701010 11.744146994171068 11.982361330444245 12.222254797793555 12.463812384186419 12.707019323593313 12.951868106324753 13.198342188637293 13.446434662421453 '\ny = '-7.9 -7.8 -7.7 -7.6 -7.5 -7.4 -7.3 -7.2 -7.1 -7.0 -6.9 -6.8 -6.7 -6.6 -6.5 -6.4 -6.3 -6.2 -6.1 -6.0 -5.9 -5.8 -5.7 -5.6 -5.5 -5.4 -5.3 -5.2 -5.1 -5.0 -4.9 -4.8 -4.7 -4.6 -4.5 -4.4 -4.3 -4.2 -4.1 -4.0 -3.9 -3.8 -3.7 -3.6 -3.5 -3.4 -3.3 -3.2 -3.1 -3.0 -2.9 -2.8 -2.7 -2.6 -2.5 -2.4 -2.3 -2.2 -2.1 -2.0 -1.9 -1.8 -1.7 -1.6 -1.5 -1.4 -1.3 -1.2 -1.1 -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.0 3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9 4.0 4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 5.0 5.1 5.2 5.3 5.4 5.5 5.6 5.7 5.8 5.9 6.0 6.1 6.2 6.3 6.4 6.5 6.6 6.7 6.8 6.9 7.0 7.1 7.2 7.3 7.4 7.5 7.6 7.7 7.8 7.9 8.0'\n[../]\n[./bulk_free_energy]\ntype = DerivativeParsedMaterial\nf_name = fb\nargs = 'eta1 eta2 eta3 eta4 mu1 mu2 mu3 mu4'\nconstant_names = 'a aa temp temp_c T0_eta T0_mu b11 b13 c11 c13 bb11 bb13 cc11 cc13 h'\nconstant_expressions = '2.057 3.943 280 338 275 270 -0.623 0.121 0.331 4.189 1.368 -3.679 0.400 2.000 0.300'\nmaterial_property_names = 'fermi_test'\nfunction = 'a*(temp-T0_eta)/(2.temp_c)((eta1)^2+fermi_test'\nderivative_order = 2\n[../]",
                          "url": "https://github.com/idaholab/moose/discussions/16297#discussioncomment-246326",
                          "updatedAt": "2022-06-14T12:15:19Z",
                          "publishedAt": "2020-12-28T06:05:21Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "laagesen"
                          },
                          "bodyText": "From what you said earlier, you are wanting to interpolate F_{1/2}(eta)  - so you would need to specify variable = eta in the [./fermi_test] block (or whichever order parameter you want to interpolate as a function of, since it looks like there are multiple order parameters). Right now you are specifying variable = fermi and I'm not sure what that is. If the derivatives of fb are going to be used in one of your kernels, you will also want to specify material_property_names = fermi_test(eta1) in [./bulk_free_energy] (assuming eta1 is what you are interpolating based on) rather than just material_property_names = fermi_test- sorry I probably did not mention that before. This will make sure that the derivatives of fermi_test are accounted for when derivatives of fb are taken, as detailed here: https://mooseframework.inl.gov/source/materials/DerivativeParsedMaterial.html . It may also be helpful to output the property fermi_test to your exodus file by specifying outputs = exodus in the [./fermi_test] block so you can visualize it and make sure you are getting what you expect.",
                          "url": "https://github.com/idaholab/moose/discussions/16297#discussioncomment-251051",
                          "updatedAt": "2023-08-11T14:27:33Z",
                          "publishedAt": "2020-12-29T18:40:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "kunokchang"
                          },
                          "bodyText": "We really appreciate for your help. It has been a huge help in applying the MOOSE framework to our research.",
                          "url": "https://github.com/idaholab/moose/discussions/16297#discussioncomment-268266",
                          "updatedAt": "2023-08-11T14:27:33Z",
                          "publishedAt": "2021-01-08T02:51:09Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "laagesen"
                          },
                          "bodyText": "Great glad we could help!",
                          "url": "https://github.com/idaholab/moose/discussions/16297#discussioncomment-269768",
                          "updatedAt": "2023-08-11T14:27:33Z",
                          "publishedAt": "2021-01-08T17:36:16Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Multi-app for exchange between a set intersecting 2d planes and a 3d mesh using the same physics kernels",
          "author": {
            "login": "rpodgorney"
          },
          "bodyText": "MOOSE Users/team--I'm looking for someone to help me put together a demo simulation using a multi-app for heat (and maybe mass) exchange between a set intersecting 2d planes (tris--a 3d fracture network) and a a 3d mesh (tet--a porous media domain)?",
          "url": "https://github.com/idaholab/moose/discussions/16631",
          "updatedAt": "2021-03-17T15:14:22Z",
          "publishedAt": "2021-01-07T20:43:14Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "friedmud"
                  },
                  "bodyText": "Should be able to just do a MultiAppMeshFunctionTransfer to transfer both directions.\nBut - it's going to depend on how you want the lower dimensional domain to feed information up to the higher dimensional domain.",
                  "url": "https://github.com/idaholab/moose/discussions/16631#discussioncomment-267817",
                  "updatedAt": "2021-01-07T20:45:50Z",
                  "publishedAt": "2021-01-07T20:45:36Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "rpodgorney"
                          },
                          "bodyText": "thanks @friedmud, that's the kind of info I need---anyone @INL have an interest to play with this?  I have resources but no time!",
                          "url": "https://github.com/idaholab/moose/discussions/16631#discussioncomment-269396",
                          "updatedAt": "2021-01-08T15:22:13Z",
                          "publishedAt": "2021-01-08T15:22:13Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "aeslaughter"
                  },
                  "bodyText": "Does @WilkAndy already have something like this?",
                  "url": "https://github.com/idaholab/moose/discussions/16631#discussioncomment-267887",
                  "updatedAt": "2021-01-07T21:21:40Z",
                  "publishedAt": "2021-01-07T21:21:26Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "rpodgorney"
                          },
                          "bodyText": "I don't know, hey @WilkAndy have you done this?",
                          "url": "https://github.com/idaholab/moose/discussions/16631#discussioncomment-269398",
                          "updatedAt": "2021-01-08T15:23:05Z",
                          "publishedAt": "2021-01-08T15:23:05Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Installation problem On HPC",
          "author": {
            "login": "zxj19910214"
          },
          "bodyText": "Dear Everyone,\nHappy new year!\nMy name is Xiaojing, I am trying to install moose on our HPC, but I got 14 tests failed, I can still generate my executable(opt) files. I am writing to ask whether the failing tests will influence my simulation performance.\nyou can see the failed process in the following picture:\n\nWarm regards,\nXiaojing",
          "url": "https://github.com/idaholab/moose/discussions/16609",
          "updatedAt": "2022-07-18T18:02:33Z",
          "publishedAt": "2021-01-04T09:39:03Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "aeslaughter"
                  },
                  "bodyText": "If you scroll up in your window you will have the complete error messages for each test. Take a look at those error messages and see if there is something consistent between them and share that information.",
                  "url": "https://github.com/idaholab/moose/discussions/16609#discussioncomment-260233",
                  "updatedAt": "2022-07-18T18:02:44Z",
                  "publishedAt": "2021-01-04T15:14:33Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "zxj19910214"
                  },
                  "bodyText": "Thank you so much for your reply, I added my test-log file below.\nlog-tests.txt",
                  "url": "https://github.com/idaholab/moose/discussions/16609#discussioncomment-260864",
                  "updatedAt": "2022-07-18T18:02:44Z",
                  "publishedAt": "2021-01-04T19:02:37Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "There's a variety of errors. Looks like you don't have matplotlib installed.\nThere's some MPI and Petsc errors too. How did you install petsc ?",
                          "url": "https://github.com/idaholab/moose/discussions/16609#discussioncomment-260930",
                          "updatedAt": "2022-07-18T18:02:47Z",
                          "publishedAt": "2021-01-04T19:25:46Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "zxj19910214"
                          },
                          "bodyText": "Thank you for your answer, I noticed there is a lot of errors after I install Moose on HPC.  I am using a system-wide installation provided by the HPC team.  They download petsc(3.11.1) from: https://ftp.mcs.anl.gov/pub/petsc/release-snapshots/\nand install it.  Will these errors influence the performance of the simulation?\nBecause I tried to use partitioner in my code: https://mooseframework.inl.gov/syntax/Mesh/Partitioner/index.html#!\nIt seems the performance is not improving when I add a partitioner. I feel curious about whether I did something wrong when I install moose. Hope you can give me some suggestions on how to figure this out.\nThank you for your help",
                          "url": "https://github.com/idaholab/moose/discussions/16609#discussioncomment-262704",
                          "updatedAt": "2022-07-18T18:02:47Z",
                          "publishedAt": "2021-01-05T15:14:40Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "moravveji"
                  },
                  "bodyText": "Hi.\nI have installed MOOSE on our machine so that our users can compile their own work in their local directories. To build MOOSE, I use the pre-installed PETSc module; everything is compiled (consistently?) using FOSS 2018a toolchain (i.e. with OpenMPI 2.1.2). However, I have the flexibility to recompile MOOSE (and its dependencies) using more recent toolchains, if that might make a performance difference.\nI have attached the build script used for the current version, so, I appreciated if you give a look, and let me know if anything can be improved.\nmoose.zip",
                  "url": "https://github.com/idaholab/moose/discussions/16609#discussioncomment-266347",
                  "updatedAt": "2022-07-18T18:02:47Z",
                  "publishedAt": "2021-01-07T07:07:14Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "moravveji"
                          },
                          "bodyText": "Additions:\n\nFor your missing matplotlib dependency (On Tier-1 skylake partition), you can use matplotlib/3.1.1-intel-2018a-Python-3.7.2 module, which is compatible with the Python dependency version\nIn the error log you sent, I see the error: PETSC ERROR: Could not locate solver package superlu_dist. Perhaps you must ./configure with --download-superlu_dist. I suspected that SUPERLU was missing from PETSc package\nI inspected the build logs of the used module PETSc/3.11.1-foss/2018a, and searched for results of SUPERLU test; Indeed, SUPERLU is installed as part of PETSc, and is tested during the build time; see e.g. /apps/leuven/skylake/2018a/software/PETSc/3.11.1-foss-2018a/share/petsc/examples/src/snes/examples/tutorials/output/ex19_superlu.out\nThe same is true for the Cholesky solver\nI checked the group permissions on the PETSc folder, and I realized that it needed some fix.\n\nWould you please try again with your tests?",
                          "url": "https://github.com/idaholab/moose/discussions/16609#discussioncomment-266413",
                          "updatedAt": "2022-07-18T18:02:47Z",
                          "publishedAt": "2021-01-07T08:00:10Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "zxj19910214"
                          },
                          "bodyText": "Thank you very much for your help, i will test it and see whether it helps",
                          "url": "https://github.com/idaholab/moose/discussions/16609#discussioncomment-267194",
                          "updatedAt": "2022-07-18T18:02:47Z",
                          "publishedAt": "2021-01-07T15:26:35Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Continue forward simulation",
          "author": {
            "login": "PengWei97"
          },
          "bodyText": "Dear MOOSE experts,\nI would like to ask, can moose continue to simulate forward at the time of the previous simulation instead of re-simulating?\nIn detail, if I set the time as follows:\n\u00a0\u00a0start_time\u00a0=\u00a00.0 \u00a0\u00a0end_time\u00a0=\u00a08000 \nAfter the simulation is completed, I set ent_time = 10000, but hope that start_time = 8001. Does moose have such a function?\nIf so, how can I do it?\nAny suggestions or recommendations to fix these problems would be greatly appreciated.\nThank you\nWei Peng",
          "url": "https://github.com/idaholab/moose/discussions/16447",
          "updatedAt": "2022-07-09T08:20:32Z",
          "publishedAt": "2020-12-10T01:35:11Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "dschwen"
                  },
                  "bodyText": "You need to add checkpoint = true in your Outputs block in your first run and then start your second run with --recover after increasing the end time.",
                  "url": "https://github.com/idaholab/moose/discussions/16447#discussioncomment-182954",
                  "updatedAt": "2022-07-09T08:20:41Z",
                  "publishedAt": "2020-12-10T01:40:46Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Thank you for your reply, the problem is solved.\nFollow your suggestion, Following your suggestion, I solved the problem in two steps:\nFirst add \"checkpoint = true\" to the outputs block in the input file.\nAfter the simulation is complete, modify the end_time, and finally run the name command line \"*-opt -i *.i --recover\".",
                          "url": "https://github.com/idaholab/moose/discussions/16447#discussioncomment-183837",
                          "updatedAt": "2022-07-09T08:20:41Z",
                          "publishedAt": "2020-12-10T03:07:27Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Dear dschwen,\nRegarding the function of this moose, I still have some questions and hope to get your suggestion.\nFirst, I use recover to run grain_growth_2D_graintracker.i, it can continue to simulate forward. @dschwen\nBut when I change the input file to poly_grain_growth_2D_eldrforce.i, it shows an error in the terminal, the error is as follows:\n*** ERROR ***\nERROR: Neither one of the following files can be located:\n'_mesh.cpr/1/header.cpr' nor\n'_mesh.cpr'\nIf you are running a parallel job, double check that you've created a split for 1 ranks.\nNote: One of paths above may refer to a valid directory on your system, however we are attempting to read a valid header file.\n\nFor the coupled model of multiple physics modules, do I need to perform other operations to continue the forward simulation?",
                          "url": "https://github.com/idaholab/moose/discussions/16447#discussioncomment-266573",
                          "updatedAt": "2022-07-09T08:20:42Z",
                          "publishedAt": "2021-01-07T09:37:10Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "WilkAndy"
                  },
                  "bodyText": "Have a read of https://mooseframework.inl.gov/application_usage/restart_recover.html to see if it satisfies your requirements.",
                  "url": "https://github.com/idaholab/moose/discussions/16447#discussioncomment-182957",
                  "updatedAt": "2022-07-09T08:20:47Z",
                  "publishedAt": "2020-12-10T01:41:39Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "PengWei97"
                          },
                          "bodyText": "Thank you for your quick reply, the webpage you gave is very important to me.",
                          "url": "https://github.com/idaholab/moose/discussions/16447#discussioncomment-183838",
                          "updatedAt": "2022-07-09T08:20:50Z",
                          "publishedAt": "2020-12-10T03:07:54Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Peacock terminated suddenly",
          "author": {
            "login": "MAbdoelatef"
          },
          "bodyText": "Merry Christmas,\nCan you please advise why Peacock is terminated suddenly (see the attached message)? It might be a Mac issue, not the MOOSE issue, but I still couldn't know why!.\nMany thanks",
          "url": "https://github.com/idaholab/moose/discussions/16590",
          "updatedAt": "2024-06-24T02:58:24Z",
          "publishedAt": "2020-12-25T23:58:26Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "aeslaughter"
                  },
                  "bodyText": "This seems like a problem with python, what version of python are you using and how was it installed? What does the command which python return?",
                  "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-260280",
                  "updatedAt": "2024-06-24T02:58:26Z",
                  "publishedAt": "2021-01-04T15:30:44Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "MAbdoelatef"
                  },
                  "bodyText": "Many thanks, Andrew, I believe it is Python 3.8 (see the attached\nscreenshot), it was installed by default while installing MOOSE by conda.\n[image: Screen Shot 2021-01-04 at 10.13.26 AM.png]\n\u2026\nOn Mon, Jan 4, 2021 at 9:31 AM Andrew E Slaughter ***@***.***> wrote:\n This seems like a problem with python, what version of python are you\n using and how was it installed? What does the command which python return?\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <https://urldefense.com/v3/__https://github.com/idaholab/moose/discussions/16590*discussioncomment-260280__;Iw!!KwNVnqRv!TSZXn_hbiT8t2u3Oxv7K3UTdu_pWQC5ytUnq1DxWidpIxWKr8tff24pogx000t-8aKQ$>,\n or unsubscribe\n <https://urldefense.com/v3/__https://github.com/notifications/unsubscribe-auth/AKILTIQAJ2GB6TMB5A6FSNDSYHNLHANCNFSM4VJOSYZA__;!!KwNVnqRv!TSZXn_hbiT8t2u3Oxv7K3UTdu_pWQC5ytUnq1DxWidpIxWKr8tff24pogx00_vJvjmY$>\n .\n\n\n-- \n*Sincerely,*\n*Mohammed Abdoelatef  | * Graduate Assistant Research\n[image: Materials Development and characterization Center(MDC 2)]\nMobile: 979.587.0877 | M.Abdoelatef@tamu.edu\n- - - - - - - - - - - - - - - - - - - - - - - -\nTEXAS A&M UNIVERSITY | FEARLESS on Every Front",
                  "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-260390",
                  "updatedAt": "2024-06-24T02:58:31Z",
                  "publishedAt": "2021-01-04T16:14:07Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "If you have time give it a try with python 3.7.\nconda create -n moose-py37 python=3.7 moose-tools moose-libmesh\nconda activate moose-py37",
                          "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-260415",
                          "updatedAt": "2024-06-24T02:58:31Z",
                          "publishedAt": "2021-01-04T16:22:33Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "Nevermind, it is 3.7 already. It is in the error message. I missed that. However, the path is not complete, it could be that it is picking up some other python you have installed.",
                          "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-260425",
                          "updatedAt": "2024-06-24T02:58:33Z",
                          "publishedAt": "2021-01-04T16:24:34Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "MAbdoelatef"
                  },
                  "bodyText": "Then, should I remove all the python versions I have, then reinstall again.\nIf yes, what are the best commands to do that.\n\u2026\nOn Mon, Jan 4, 2021 at 10:24 AM Andrew E Slaughter ***@***.***> wrote:\n Nevermind, it is 3.7 already. It is in the error message. I missed that.\n However, the path is not complete, it could be that it is picking up some\n other python you have installed.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <https://urldefense.com/v3/__https://github.com/idaholab/moose/discussions/16590*discussioncomment-260425__;Iw!!KwNVnqRv!Tx9KEzgJHB0svaYWxuWXRd1-NBsV44Fggjd3nvgn_dWLw5_auW7kH8X-DEKAdNqByEs$>,\n or unsubscribe\n <https://urldefense.com/v3/__https://github.com/notifications/unsubscribe-auth/AKILTIXF2RTFZFRKLUNOZ2DSYHTVFANCNFSM4VJOSYZA__;!!KwNVnqRv!Tx9KEzgJHB0svaYWxuWXRd1-NBsV44Fggjd3nvgn_dWLw5_auW7kH8X-DEKA3tIVbEY$>\n .\n\n\n-- \n*Sincerely,*\n*Mohammed Abdoelatef  | * Graduate Assistant Research\n[image: Materials Development and characterization Center(MDC 2)]\nMobile: 979.587.0877 | M.Abdoelatef@tamu.edu\n- - - - - - - - - - - - - - - - - - - - - - - -\nTEXAS A&M UNIVERSITY | FEARLESS on Every Front",
                  "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-260449",
                  "updatedAt": "2024-06-24T02:58:39Z",
                  "publishedAt": "2021-01-04T16:30:52Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "I am just trying to figure out what python is being used. If you type which python in the same window you are running peacock, what do you get?",
                          "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-260583",
                          "updatedAt": "2024-06-24T02:58:40Z",
                          "publishedAt": "2021-01-04T17:18:21Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "MAbdoelatef"
                  },
                  "bodyText": "I think the same window is not allowing me to add any other command, see\nbelow. Am I missing something?\n[image: Screen Shot 2021-01-04 at 2.06.12 PM.png]\n\u2026\nOn Mon, Jan 4, 2021 at 11:18 AM Andrew E Slaughter ***@***.***> wrote:\n I am just trying to figure out what python is being used. If you type which\n python in the same window you are running peacock, what do you get?\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <https://urldefense.com/v3/__https://github.com/idaholab/moose/discussions/16590*discussioncomment-260583__;Iw!!KwNVnqRv!S_RXFUrF3zi0QZISjztC0nSiqNsbfcgnJnbDi8_FzD8pj-fnr0-AYR3Z9G_LVCxaTtM$>,\n or unsubscribe\n <https://urldefense.com/v3/__https://github.com/notifications/unsubscribe-auth/AKILTIVIRTV5K2Q3VDPZ3E3SYHZ6ZANCNFSM4VJOSYZA__;!!KwNVnqRv!S_RXFUrF3zi0QZISjztC0nSiqNsbfcgnJnbDi8_FzD8pj-fnr0-AYR3Z9G_LpWdSLdI$>\n .\n\n\n-- \n*Sincerely,*\n*Mohammed Abdoelatef  | * Graduate Assistant Research\n[image: Materials Development and characterization Center(MDC 2)]\nMobile: 979.587.0877 | M.Abdoelatef@tamu.edu\n- - - - - - - - - - - - - - - - - - - - - - - -\nTEXAS A&M UNIVERSITY | FEARLESS on Every Front",
                  "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-261043",
                  "updatedAt": "2024-06-24T02:58:40Z",
                  "publishedAt": "2021-01-04T20:07:24Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "The image isn't showing up.",
                          "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-261079",
                          "updatedAt": "2021-01-04T20:17:40Z",
                          "publishedAt": "2021-01-04T20:17:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "I think you will need to go to the discussions thread to add the image, the attachment via the reply email is not working.",
                          "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-261140",
                          "updatedAt": "2024-06-24T02:58:42Z",
                          "publishedAt": "2021-01-04T20:46:26Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "MAbdoelatef"
                          },
                          "bodyText": "",
                          "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-261146",
                          "updatedAt": "2024-06-24T02:58:43Z",
                          "publishedAt": "2021-01-04T20:50:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "That is what I would expect for python, coming from miniconda3 location. I am not sure why you are getting the MacOS failure, but the real problem seems to be in your input file which is producing an error as shown in this screen shot.",
                          "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-261178",
                          "updatedAt": "2021-01-04T21:05:01Z",
                          "publishedAt": "2021-01-04T21:05:01Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "MAbdoelatef"
                          },
                          "bodyText": "Actually, the peacock problem happens for both working and non-working input files. I believe the non-working input file is not the reason. I will try to remove the python and reinstall it again; I will notify you if it works.\nMany thanks for taking the time to consider this issue.",
                          "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-261195",
                          "updatedAt": "2021-01-04T21:10:33Z",
                          "publishedAt": "2021-01-04T21:10:33Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "Can you consistently reproduce the MacOS \"python quit unexpectedly\" problem? If so, what are the steps for doing that.",
                          "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-265108",
                          "updatedAt": "2021-01-06T16:17:00Z",
                          "publishedAt": "2021-01-06T16:17:00Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "MAbdoelatef"
                  },
                  "bodyText": "Please see the attached screenshot.\n\u2026\nOn Mon, Jan 4, 2021 at 2:17 PM Andrew E Slaughter ***@***.***> wrote:\n The image isn't showing up.\n\n \u2014\n You are receiving this because you are subscribed to this thread.\n Reply to this email directly, view it on GitHub\n <https://urldefense.com/v3/__https://github.com/idaholab/moose/discussions/16590*discussioncomment-261079__;Iw!!KwNVnqRv!UqJa0P7h1mCRHWjwtDh3aaeSxzPCwXAbANQA_rhg2RPfvTuvXV8L4NxJxMjyONYLKqU$>,\n or unsubscribe\n <https://urldefense.com/v3/__https://github.com/notifications/unsubscribe-auth/AKILTIRVFIUOVOQKA5YAXR3SYIO7HANCNFSM4VJOSYZA__;!!KwNVnqRv!UqJa0P7h1mCRHWjwtDh3aaeSxzPCwXAbANQA_rhg2RPfvTuvXV8L4NxJxMjyXnfEMWo$>\n .\n\n\n-- \n*Sincerely,*\n*Mohammed Abdoelatef  | * Graduate Assistant Research\n[image: Materials Development and characterization Center(MDC 2)]\nMobile: 979.587.0877 | M.Abdoelatef@tamu.edu\n- - - - - - - - - - - - - - - - - - - - - - - -\nTEXAS A&M UNIVERSITY | FEARLESS on Every Front",
                  "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-261091",
                  "updatedAt": "2021-01-04T20:23:45Z",
                  "publishedAt": "2021-01-04T20:23:31Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "friedmud"
                          },
                          "bodyText": "Just before running the peacock command - please do which python",
                          "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-265002",
                          "updatedAt": "2021-01-06T15:28:18Z",
                          "publishedAt": "2021-01-06T15:28:18Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aeslaughter"
                          },
                          "bodyText": "That is in the screenshot above, in the upper left terminal. It looks correct.",
                          "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-265103",
                          "updatedAt": "2021-01-06T16:15:48Z",
                          "publishedAt": "2021-01-06T16:15:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "friedmud"
                          },
                          "bodyText": "Sorry @aeslaughter you're right - I only saw the one he did after he started Peacock",
                          "url": "https://github.com/idaholab/moose/discussions/16590#discussioncomment-265309",
                          "updatedAt": "2021-01-06T17:47:16Z",
                          "publishedAt": "2021-01-06T17:47:16Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}