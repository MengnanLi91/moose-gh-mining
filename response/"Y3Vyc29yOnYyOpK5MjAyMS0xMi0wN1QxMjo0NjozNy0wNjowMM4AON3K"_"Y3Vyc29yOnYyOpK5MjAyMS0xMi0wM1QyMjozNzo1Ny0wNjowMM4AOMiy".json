{
  "discussions": {
    "pageInfo": {
      "hasNextPage": true,
      "endCursor": "Y3Vyc29yOnYyOpK5MjAyMS0xMi0wM1QyMjozNzo1Ny0wNjowMM4AOMiy"
    },
    "edges": [
      {
        "node": {
          "title": "failing to compile contact module",
          "author": {
            "login": "mcacace"
          },
          "bodyText": "Dear all,\nafter a fresh update of libmesh and moose, I cannot compile the contact module any longer. Errors seem to be related to some malfunctions in the TIMPI libmesh - no type (buffer_type) and accessing private members or not defined functions.\nI should add that other modules (and the framework) compile just fine, and that my moose-libmesh version (via conda) is somewhat older (no idea why, since I also update conda)  than the one posted in the discussions (2021.10.27 vs 2021.11.11 --> might this do the trick), and I am running on an ubuntu 18.04 LTS system.\nAny help/hints would be great, thanks,\nmauro",
          "url": "https://github.com/idaholab/moose/discussions/19569",
          "updatedAt": "2022-09-30T01:41:56Z",
          "publishedAt": "2021-12-07T16:50:12Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nYour moose-libmesh version cannot be older than the supported one, otherwise moose cant compile.\nPlease follow the instructions on that post you saw\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/19569#discussioncomment-1767496",
                  "updatedAt": "2022-09-30T01:41:57Z",
                  "publishedAt": "2021-12-07T17:08:05Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "mcacace"
                          },
                          "bodyText": "@GiudGiud I did follow the steps for updating via conda, but cannot upgrade my moose-libmesh version further.",
                          "url": "https://github.com/idaholab/moose/discussions/19569#discussioncomment-1767514",
                          "updatedAt": "2022-09-30T01:41:59Z",
                          "publishedAt": "2021-12-07T17:10:29Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "ngrilli"
                  },
                  "bodyText": "Dear @mcacace\nI updated last week and also has problems compiling.\nI ended up cancelling completely the moose folder and starting the Ubuntu installation procedure from scratch,\nso that also libmesh and petsc get updated.\nBest Regards,\nNicol\u00f2",
                  "url": "https://github.com/idaholab/moose/discussions/19569#discussioncomment-1767499",
                  "updatedAt": "2022-09-30T01:41:59Z",
                  "publishedAt": "2021-12-07T17:08:54Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "mcacace"
                          },
                          "bodyText": "@ngrilli thanks! I would try to forced removing the moose envs in the conda and reinstall all. BTW, did you also upgrade to mamba? And, is it worth? Thanks",
                          "url": "https://github.com/idaholab/moose/discussions/19569#discussioncomment-1767524",
                          "updatedAt": "2022-10-09T03:58:08Z",
                          "publishedAt": "2021-12-07T17:13:21Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "see this post\n#19532\nThis is the current solution to update",
                          "url": "https://github.com/idaholab/moose/discussions/19569#discussioncomment-1767618",
                          "updatedAt": "2022-10-09T03:58:09Z",
                          "publishedAt": "2021-12-07T17:28:58Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "mcacace"
                          },
                          "bodyText": "@ngrilli It worked, I have now the current libmesh version (and wow, mamba is indeed faster!).",
                          "url": "https://github.com/idaholab/moose/discussions/19569#discussioncomment-1767698",
                          "updatedAt": "2022-10-09T03:58:09Z",
                          "publishedAt": "2021-12-07T17:39:23Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "mcacace"
                          },
                          "bodyText": "Thanks @GiudGiud -- I should have read the whole post ...",
                          "url": "https://github.com/idaholab/moose/discussions/19569#discussioncomment-1767709",
                          "updatedAt": "2022-10-09T03:58:09Z",
                          "publishedAt": "2021-12-07T17:41:15Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "exit code 11",
          "author": {
            "login": "amosaha"
          },
          "bodyText": "Hi ,\nMy input file is below, and I\u2019m sure my mesh file is correct. When I add the BCs of the type of heatconductionBC , the procedure crashed and told me the exit code 11. How to solve the problem?\nThanks.\n\n[GlobalParams]\n  displacements = 'disp_x disp_y disp_z'\n[]\n\n[Mesh]\n  file=suc.e\n[]\n\n\n[Variables]\n  [temp]\n    block='1 2'\n initial_condition=1.0\n  []\n[]\n\n\n[Modules/TensorMechanics/Master]\n  [all]\n    add_variables = true\n    strain = SMALL\n    automatic_eigenstrain_names = true\n    generate_output = 'vonmises_stress'\n  []\n[]\n\n[Kernels]\n  [hc]\n    type = HeatConduction\n    variable = temp\n    block='1 2'\n  []\n  [source]\n    type=HeatSource\n    variable=temp\n    block=2\n    value=10\n  []\n[]\n\n[BCs] \n  [temp.inside]\n    type = DirichletBC\n    variable = temp\n    boundary = inside\n    value = 10\n   []\n  [temp.outside]\n    type = DirichletBC\n    variable = temp\n    boundary = ouside\n    value = 1\n[]\n [./middle]\n    type=HeatConductionBC\n    variable=temp\n    boundary='middle'\n  [../]\n\n [bottomz]\n    type = DirichletBC\n    variable = disp_z\n    boundary = bottom\n    value = 0\n   []\n [fix1]\n    type = DirichletBC\n    variable = disp_y\n    boundary = fix1\n    value = 0\n   []\n [fix2]\n    type = DirichletBC\n    variable = disp_x\n    boundary = fix2\n    value = 0\n   []\n[]\n\n[Materials]\n  [hcm]\n    type = HeatConductionMaterial\n    block = '1 2'\n    specific_heat = 460\n    thermal_conductivity = 40\n    use_displaced_mesh = true \n  []\n [density]\n type = GenericConstantMaterial\n    prop_names = 'density'\n    prop_values = '7.85'\n  []\n  [elasticity]\n    type = ComputeIsotropicElasticityTensor\n    youngs_modulus = 2e11\n    poissons_ratio = 0.3\n  []\n  [expansion]\n    type = ComputeThermalExpansionEigenstrain\n    temperature = temp\n    thermal_expansion_coeff = 1.2e-5\n    stress_free_temperature =5\n    eigenstrain_name = thermal_expansion\n  []\n  [stress]\n    type = ComputeLinearElasticStress\n  []\n[]\n\n[Preconditioning]\n    [./SMP]\n        type = SMP\n        full = true\n    [../]\n[]\n\n\n[Executioner]\n  type =Steady\n  solve_type = 'PJFNK'\n  petsc_options_iname='-pc_type -pc_hypre_type'\n  petsc_options_value='hypre boomeramg'\n#  start_time=0.0\n#  num_steps=10\n#  dt=0.1\n[]\n\n[Outputs]\n  exodus = true\n[]",
          "url": "https://github.com/idaholab/moose/discussions/19550",
          "updatedAt": "2022-07-08T00:06:28Z",
          "publishedAt": "2021-12-06T09:11:55Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nPlease follow the instructions there https://mooseframework.inl.gov/application_development/debugging.html to:\n\nrun in devel or debug mode and see if you hit any problems\nget a backtrace if you do\n\nI suspect the problem is with the boundary condition in the middle of the mesh.\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/19550#discussioncomment-1760575",
                  "updatedAt": "2022-07-08T00:06:32Z",
                  "publishedAt": "2021-12-06T19:48:31Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "amosaha"
                          },
                          "bodyText": "Oh thanks. I have found my problem.",
                          "url": "https://github.com/idaholab/moose/discussions/19550#discussioncomment-1762983",
                          "updatedAt": "2022-07-08T00:06:35Z",
                          "publishedAt": "2021-12-07T07:04:37Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "How to output curve of strain hardening rate and strain",
          "author": {
            "login": "xchengood"
          },
          "bodyText": "Hi Moose experts or users,\nCould anyone share any ideas or thoughts about how to output the curve of strain hardening rate and strain? One example is shown below. Now I can get a reasonable curve of stress-strain. But I have no idea how to obtain the curve of strain hardening rate-strain in Moose. Thank you.",
          "url": "https://github.com/idaholab/moose/discussions/19557",
          "updatedAt": "2022-09-12T17:14:52Z",
          "publishedAt": "2021-12-06T19:25:16Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "ngrilli"
                  },
                  "bodyText": "Dear @xchengood\nParaview has a time derivative filter, you can take the time derivative of the stress,\nif you know your strain rate, you will be able to calculate the d_sigma/d_epsilon.\nBest Regards,\nNicol\u00f2",
                  "url": "https://github.com/idaholab/moose/discussions/19557#discussioncomment-1761529",
                  "updatedAt": "2022-09-12T17:14:59Z",
                  "publishedAt": "2021-12-06T23:21:51Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "One dimensional harmonic elastic wave results does not make sense",
          "author": {
            "login": "aaelmeli"
          },
          "bodyText": "Hi\nI am modeling harmonic elastic wave propagation in a one-dimensional bar. The bar is fixed on the left, and I apply DirichletBC=1 on the right end. The results do not seem to be accurate, please see the following picture, the displacement suddenly dropped from 1 to a relatively very small value then oscillates.\n\nIf I changed the DirichletBC=1 to be NeumannBC=1 on the right, I got the correct solution.\nThe input file that can reproduce these results is as follows:\n[Mesh]\n    type = GeneratedMesh\n    dim = 1\n    xmin=0\n    xmax=1\n    nx = 1000\n[]\n\n[Variables]\n    [uxr]\n       order = FIRST\n       family = LAGRANGE\n    []\n \n    [uxi]\n       order = FIRST\n       family = LAGRANGE\n    []\n\n[]\n\n[Kernels]\n    [urealx]\n    type = StressDivergenceTensors\n    variable = uxr\n    displacements='uxr'\n    component = 0\n    base_name = A\n    []\n\n    [uimagx]\n    type = StressDivergenceTensors\n    variable = uxi\n    displacements='uxi'\n    component = 0\n    base_name = B\n    []\n\n    [reaction_realx]\n        type = Reaction\n        variable = uxr\n        rate = -10000\n    []\n\n    [reaction_imagx]\n        type = Reaction\n        variable = uxi\n        rate = -10000\n    []\n\n\n[]\n\n[BCs]\n#Left\n  [uxr_left]\n        type = DirichletBC\n        variable = uxr\n        boundary = 'left'\n        value = 0\n  []\n  [uxi_left]\n        type = DirichletBC\n        variable = uxi\n        boundary = 'left'\n        value = 0\n  []\n\n    [BC_right_xreal]\n        type = DirichletBC\n        variable = uxr\n        boundary = 'right'\n        value = 1\n    []\n    [BC_right_ximag]\n        type = DirichletBC\n        variable = uxi\n        boundary = 'right'\n        value = 0\n    []\n\n[]\n[Materials]\n\n  [elasticity_tensor_A]\n    type = ComputeIsotropicElasticityTensor\n    base_name = A\n    youngs_modulus = 1\n    poissons_ratio = 0.0\n  []\n  [strain_A]\n    type = ComputePlaneFiniteStrain\n    base_name = A\n    displacements='uxr  uxi'\n  []\n  [stress_A]\n    type = ComputeFiniteStrainElasticStress\n    base_name = A\n  []\n\n   [elasticity_tensor_B]\n    type = ComputeIsotropicElasticityTensor\n    base_name = B\n    youngs_modulus = 1\n    poissons_ratio = 0.0\n  []\n  [strain_B]\n    type = ComputePlaneFiniteStrain\n    base_name = B\n    displacements='uxr  uxi '\n  []\n  [stress_B]\n    type = ComputeFiniteStrainElasticStress\n    base_name = B\n  []\n\n[]\n\n\n[Outputs]\n    [exodus_coupled]\n        type = Exodus\n    []\n        print_perf_log = true\n[]\n\n[Executioner]\n  type = Steady\n  solve_type=LINEAR\n  petsc_options_iname = ' -pc_type'\n  petsc_options_value = 'lu'\n[]\n\nAny suggestions?",
          "url": "https://github.com/idaholab/moose/discussions/19510",
          "updatedAt": "2022-06-18T06:13:06Z",
          "publishedAt": "2021-11-30T18:24:08Z",
          "category": {
            "name": "Q&A Modules: Solid mechanics"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "hugary1995"
                  },
                  "bodyText": "There are a few things I don't understand in your input file. For starters, could you write down the equations you are trying to solve here?",
                  "url": "https://github.com/idaholab/moose/discussions/19510#discussioncomment-1728213",
                  "updatedAt": "2022-06-18T06:13:20Z",
                  "publishedAt": "2021-12-01T13:07:35Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "aaelmeli"
                          },
                          "bodyText": "Hi @hugary1995 ,\nThis is an attempt to model the steady-state elastic wave equation. This can be generally written as\n\nwith D=1 (the dimension of the problem)\nIn the posted input file, I just considered the minimum input that can reproduce the results. So, I only considered the x-displacement.\nThe original input file that I used is as follows, which includes two displacement components (x,y). The CoupledVarNeumannBC was used to couple the real and imaginary parts of each displacement component.\n[Mesh]\n    type = GeneratedMesh\n    dim = 1\n    xmin=0\n    xmax=1\n    nx = 1000\n[]\n\n[Variables]\n    [uxr]\n       order = FIRST\n       family = LAGRANGE\n    []\n    [uyr]\n       order = FIRST\n       family = LAGRANGE\n    []\n    [uxi]\n       order = FIRST\n       family = LAGRANGE\n    []\n    [uyi]\n       order = FIRST\n       family = LAGRANGE\n    []\n[]\n\n[Kernels]\n    [urealx]\n    type = StressDivergenceTensors\n    variable = uxr\n    displacements='uxr'\n    component = 0\n    base_name = A\n    []\n    [urealy]\n    type = StressDivergenceTensors\n    variable = uyr\n    displacements='uyr'\n    component = 1\n    base_name = B\n    []\n    [uimagx]\n    type = StressDivergenceTensors\n    variable = uxi\n    displacements='uxi'\n    component = 0\n    base_name = A\n    []\n    [uimagy]\n    type = StressDivergenceTensors\n    variable = uyi\n    displacements='uyi'\n    component = 1\n    base_name = B\n    []\n    [reaction_realx]\n        type = Reaction\n        variable = uxr\n        rate = -10000\n    []\n    [reaction_realy]\n        type = Reaction\n        variable = uyr\n        rate = -10000\n    []\n    [reaction_imagx]\n        type = Reaction\n        variable = uxi\n        rate = -10000\n    []\n    [reaction_imagy]\n        type = Reaction\n        variable = uyi\n        rate = -10000\n    []\n[]\n\n[BCs]\n#Left\n  [uxr_left]\n        type = CoupledVarNeumannBC\n        variable = uxr\n        boundary = 'left'\n        v = uxi\n        coef=-100\n  []\n  [uxi_left]\n        type = CoupledVarNeumannBC\n        variable = uxi\n        boundary = 'left'\n        v = uxr\n        coef=100\n  []\n  [uyr_left]\n        type = CoupledVarNeumannBC\n        variable = uyr\n        boundary = 'left'\n        v = uyi\n        coef=-70.7\n  []\n  [uyi_left]\n        type = CoupledVarNeumannBC\n        variable = uyi\n        boundary = 'left'\n        v = uyr\n        coef=70.7\n  []\n    [BC_right_xreal]\n        type = DirichletBC\n        variable = uxr\n        boundary = 'right'\n        value = 1\n    []\n    [BC_right_ximag]\n        type = DirichletBC\n        variable = uxi\n        boundary = 'right'\n        value = 0\n    []\n[]\n[Materials]\n\n  [elasticity_tensor_A]\n    type = ComputeIsotropicElasticityTensor\n    base_name = A\n    youngs_modulus = 1\n    poissons_ratio = 0.0\n  []\n  [strain_A]\n    type = ComputePlaneFiniteStrain\n    base_name = A\n    displacements='uxr uyr'\n  []\n  [stress_A]\n    type = ComputeFiniteStrainElasticStress\n    base_name = A\n  []\n\n   [elasticity_tensor_B]\n    type = ComputeIsotropicElasticityTensor\n    base_name = B\n    youngs_modulus = 1\n    poissons_ratio = 0.0\n  []\n  [strain_B]\n    type = ComputePlaneFiniteStrain\n    base_name = B\n    displacements='uxi uyi'\n  []\n  [stress_B]\n    type = ComputeFiniteStrainElasticStress\n    base_name = B\n  []\n\n[]\n\n[Outputs]\n    [exodus_coupled]\n        type = Exodus\n    []\nperf_graph = true\n[]\n\n[Executioner]\n type = Steady\n solve_type=LINEAR\n petsc_options_iname = ' -pc_type'\n petsc_options_value = 'lu'\n[]",
                          "url": "https://github.com/idaholab/moose/discussions/19510#discussioncomment-1732435",
                          "updatedAt": "2022-06-18T06:13:21Z",
                          "publishedAt": "2021-12-01T22:20:46Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hugary1995"
                          },
                          "bodyText": "I typed some equations in this pdf:\nscratch.pdf\nSo basically your real and imaginary parts should be decoupled. But in your 1D input file you are defining strains as some weird coupling between real and imaginary displacements. I recommend you to name your base names as base_name = real and base_name = imaginary for better readability. Another way to view this is: If you separate out objects with either base name, you should get a completely defined model.\nI also noticed that you used nonlinear constitutive relations in your input file, e.g. ComputeFiniteStrainElasticStress and ComputePlaneFiniteStrain. Therefore your system is no longer linear, so you cannot use solve_type = LINEAR in the executioner. Try solve_type = Newton.",
                          "url": "https://github.com/idaholab/moose/discussions/19510#discussioncomment-1741426",
                          "updatedAt": "2022-06-18T06:14:06Z",
                          "publishedAt": "2021-12-03T02:47:06Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hugary1995"
                          },
                          "bodyText": "I took a look at your 2D input file, it's not quite right either. For example, the stress divergence kernels should be set up like:\n[urealx]\n    type = StressDivergenceTensors\n    variable = uxr\n    displacements='uxr uyr'\n    component = 0\n    base_name = real\n[]\n[urealy]\n    type = StressDivergenceTensors\n    variable = uyr\n    displacements='uxr uyr'\n    component = 1\n    base_name = real\n[]\n[uimagx]\n    type = StressDivergenceTensors\n    variable = uxi\n    displacements='uxi uyi'\n    component = 0\n    base_name = imaginary\n[]\n[uimagy]\n    type = StressDivergenceTensors\n    variable = uyi\n    displacements='uxi uyi'\n    component = 1\n    base_name = imaginary\n[]\nThe displacements argument should be displacement components associated with this vector-valued momentum equation.",
                          "url": "https://github.com/idaholab/moose/discussions/19510#discussioncomment-1741672",
                          "updatedAt": "2022-06-18T06:14:05Z",
                          "publishedAt": "2021-12-03T04:09:57Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "aaelmeli"
                          },
                          "bodyText": "Thanks, @hugary1995 for correcting me, I was not careful when creating the 1-D input file, for the 2D (not posted here), I have correctly defined the kernel, but I have used nonlinear constitutive relation. once I corrected it and considered your corrections, I got the expected solution.\nThank you.",
                          "url": "https://github.com/idaholab/moose/discussions/19510#discussioncomment-1760895",
                          "updatedAt": "2022-10-04T03:20:25Z",
                          "publishedAt": "2021-12-06T20:53:15Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "[Solution][Conda error][CondaHTTPError: HTTP 000 CONNECTION FAILED]",
          "author": {
            "login": "coskrrb2002"
          },
          "bodyText": "For those who suffer from the error of \"CondaHTTPError: HTTP 000 CONNECTION FAILED\".\nUse the following steps.\n\nDownload the old version of Conda by the following command:\nwget https://repo.anaconda.com/miniconda/Miniconda3-4.7.12.1-Linux-x86_64.sh\nInstall it.\nbash Miniconda3-4.7.12.1-Linux-x86_64.sh -b -p ~/miniconda3\nThen you can follow the guideline of moose for Linux:\nhttps://mooseframework.inl.gov/getting_started/installation/conda.html\nFollow from the line:\nexport PATH=$HOME/miniconda3/bin:$PATH\n\nCheers,\nNakkyu",
          "url": "https://github.com/idaholab/moose/discussions/19544",
          "updatedAt": "2022-10-17T13:07:50Z",
          "publishedAt": "2021-12-04T06:04:41Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "loganharbour"
                  },
                  "bodyText": "I'm not sure I would suggest this. Errors like that usually indicative of an actual connection issue.\nDo you have a thread somewhere in which someone suggested a downgrade?",
                  "url": "https://github.com/idaholab/moose/discussions/19544#discussioncomment-1750976",
                  "updatedAt": "2022-10-17T13:08:00Z",
                  "publishedAt": "2021-12-04T23:53:39Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "coskrrb2002"
                          },
                          "bodyText": "Here is the post:\nconda/conda#9948\nI used a Ubuntu app for windows.\nSo, I was guessing that this connection issue is related to wsl version of windows.\nBy the way, after the installation of the old version of Conda, Conda can be updated.\nSo, until someone figure out the real problem, I guess this will be the temporary solution.",
                          "url": "https://github.com/idaholab/moose/discussions/19544#discussioncomment-1751477",
                          "updatedAt": "2022-10-17T13:08:06Z",
                          "publishedAt": "2021-12-05T06:42:01Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "There are other work-arounds on that issue. Indeed I actually posted among that thread a couple months back.\nThis fix should work for any installation of Conda (Miniconda, Miniforge, Mambaforge, etc).\nfind miniconda3/ -type f -exec touch {} +\nI prefer the above solution over others mentioning chmod -R 777. For obvious security reasons.",
                          "url": "https://github.com/idaholab/moose/discussions/19544#discussioncomment-1757664",
                          "updatedAt": "2022-10-17T13:08:06Z",
                          "publishedAt": "2021-12-06T13:40:02Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Something wrong about PETSc and libmesh(PETSc was not found)",
          "author": {
            "login": "wzx-zzsdad"
          },
          "bodyText": "When I use ./update_and_rebuild_libmesh.sh ,it shows me this question above. But my PETSc was already installed. I downloaded PETSc 3.13.2 and used this way to install PETSc below:\n\nand the result of installing PETSc is below:\n\nmy compiler and mpi information(I can use the same way to install moose successfully on other platform(openeuler) but on centos7.6 it can not be installed successfully):\n\n\nBy the way,this information about compiling libmesh on openeuler platform is yes:\n\nPlease help me,thank you!",
          "url": "https://github.com/idaholab/moose/discussions/19491",
          "updatedAt": "2022-06-17T03:00:16Z",
          "publishedAt": "2021-11-28T07:09:06Z",
          "category": {
            "name": "Q&A Getting Started"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "milljm"
                  },
                  "bodyText": "In the same directory where you ran ./update_and_rebuild_libmesh.sh, there is a libmesh_diagnostic.log. Can you attach that to this thread? It gets created when you run ./update_and_rebuild_libmesh.sh. So if the diagnostic log is not present, just run the script again, let it fail, and then the log file should be present.\nAlso, in /home/MOOSE/moose/libmesh/build, there should be a config.log. Please attach that as well (the more information the better).\nSome thoughts\nFlang could also be an issue if that is your selected fortran wrapper/compiler. To my knowledge, we have yet to make use of this new fortran compiler from the LLVM toolchain.\nA simple test for this, would be to try and build libmesh without PETSc support (just to see if libMesh can be built using your compiler stack). Perhaps libMesh is using system compilers, while PETSc was instructed to use special compilers (--with-mpi-dir=/path/to/install/ompi). Being that is a screen shot, and not pasted text, I have to assume /path/to/ompi literally exists.",
                  "url": "https://github.com/idaholab/moose/discussions/19491#discussioncomment-1716497",
                  "updatedAt": "2022-06-22T12:39:29Z",
                  "publishedAt": "2021-11-29T15:06:46Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "wzx-zzsdad"
                          },
                          "bodyText": "I rebuild libmesh in a new path, two logs:\nlibmesh_diagnostic.docx\nconfig.docx\nI also tried  your thoughts.I build libmesh without PETSc but it will generate too many errors when 'make'.\n\nAnd I dont know where can I find complete information about this.\nFurthermore , if my system compilers is GCC9.1.0, I can successfully install libmesh by ./updata_and_build_libmesh.sh and moose even though my openmpi was installed by clang/flang. I tried specifying --with-cc=clang --with-cxx=clang++ --with-fc=flang in configure_libmesh.sh but it also cannot make successfully .Is there any other ways to install libmesh by specifying the compiler?",
                          "url": "https://github.com/idaholab/moose/discussions/19491#discussioncomment-1719740",
                          "updatedAt": "2022-06-23T09:03:46Z",
                          "publishedAt": "2021-11-30T03:21:04Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "I don't have any Microsoft products installed... can you attache a regular .txt log?\n[edit] never mind. I see it is only the suffix being called .docx. I can open these files just fine with a basic editor.",
                          "url": "https://github.com/idaholab/moose/discussions/19491#discussioncomment-1723147",
                          "updatedAt": "2022-06-23T09:03:46Z",
                          "publishedAt": "2021-11-30T16:02:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "The error is with this:\nconfigure:48980: result: <<< Found PETSc 3.13.2 installation in /home/MOOSE-clang/moose/petsc ... >>>\nconfigure:48990: checking whether we can compile a trivial PETSc program\nconfigure:49021: /path/to/install/ompi/bin/mpicxx -c  -I/home/MOOSE-clang/moose/petsc/include -I/home/MOOSE-clang/moose/petsc/arch-moose/include -I/home/MOOSE-clang/moose/petsc/arch-moose/include -I/home/MOOSE-clang/moose/petsc/include -I/home/MOOSE-clang/moose/petsc/arch-moose/include -I/path/to/install/ompi/include  conftest.cpp >&5\nIn file included from conftest.cpp:146:\nIn file included from /home/MOOSE-clang/moose/petsc/include/petsc.h:5:\nIn file included from /home/MOOSE-clang/moose/petsc/include/petscbag.h:4:\nIn file included from /home/MOOSE-clang/moose/petsc/include/petscsys.h:36:\nIn file included from /home/MOOSE-clang/moose/petsc/include/petscsystypes.h:218:\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/complex:374:34: error: no matching member function for call to 'imag'\n      complex<_Tp> __r(__x, -__y.imag());\n                             ~~~~^~~~\n/home/MOOSE-clang/moose/petsc/include/petsccxxcomplexfix.h:73:1: note: in instantiation of function template specialization 'std::operator-<double>' requested here\nPETSC_CXX_COMPLEX_FIX(PetscInt)\n^\n/home/MOOSE-clang/moose/petsc/include/petsccxxcomplexfix.h:55:104: note: expanded from macro 'PETSC_CXX_COMPLEX_FIX'\nstatic inline PetscComplex operator-(const Type& lhs, const PetscComplex& rhs) { return PetscReal(lhs) - const_cast<PetscComplex&>(rhs); } \\\n                                                                                                       ^\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/complex:1224:7: note: candidate function not viable: 'this' argument has type 'const complex<double>', but method is not marked const\n      imag() { return __imag__ _M_value; }\n      ^\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/complex:1245:7: note: candidate function not viable: requires single argument '__val', but no arguments were provided\n      imag(double __val) { __imag__ _M_value = __val; }\n      ^\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/complex:1328:23: error: no matching member function for call to 'real'\n          __real__ __t = __z.real();\n                         ~~~~^~~~\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/complex:435:11: note: in instantiation of function template specialization 'std::complex<double>::operator/=<double>' requested here\n      __r /= __y;\n          ^\n/home/MOOSE-clang/moose/petsc/include/petsccxxcomplexfix.h:73:1: note: in instantiation of function template specialization 'std::operator/<double>' requested here\nPETSC_CXX_COMPLEX_FIX(PetscInt)\n^\n/home/MOOSE-clang/moose/petsc/include/petsccxxcomplexfix.h:59:104: note: expanded from macro 'PETSC_CXX_COMPLEX_FIX'\nstatic inline PetscComplex operator/(const Type& lhs, const PetscComplex& rhs) { return PetscReal(lhs) / const_cast<PetscComplex&>(rhs); } \\\n                                                                                                       ^\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/complex:1220:7: note: candidate function not viable: 'this' argument has type 'const complex<double>', but method is not marked const\n      real() { return __real__ _M_value; }\n      ^\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/complex:1242:7: note: candidate function not viable: requires single argument '__val', but no arguments were provided\n      real(double __val) { __real__ _M_value = __val; }\n      ^\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/complex:1329:23: error: no matching member function for call to 'imag'\n          __imag__ __t = __z.imag();\n                         ~~~~^~~~\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/complex:1224:7: note: candidate function not viable: 'this' argument has type 'const complex<double>', but method is not marked const\n      imag() { return __imag__ _M_value; }\n      ^\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/complex:1245:7: note: candidate function not viable: requires single argument '__val', but no arguments were provided\n      imag(double __val) { __imag__ _M_value = __val; }\n      ^\n3 errors generated.\nconfigure:49021: $? = 1\nconfigure: failed program was:\n| /* confdefs.h */\n| #define PACKAGE_NAME \"libmesh\"\n| #define PACKAGE_TARNAME \"libmesh\"\n| #define PACKAGE_VERSION \"1.7.0-pre\"\n| #define PACKAGE_STRING \"libmesh 1.7.0-pre\"\n| #define PACKAGE_BUGREPORT \"https://github.com/libMesh/libmesh/discussions\"\n| #define PACKAGE_URL \"http://libmesh.github.io\"\n| #define CONFIGURE_INFO \"../configure  '--enable-silent-rules' '--enable-unique-id' '--disable-warnings' '--enable-glibcxx-debugging' '--with-thread-model=openmp' '--disable-maintainer-mode' '--enable-metaphysicl-required' '--with-cxx-std-min=2014' '--without-gdb-command' '--with-methods=opt oprof dbg' '--prefix=/home/MOOSE-clang/moose/scripts/../libmesh/installed' '--with-future-timpi-dir=/home/MOOSE-clang/moose/scripts/../libmesh/installed' 'INSTALL=/home/MOOSE-clang/moose/scripts/../libmesh/build-aux/install-sh -C' '--enable-petsc-hypre-required' 'PETSC_DIR=/home/MOOSE-clang/moose/petsc' 'PETSC_ARCH=arch-moose' 'METHODS=opt oprof dbg'\"\n\nI am guessing the compiler libMesh is trying to use is not the same as the one used to build PETSc. This coincides with what the libmesh_diagnostic.log also mentions:\nTue Nov 30 10:35:03 CST 2021\nRUNNING AS ROOT\n\nSystem Arch: CentOS Linux release 7.6.1810 (AltArch)\n\nMOOSE Package Version: Custom Build\n\nCPU Count: 128\n\nMemory Free: 22509.125 MB\n\n$CC not set                   <------------------ THIS SHOULD BE SET\n\nMPICC:\nwhich mpicc:\n\t/path/to/install/ompi/bin/mpicc\nmpicc -show:\n\tclang -I/path/to/install/ompi//include/openmpi -I/path/to/install/ompi//include/openmpi/opal/mca/hwloc/hwloc201/hwloc/include -I/path/to/install/ompi//include/openmpi/opal/mca/event/libevent2022/libevent -I/path/to/install/ompi//include/openmpi/opal/mca/event/libevent2022/libevent/include -I/path/to/install/ompi//include -pthread -Wl,-rpath -Wl,/path/to/install/ompi//lib -Wl,--enable-new-dtags -L/path/to/install/ompi//lib -lmpi\n\nCOMPILER clang:\nBisheng Compiler 1.3.3.b023 clang version 10.0.1 (clang-e31092d4f8cd flang-3c92ea4b404f)\nTarget: aarch64-unknown-linux-gnu\nThread model: posix\nInstalledDir: /opt/compiler/bisheng-compiler-1.3.3-aarch64-linux/bin\n\nI believe libMesh will default to gcc if CC is not set... try exporting the following:\nexport CC=mpicc CXX=mpicxx FC=mpif90\n\nand then run ./update_and_rebuild_libmesh.sh again... If it fails, please attache the new logs again.",
                          "url": "https://github.com/idaholab/moose/discussions/19491#discussioncomment-1723238",
                          "updatedAt": "2022-06-23T09:03:46Z",
                          "publishedAt": "2021-11-30T16:13:07Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "I see something else as well:\nconftest.c:176:10: fatal error: '/home/MOOSE-clang/moose/petsc/arch-moose/include/petscversion.h' file not found\n#include </home/MOOSE-clang/moose/petsc/arch-moose/include/petscversion.h>\n         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n1 error generated.\n\nDoes this location exist? Its possible you also need to export PETSC_ARCH= to whatever arch- dir is listed in /home/MOOSE-clang/moose/petsc. I have no way of guessing what that might be. If you are unsure, can you provide a directory listing of that location?",
                          "url": "https://github.com/idaholab/moose/discussions/19491#discussioncomment-1723260",
                          "updatedAt": "2022-06-23T08:45:04Z",
                          "publishedAt": "2021-11-30T16:19:38Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "wzx-zzsdad"
                          },
                          "bodyText": "I tried export CC=mpicc CXX=mpicxx FC=mpif90 and in the log $CC has set:\n\nbut also failed while installing libmesh.\nlibmesh_diagnostic.log\nconfig.log\nAnd I have set :\nexport PETSC_DIR=/home/MOOSE-clang/moose/petsc\nexport PETSC_ARCH=arch-moose\n\n\nBut definitely there is no petscversion.h in my petsc path. I checked other machine which has installed moose successfully(with gcc-9.1.0 , the same configure parameters and PETSc version 3.13.2), there is no petscversion.h  in  petsc/arch-moose/include path either.",
                          "url": "https://github.com/idaholab/moose/discussions/19491#discussioncomment-1726023",
                          "updatedAt": "2022-06-23T08:45:06Z",
                          "publishedAt": "2021-12-01T03:38:33Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "@fdkong When folks build petsc but not install it (not using --prefix), do users need to export PETSC_ARCH? I don't believe that directory exists, since there was nothing being installed.\nStill, I am not sure that is the issue, since it looks like libMesh finds what it needs anyway:\nchecking /home/MOOSE-clang/moose/petsc/arch-moose/include/petscversion.h usability... no\nchecking /home/MOOSE-clang/moose/petsc/arch-moose/include/petscversion.h presence... no\nchecking for /home/MOOSE-clang/moose/petsc/arch-moose/include/petscversion.h... no\nchecking /home/MOOSE-clang/moose/petsc/include/petscversion.h usability... yes\nchecking /home/MOOSE-clang/moose/petsc/include/petscversion.h presence... yes\nchecking for /home/MOOSE-clang/moose/petsc/include/petscversion.h... yes\n\nI am thinking libMesh configure is dying here:\nconfigure:48980: result: <<< Found PETSc 3.13.2 installation in /home/MOOSE-clang/moose/petsc ... >>>\nconfigure:48990: checking whether we can compile a trivial PETSc program\nconfigure:49021: mpicxx -c  -I/home/MOOSE-clang/moose/petsc/include -I/home/MOOSE-clang/moose/petsc/arch-moose/include -I/home/MOOSE-clang/moose/petsc/arch-moose/include -I/home/MOOSE-clang/moose/petsc/include -I/home/MOOSE-clang/moose/petsc/arch-moose/include -I/path/to/install/ompi/include  conftest.cpp >&5\nIn file included from conftest.cpp:146:\nIn file included from /home/MOOSE-clang/moose/petsc/include/petsc.h:5:\nIn file included from /home/MOOSE-clang/moose/petsc/include/petscbag.h:4:\nIn file included from /home/MOOSE-clang/moose/petsc/include/petscsys.h:36:\nIn file included from /home/MOOSE-clang/moose/petsc/include/petscsystypes.h:218:\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/complex:374:34: error: no matching member function for call to 'imag'\n      complex<_Tp> __r(__x, -__y.imag());\n                             ~~~~^~~~\n\nBut I am not sure why. PETSc seems to have built fine (and tested fine) in the original post.",
                          "url": "https://github.com/idaholab/moose/discussions/19491#discussioncomment-1728822",
                          "updatedAt": "2022-06-23T08:45:07Z",
                          "publishedAt": "2021-12-01T14:55:49Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "fdkong"
                          },
                          "bodyText": "I am confused by several things here @wzx-zzsdad:\n\n\nOriginally, your PETSc was built as PETSC_DIR=/home/MOOSE/moose/petsc PETSC_ARCH=arch-moose \n\n\nBut then you set:\n\n\nexport PETSC_DIR=/home/MOOSE-clang/moose/petsc\nexport PETSC_ARCH=arch-moose\n\nCould you explain a bit more what the motivation here?\nLibmesh error might be because you used (unintentionally) different compilers for libmesh and petsc.\nBTW, if you want to build PETSc, you really should use our in-house script: ./scripts/update_and_rebuild_petsc.sh. If you want to point to a different MPI, you could do ./scripts/update_and_rebuild_petsc.sh --with-mpi-dir=balabala",
                          "url": "https://github.com/idaholab/moose/discussions/19491#discussioncomment-1729709",
                          "updatedAt": "2022-06-23T08:45:08Z",
                          "publishedAt": "2021-12-01T17:13:28Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "wzx-zzsdad"
                          },
                          "bodyText": "Firstly ,I git moose in a new directory so my PETSc path has changed. Secondly, I can use ./scripts/update_and_rebuild_petsc.sh but I need to set --with-openmp=0 in configure_petsc.sh if I use clang not gcc compiler. It will hang when make check  if I directlly run ./scripts/update_and_rebuild_petsc.sh(default: --with-openmp=1) like this:\n\nEven if I use ./scripts/update_and_rebuild_petsc.sh ----with-mpi-dir=/path/to/install/ompi, the installation of libmesh was also failed.\nBTW,I can install moose successfully with gcc compiler, but there is no petscversion.h in arch-moose.",
                          "url": "https://github.com/idaholab/moose/discussions/19491#discussioncomment-1736322",
                          "updatedAt": "2022-06-23T08:45:15Z",
                          "publishedAt": "2021-12-02T10:58:37Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "milljm"
                          },
                          "bodyText": "clang and clang++ should work, we use it all the time. But I am concerned about flang... That is, if when using the LLVM toolchain you are indeed using flang. Just so we all know, can you run the following:\nmpif90 -show",
                          "url": "https://github.com/idaholab/moose/discussions/19491#discussioncomment-1737561",
                          "updatedAt": "2022-06-23T08:45:16Z",
                          "publishedAt": "2021-12-02T14:42:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "wzx-zzsdad"
                          },
                          "bodyText": "",
                          "url": "https://github.com/idaholab/moose/discussions/19491#discussioncomment-1741382",
                          "updatedAt": "2022-06-23T08:45:15Z",
                          "publishedAt": "2021-12-03T02:35:08Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Serial build, is it possible?",
          "author": {
            "login": "makeclean"
          },
          "bodyText": "HI All\nIve only ever wanted to build MOOSE in parallel for use on HPC clusters, but now I have a rather unique need to compile in serial. It seems that this isn't currently possible using the offered build scripts.\nDuring the build for PETSC, with no MPI installed I got a message suggesting I set --with-mpi=0 for the petsc build, however when I do the following; ./scripts/update_and_rebuild_petsc.sh --prefix=/opt/petsc --with-mpi=0, I get\n==========================================================================================      Trying to download git://https://gitlab.com/slepc/slepc.git for SLEPC               ====================================================================================================================================================================================      SLEPc examples are available at ${PETSC_DIR}/arch-moose/externalpackages/git.slepc        export SLEPC_DIR=/opt/petsc                                                         ====================================================================================================================================================================================      Trying to download git://https://bitbucket.org/petsc/pkg-metis.git for METIS        ====================================================================================================================================================================================      Configuring METIS with cmake; this may take several minutes                         ====================================================================================================================================================================================      Compiling and installing METIS; this may take several minutes                       ==========================================================================================TESTING: checkDependencies from config.packages.parmetis(config/BuildSystem/config/package*******************************************************************************\n         UNABLE to CONFIGURE with GIVEN OPTIONS    (see configure.log for details):\n-------------------------------------------------------------------------------\nDid not find package MPI needed by parmetis.\nEnable the package using --with-mpi\n*******************************************************************************\n\nThere was an error. Exiting...     \n\nBefore I go too far down this rabbit hole, does any one know if its currently possible?",
          "url": "https://github.com/idaholab/moose/discussions/18375",
          "updatedAt": "2021-12-04T20:38:11Z",
          "publishedAt": "2021-07-19T06:27:52Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "@fdkong for petsc build",
                  "url": "https://github.com/idaholab/moose/discussions/18375#discussioncomment-1022094",
                  "updatedAt": "2021-07-19T14:14:29Z",
                  "publishedAt": "2021-07-19T14:14:18Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "fdkong"
                  },
                  "bodyText": "It is possible to build PETSc without MPI even though we do not do that often. You need to shut off any third-party package that requires MPI, for example, parmetis, by doing \"--download-xxxx = 0\".\nBut we might not have tests for checking libmesh-and-moose-without-MPI. However, I would be interested  in the results. It is good to try it out.\nCould you please kindly let us what is the motivation here to build packages without MPI?",
                  "url": "https://github.com/idaholab/moose/discussions/18375#discussioncomment-1022331",
                  "updatedAt": "2021-07-19T15:11:25Z",
                  "publishedAt": "2021-07-19T14:43:26Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "Sure thing, in this case I've wrapped a geometry using the GMSH python interface, which is driven by OpenMDAO using their pyDOE2 module to drive the exploration of the design space, calling a moose application a bunch of times. This can be done in parallel, and is done by launching your python script with mpi4py. The issue here, is that since the MOOSE application doesnt initialise MPI, there is already an a running MPI initialised, and doesnt seem to play nicely. My runs are short, and thus MOOSE doesn't need to run in parallel.",
                          "url": "https://github.com/idaholab/moose/discussions/18375#discussioncomment-1025400",
                          "updatedAt": "2021-07-20T08:47:13Z",
                          "publishedAt": "2021-07-20T08:47:13Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "am-tc01"
                          },
                          "bodyText": "@makeclean Just wondering if you could succeed with a serial build of MOOSE?",
                          "url": "https://github.com/idaholab/moose/discussions/18375#discussioncomment-1129371",
                          "updatedAt": "2021-08-04T09:10:14Z",
                          "publishedAt": "2021-08-04T09:10:14Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "I think you've jumped the gun here @GiudGiud - no, it failed saying METIS couldnt find MPI even with such arguments.",
                          "url": "https://github.com/idaholab/moose/discussions/18375#discussioncomment-1136199",
                          "updatedAt": "2021-08-05T18:53:29Z",
                          "publishedAt": "2021-08-05T18:53:29Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "what argument did you use?\ncan you pls share the build log?",
                          "url": "https://github.com/idaholab/moose/discussions/18375#discussioncomment-1136244",
                          "updatedAt": "2021-08-05T19:06:58Z",
                          "publishedAt": "2021-08-05T19:06:58Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "gwenchee"
                  },
                  "bodyText": "@makeclean Did you figure this out? I want to do a similar setup to run a MOOSE sub-app with an optimization wrapper.",
                  "url": "https://github.com/idaholab/moose/discussions/18375#discussioncomment-1746986",
                  "updatedAt": "2021-12-03T22:18:25Z",
                  "publishedAt": "2021-12-03T22:18:14Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "makeclean"
                          },
                          "bodyText": "I did not, if you have any success let us know :)",
                          "url": "https://github.com/idaholab/moose/discussions/18375#discussioncomment-1750493",
                          "updatedAt": "2021-12-04T20:38:01Z",
                          "publishedAt": "2021-12-04T20:38:01Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "How to extend the time step limit in my input file?",
          "author": {
            "login": "abc-hy"
          },
          "bodyText": "Hi everyone,\nI have a question about my input file. I wanted to run my simulation for a longer time. However, every time I get the following message saying that the time step limit is reached and I cannot continue my simulation. Do you know how to extend the time step limit and let the simulation run a longer time?\nThe following is the message I got:\n\nThank you very much.\nI am looking forward to your advice.\nThe following is my input file:\n#\n# Simulation of iron-chromium alloy decomposition using simplified conditions.\n#\n\n[Mesh]\n  type = GeneratedMesh\n  dim = 2\n  elem_type = QUAD4\n  nx = 60\n  ny = 24\n  nz = 0\n  xmin = 0\n  xmax = 6.0\n  ymin = 0\n  ymax = 2.4\n  zmin = 0\n  zmax = 0\n  uniform_refine = 3\n  nemesis = true\n  skip_partitioning = true\n[]\n\n[Variables]\n\n  [./c]\n    order = FIRST\n    family = LAGRANGE\n    [./InitialCondition]\n      type = IsolatedBoundingBoxIC\n      smaller_coordinate_corners = '0.0 0.3 0   0.0 1.5 0  4.0 0.3 0   4.0 1.5 0  2.0 0.0 0'\n      larger_coordinate_corners =  '2.0 0.9 0   2.0 2.1 0  6.0 0.9 0   6.0 2.1 0  4.0 2.4 0'\n      inside = '1.0 1.0 1.0 1.0 0.0'\n      outside = -1.0\n      int_width = 0\n    [../]\n  [../]\n\n  [./w]\n    order = FIRST\n    family = LAGRANGE\n  [../]\n\n[]\n\n\n[BCs]\n  [./Periodic]\n    [./cx]\n      variable = c\n      auto_direction = 'x,y'\n    [../]\n    [./wx]\n      variable = w\n      auto_direction = 'x,y'\n    [../]\n  [../]\n\n[]\n\n\n[Kernels]\n  [./c_res]\n    type = SplitCHParsed\n    variable = c\n    f_name = F\n    kappa_name = kappa_c\n    w = w\n  [../]\n  [./w_res]\n    type = SplitCHWRes\n    variable = w\n    mob_name = M\n  [../]\n  [./time]\n    type = CoupledTimeDerivative\n    variable = w\n    v = c\n  [../]\n[]\n\n\n[Materials]\n  [./mobility]\n    type = DerivativeParsedMaterial\n    f_name = M\n    args = 'c'\n    function = 1\n    derivative_order = 1\n  [../]\n\n  [./kappa_c]\n    type = GenericConstantMaterial\n    prop_names  = 'kappa_c'\n    prop_values = '8.0e-4'\n  [../]\n\n  [./free_energy]\n    # equivalent to `MathFreeEnergy`\n    type = DerivativeParsedMaterial\n    f_name = F\n    args = 'c'\n    function = (27/8)*c^2*(2-4*c^2+2*c^4)\n  [../]\n[]\n\n[Postprocessors]\n  [./step_size]             # Size of the time step\n    type = TimestepSize\n  [../]\n  [./iterations]            # Number of iterations needed to converge timestep\n    type = NumNonlinearIterations\n  [../]\n  [./nodes]                 # Number of nodes in mesh\n    type = NumNodes\n  [../]\n  [./evaluations]           # Cumulative residual calculations for simulation\n    type = NumResidualEvaluations\n  [../]\n  [./active_time]           # Time computer spent on simulation\n    type = PerfGraphData\n    section_name = \"Root\"\n    data_type = total\n  [../]\n[]\n\n[Preconditioning]\n  # active = ' '\n  [./SMP]\n    type = SMP\n    full = true\n  [../]\n[]\n\n[Executioner]\n  type = Transient\n  scheme = 'BDF2'\n  #petsc_options = '-snes_mf'\n\n  #Preconditioned JFNK (default)\n  solve_type = 'NEWTON'\n\n  petsc_options_iname = '-pc_type -ksp_grmres_restart -sub_ksp_type -sub_pc_type -pc_asm_overlap'\n  petsc_options_value = 'asm      31                  preonly       lu           1'\n  #petsc_options_iname = '-pc_type'\n  #petsc_options_value = 'lu'\n\n  l_max_its = 30 # maximum linear iterations\n  l_tol = 1.0e-6 # 0.001 Linear Tolerance\n\n  nl_max_its = 50 # maximum number of nonlinear iterations. exceed will cut dt.\n  nl_rel_tol = 1.0e-9 # -8 nonlinear relative tolerance\n  num_steps = 2\n\n  [./TimeStepper]\n    type = IterationAdaptiveDT\n    dt = 1e-6\n    cutback_factor = 0.67\n    growth_factor = 1.5   # 1.6\n    optimal_iterations = 10\n    iteration_window = 2\n  [../]\n\n  [./Adaptivity]\n    coarsen_fraction = 0.1\n    refine_fraction = 0.7\n    max_h_level = 3\n    interval = 1\n  [../]\n[]\n\n[Debug]\n  show_var_residual_norms = true\n[]\n\n[Outputs]\n  exodus = true\n  console = true\n  csv = true\n  interval = 2\n  checkpoint = true\n  [./console]\n    type = Console\n    max_rows = 10\n  [../]\n[]",
          "url": "https://github.com/idaholab/moose/discussions/19537",
          "updatedAt": "2022-08-02T14:48:35Z",
          "publishedAt": "2021-12-03T17:05:17Z",
          "category": {
            "name": "Q&A Modules: Phase field"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "jiangwen84"
                  },
                  "bodyText": "When the time steps cuts down to e-14, practically there is no need to continue the simulation. It simply means your solution is no longer converging. You need to find out what causes the issue, largely due to unrealistic physics occurring in your simulation.",
                  "url": "https://github.com/idaholab/moose/discussions/19537#discussioncomment-1745562",
                  "updatedAt": "2022-08-15T01:42:59Z",
                  "publishedAt": "2021-12-03T17:22:21Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "@abc-hy your simulation is diverging at time = 189.841s.\nYou should look at the output (exodus file) and see what the variables are doing close to then\nYou can also output the material properties to exodus to examine those",
                          "url": "https://github.com/idaholab/moose/discussions/19537#discussioncomment-1746561",
                          "updatedAt": "2022-08-15T01:42:59Z",
                          "publishedAt": "2021-12-03T20:25:40Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "Thank you for your reply.\nIs there a place that I can directly set the time step limit value?",
                          "url": "https://github.com/idaholab/moose/discussions/19537#discussioncomment-1746828",
                          "updatedAt": "2022-08-15T01:42:59Z",
                          "publishedAt": "2021-12-03T21:41:14Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "end_time sets the time for the end of the simulation.\nIt s set in the [Executioner] block",
                          "url": "https://github.com/idaholab/moose/discussions/19537#discussioncomment-1746835",
                          "updatedAt": "2022-08-15T01:42:59Z",
                          "publishedAt": "2021-12-03T21:43:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "abc-hy"
                          },
                          "bodyText": "I think the dtmin can change the time step limit.\nIn the following link:\nhttps://mooseframework.inl.gov/source/executioners/Transient.html",
                          "url": "https://github.com/idaholab/moose/discussions/19537#discussioncomment-1747084",
                          "updatedAt": "2022-08-15T01:47:17Z",
                          "publishedAt": "2021-12-03T22:41:48Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "GiudGiud"
                          },
                          "bodyText": "but you dont want to change the dtmin? This dtmin you are reaching is just the failure one.\nI think you want to push the end simulation time further, and to do that you need to figure out why it doesnt converge",
                          "url": "https://github.com/idaholab/moose/discussions/19537#discussioncomment-1748080",
                          "updatedAt": "2022-08-15T01:47:17Z",
                          "publishedAt": "2021-12-04T05:33:29Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              },
              {
                "node": {
                  "author": {
                    "login": "loganharbour"
                  },
                  "bodyText": "In the future, please avoid posting screenshots of text. Instead, paste the text in a code block.\nSee #18270 for more information on posting guidelines in discussions.",
                  "url": "https://github.com/idaholab/moose/discussions/19537#discussioncomment-1746546",
                  "updatedAt": "2022-08-15T01:44:48Z",
                  "publishedAt": "2021-12-03T20:21:50Z",
                  "isAnswer": false,
                  "replies": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Energy Based Damage for Ductile Fracture in Peridynamics",
          "author": {
            "login": "ppandit95"
          },
          "bodyText": "Dear MOOSE Community\nI wish to simulate the tensile test for a ductile material and get the desired stress strain curve but I was wondering if energy based bond damage model is implemented as in the plastic region , a critical stretch based model wont work due to non linearities.Any headers in this regard will be helpful.\nMoreover,I donot know whether a isotropic hardening model is available or not.\nMany Thanks\nPushkar",
          "url": "https://github.com/idaholab/moose/discussions/19388",
          "updatedAt": "2022-06-30T23:43:30Z",
          "publishedAt": "2021-11-15T06:37:52Z",
          "category": {
            "name": "Q&A Modules: General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "GiudGiud"
                  },
                  "bodyText": "Hello\nIs this for peridynamics?\nThere are isotropic hardening models, for example\nhttps://mooseframework.inl.gov/source/materials/IsotropicPowerLawHardeningStressUpdate.html\nI d look in the tensor mechanics documentation for what you want:\nhttps://mooseframework.inl.gov/modules/tensor_mechanics/index.html#!\nGuillaume",
                  "url": "https://github.com/idaholab/moose/discussions/19388#discussioncomment-1742083",
                  "updatedAt": "2022-06-30T23:43:31Z",
                  "publishedAt": "2021-12-03T06:37:58Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "hugary1995"
                          },
                          "bodyText": "Hi Pushkar,\nThe Peridynamics module is currently limited to elastic constitutive models (a few simple damage models are a notable exception). As far as I can tell, the Peridynamics module doesn't have any plasticity models yet. However, implementing new material models should mostly be copy-pasting from the tensor mechanics module. So you can follow the links @GiudGiud posted above.",
                          "url": "https://github.com/idaholab/moose/discussions/19388#discussioncomment-1742252",
                          "updatedAt": "2022-06-30T23:43:31Z",
                          "publishedAt": "2021-12-03T07:23:11Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ppandit95"
                          },
                          "bodyText": "thanks @GiudGiud and @hugary1995 for directing to the relevant sources which can be used for modeling plasticity with isotropic hardening .",
                          "url": "https://github.com/idaholab/moose/discussions/19388#discussioncomment-1742797",
                          "updatedAt": "2022-06-30T23:43:31Z",
                          "publishedAt": "2021-12-03T09:19:59Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "jiangwen84"
                          },
                          "bodyText": "I remembered @hchen139 implemented creep and/or plasticity for the NOSPD formulation. @hchen139 Could you comment on this?",
                          "url": "https://github.com/idaholab/moose/discussions/19388#discussioncomment-1745593",
                          "updatedAt": "2022-06-30T23:43:31Z",
                          "publishedAt": "2021-12-03T17:26:32Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "hchen139"
                          },
                          "bodyText": "NOSPD can incorporate any available inelastic material model from tensor mechanics module, such as creep and plasticity models. As for damage models for PD, the only one available is bond stretch-based model. You will need to develop your own specific damage model based on current capability of the PD module in MOOSE.",
                          "url": "https://github.com/idaholab/moose/discussions/19388#discussioncomment-1745677",
                          "updatedAt": "2022-06-30T23:43:49Z",
                          "publishedAt": "2021-12-03T17:39:39Z",
                          "isAnswer": false
                        }
                      },
                      {
                        "node": {
                          "author": {
                            "login": "ppandit95"
                          },
                          "bodyText": "thanks @jiangwen84 and @hchen139 for elaborating on the issue of damage modelling in ductile materials ....",
                          "url": "https://github.com/idaholab/moose/discussions/19388#discussioncomment-1748007",
                          "updatedAt": "2022-06-30T23:43:46Z",
                          "publishedAt": "2021-12-04T04:39:52Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      },
      {
        "node": {
          "title": "Peridynamics with Phase Field Equations",
          "author": {
            "login": "ppandit95"
          },
          "bodyText": "Dear MOOSE Community,\nI wish to use phase field equations along with peridynamics constitutive model for which I am concerned whether the peridynamic solution is redistributed to Finite Element nodes so that they can be utilised in phase field equations or one has to develop a corresponding constitutive model in peridynamics which mimicks evolution of phase field.Any headers in this regard will be beneficial.\nMany Thanks\nPushkar",
          "url": "https://github.com/idaholab/moose/discussions/19536",
          "updatedAt": "2022-07-14T21:03:17Z",
          "publishedAt": "2021-12-03T15:51:04Z",
          "category": {
            "name": "Q&A General"
          },
          "comments": {
            "edges": [
              {
                "node": {
                  "author": {
                    "login": "jiangwen84"
                  },
                  "bodyText": "It is not clear to me what you want to do here. Maybe it is better to write down your algorithms.\nIn peridynamics, line elements are used to model the bonds. The phase field will be solved on a standard element meshes. They use different meshes, so I do not believe there is a simple way to use the peridynamics solution directly in phase field. However, it might be possible to use Multi-App system that solves phase-field and peridynamics separately and then transfer the data between two simulation.",
                  "url": "https://github.com/idaholab/moose/discussions/19536#discussioncomment-1745544",
                  "updatedAt": "2022-07-14T21:03:33Z",
                  "publishedAt": "2021-12-03T17:18:54Z",
                  "isAnswer": true,
                  "replies": {
                    "edges": [
                      {
                        "node": {
                          "author": {
                            "login": "ppandit95"
                          },
                          "bodyText": "ohh thanks @jiangwen84 for suggesting possible ways to integrate peridynamics solution with phase field evolution...",
                          "url": "https://github.com/idaholab/moose/discussions/19536#discussioncomment-1748005",
                          "updatedAt": "2022-07-14T21:03:42Z",
                          "publishedAt": "2021-12-04T04:37:56Z",
                          "isAnswer": false
                        }
                      }
                    ]
                  }
                }
              }
            ]
          }
        }
      }
    ]
  }
}